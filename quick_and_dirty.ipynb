{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test get_features_from_tsfresh\n",
    "from inputs import Data, get_features_from_tsfresh,load_separators\n",
    "\n",
    "data = Data(movingWindow=100,nEventsPerStat=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "hdf5_directory = 'D:/SDC/py/HDF5/'\n",
    "filename_raw = hdf5_directory+'tradeinfo.hdf5'\n",
    "separators_directory = hdf5_directory+'separators/'\n",
    "f_raw = h5py.File(filename_raw,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AUDCAD\n",
      "\t s 0 of 21. From 2016.01.04 00:00:08 to 2016.10.13 15:41:59\n",
      "\t s 1 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 2 of 21. From 2016.12.26 06:00:00 to 2016.12.30 23:58:30\n",
      "\t s 3 of 21. From 2017.01.02 09:00:00 to 2017.01.26 23:59:59\n",
      "\t s 4 of 21. From 2017.01.30 00:05:00 to 2017.09.05 23:59:59\n",
      "\t s 5 of 21. From 2017.09.06 20:25:01 to 2017.11.10 09:38:15\n",
      "\t s 6 of 21. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t s 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:07\n",
      "\t s 9 of 21. From 2017.12.12 09:55:53 to 2017.12.22 23:58:59\n",
      "\t s 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:42\n",
      "\t s 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:25:25\n",
      "\t s 12 of 21. From 2018.01.11 14:39:34 to 2018.01.25 08:17:37\n",
      "\t s 13 of 21. From 2018.01.25 08:53:48 to 2018.03.08 23:58:59\n",
      "\t s 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t s 15 of 21. From 2018.03.20 05:44:39 to 2018.04.12 09:26:13\n",
      "\t s 16 of 21. From 2018.04.12 10:00:43 to 2018.05.08 03:27:47\n",
      "\t s 17 of 21. From 2018.05.08 04:24:14 to 2018.07.13 23:59:56\n",
      "\t s 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 21 of 21. From 2018.08.27 19:03:29 to 2018.09.27 23:58:58\n",
      "2. EURAUD\n",
      "\t s 0 of 31. From 2016.01.04 00:02:59 to 2016.04.22 23:59:59\n",
      "\t s 1 of 31. From 2016.04.25 03:00:00 to 2016.06.09 11:59:59\n",
      "\t s 2 of 31. From 2016.06.09 12:22:30 to 2016.11.04 22:54:59\n",
      "\t s 3 of 31. From 2016.11.07 01:27:12 to 2016.11.07 23:59:59\n",
      "\t s 4 of 31. From 2016.11.09 13:29:47 to 2016.11.11 23:54:59\n",
      "\t s 5 of 31. From 2016.11.18 00:05:14 to 2016.12.23 23:54:59\n",
      "\t s 6 of 31. From 2016.12.26 09:00:00 to 2016.12.26 11:40:30\n",
      "\t s 7 of 31. From 2016.12.26 12:06:59 to 2016.12.26 15:17:59\n",
      "\ts 8 of 31. Not enough entries. Skipped.\n",
      "\t s 9 of 31. From 2016.12.26 19:42:30 to 2016.12.29 23:59:59\n",
      "\t s 10 of 31. From 2017.01.02 00:02:30 to 2017.04.25 16:55:09\n",
      "\t s 11 of 31. From 2017.04.27 12:00:16 to 2017.07.20 00:03:59\n",
      "\t s 12 of 31. From 2017.07.20 00:25:00 to 2017.09.05 02:36:00\n",
      "\ts 13 of 31. Not enough entries. Skipped.\n",
      "\ts 14 of 31. Not enough entries. Skipped.\n",
      "\t s 15 of 31. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t s 16 of 31. From 2017.11.10 10:05:51 to 2017.11.24 23:58:59\n",
      "\t s 17 of 31. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 18 of 31. From 2017.12.11 00:05:00 to 2017.12.12 04:13:03\n",
      "\t s 19 of 31. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t s 20 of 31. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 21 of 31. From 2018.01.02 03:00:00 to 2018.01.10 21:30:14\n",
      "\t s 22 of 31. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 23 of 31. From 2018.01.25 08:49:52 to 2018.03.08 07:51:45\n",
      "\t s 24 of 31. From 2018.03.09 00:05:00 to 2018.03.20 05:04:46\n",
      "\t s 25 of 31. From 2018.03.20 05:44:29 to 2018.04.12 09:26:15\n",
      "\t s 26 of 31. From 2018.04.12 09:59:08 to 2018.05.08 03:27:55\n",
      "\t s 27 of 31. From 2018.05.08 04:24:14 to 2018.07.13 23:59:57\n",
      "\t s 28 of 31. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 29 of 31. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t s 30 of 31. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 31 of 31. From 2018.08.27 19:03:32 to 2018.09.27 23:58:54\n",
      "3. EURCAD\n",
      "\t s 0 of 23. From 2016.01.04 00:00:00 to 2016.01.11 00:17:59\n",
      "\t s 1 of 23. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 23. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 23. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t s 4 of 23. From 2017.01.02 00:01:00 to 2017.08.24 23:44:59\n",
      "\t s 5 of 23. From 2017.08.28 00:05:02 to 2017.09.05 02:35:52\n",
      "\ts 6 of 23. Not enough entries. Skipped.\n",
      "\t s 7 of 23. From 2017.09.05 09:45:51 to 2017.11.10 09:38:15\n",
      "\t s 8 of 23. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t s 9 of 23. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 10 of 23. From 2017.12.11 00:05:00 to 2017.12.12 04:13:04\n",
      "\t s 11 of 23. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t s 12 of 23. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 13 of 23. From 2018.01.02 03:00:00 to 2018.01.10 21:19:40\n",
      "\t s 14 of 23. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 15 of 23. From 2018.01.25 09:10:26 to 2018.03.07 23:58:59\n",
      "\t s 16 of 23. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t s 17 of 23. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t s 18 of 23. From 2018.04.12 09:59:08 to 2018.05.08 03:27:46\n",
      "\t s 19 of 23. From 2018.05.08 04:24:14 to 2018.07.13 23:59:55\n",
      "\t s 20 of 23. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 21 of 23. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 22 of 23. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 23 of 23. From 2018.08.27 19:03:29 to 2018.09.27 23:58:59\n",
      "4. EURCHF\n",
      "\t s 0 of 28. From 2016.01.04 00:00:00 to 2016.01.11 00:20:59\n",
      "\t s 1 of 28. From 2016.01.11 01:00:00 to 2016.08.15 00:08:59\n",
      "\t s 2 of 28. From 2016.08.15 00:29:00 to 2016.10.13 15:41:59\n",
      "\t s 3 of 28. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 4 of 28. From 2016.12.26 06:00:00 to 2017.08.11 23:59:59\n",
      "\t s 5 of 28. From 2017.08.14 19:30:49 to 2017.08.14 23:58:59\n",
      "\t s 6 of 28. From 2017.08.15 02:21:35 to 2017.08.15 20:17:18\n",
      "\t s 7 of 28. From 2017.08.15 05:00:06 to 2017.08.15 12:51:32\n",
      "\t s 8 of 28. From 2017.08.15 20:17:22 to 2017.08.17 23:58:50\n",
      "\t s 9 of 28. From 2017.08.21 00:05:08 to 2017.08.25 19:54:33\n",
      "\t s 10 of 28. From 2017.08.28 00:05:02 to 2017.09.05 02:35:52\n",
      "\ts 11 of 28. Not enough entries. Skipped.\n",
      "\t s 12 of 28. From 2017.09.05 09:45:51 to 2017.11.10 09:38:15\n",
      "\t s 13 of 28. From 2017.11.10 10:05:51 to 2017.11.24 23:58:59\n",
      "\t s 14 of 28. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 15 of 28. From 2017.12.11 00:05:00 to 2017.12.12 04:12:53\n",
      "\t s 16 of 28. From 2017.12.12 10:13:34 to 2017.12.22 23:58:52\n",
      "\t s 17 of 28. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t s 18 of 28. From 2018.01.02 03:00:00 to 2018.01.10 20:51:51\n",
      "\t s 19 of 28. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 20 of 28. From 2018.01.25 09:10:27 to 2018.03.07 23:58:59\n",
      "\t s 21 of 28. From 2018.03.09 00:05:00 to 2018.03.20 05:04:42\n",
      "\t s 22 of 28. From 2018.03.20 05:44:29 to 2018.04.12 09:26:15\n",
      "\t s 23 of 28. From 2018.04.12 09:59:09 to 2018.05.08 03:27:51\n",
      "\t s 24 of 28. From 2018.05.08 04:24:15 to 2018.07.13 23:59:04\n",
      "\t s 25 of 28. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 26 of 28. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 27 of 28. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 28 of 28. From 2018.08.27 19:03:32 to 2018.09.27 23:58:58\n",
      "7. EURGBP\n",
      "\t s 0 of 21. From 2017.01.02 00:00:30 to 2017.08.14 23:45:59\n",
      "\t s 1 of 21. From 2017.08.15 02:30:32 to 2017.08.17 23:58:59\n",
      "\t s 2 of 21. From 2017.08.21 00:05:08 to 2017.08.25 19:58:59\n",
      "\t s 3 of 21. From 2017.08.28 00:05:01 to 2017.09.05 02:36:00\n",
      "\ts 4 of 21. Not enough entries. Skipped.\n",
      "\t s 5 of 21. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t s 6 of 21. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t s 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:09\n",
      "\t s 9 of 21. From 2017.12.12 10:13:34 to 2017.12.22 23:58:50\n",
      "\t s 10 of 21. From 2017.12.26 03:00:01 to 2017.12.29 23:58:57\n",
      "\t s 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:29:03\n",
      "\t s 12 of 21. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 13 of 21. From 2018.01.25 09:10:26 to 2018.03.07 23:58:59\n",
      "\t s 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:41\n",
      "\t s 15 of 21. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t s 16 of 21. From 2018.04.12 09:59:08 to 2018.05.08 03:27:48\n",
      "\t s 17 of 21. From 2018.05.08 04:24:15 to 2018.07.13 23:59:06\n",
      "\t s 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 21 of 21. From 2018.08.27 19:03:32 to 2018.09.27 23:58:56\n",
      "8. EURNZD\n",
      "\t s 0 of 29. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "\t s 1 of 29. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 2 of 29. From 2016.12.26 06:00:00 to 2016.12.30 23:58:02\n",
      "\t s 3 of 29. From 2017.03.08 00:01:00 to 2017.03.17 22:54:59\n",
      "\t s 4 of 29. From 2017.03.20 01:08:01 to 2017.03.24 22:59:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t s 5 of 29. From 2017.03.27 01:18:09 to 2017.03.27 23:59:59\n",
      "\t s 6 of 29. From 2017.03.28 02:31:26 to 2017.03.28 23:59:59\n",
      "\t s 7 of 29. From 2017.03.29 02:09:06 to 2017.03.30 23:59:59\n",
      "\t s 8 of 29. From 2017.03.31 02:39:18 to 2017.03.31 23:59:59\n",
      "\t s 9 of 29. From 2017.04.03 02:27:33 to 2017.04.03 23:59:59\n",
      "\t s 10 of 29. From 2017.04.04 02:32:37 to 2017.07.14 00:04:30\n",
      "\t s 11 of 29. From 2017.07.14 00:27:00 to 2017.09.05 02:36:00\n",
      "\ts 12 of 29. Not enough entries. Skipped.\n",
      "\t s 13 of 29. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t s 14 of 29. From 2017.11.10 10:05:51 to 2017.11.24 23:58:57\n",
      "\t s 15 of 29. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 16 of 29. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t s 17 of 29. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t s 18 of 29. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t s 19 of 29. From 2018.01.02 03:00:00 to 2018.01.10 21:13:01\n",
      "\t s 20 of 29. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 21 of 29. From 2018.01.25 09:10:27 to 2018.03.07 23:58:59\n",
      "\t s 22 of 29. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t s 23 of 29. From 2018.03.20 05:44:28 to 2018.04.12 09:26:15\n",
      "\t s 24 of 29. From 2018.04.12 09:59:09 to 2018.05.08 03:27:49\n",
      "\t s 25 of 29. From 2018.05.08 04:24:15 to 2018.07.13 23:59:10\n",
      "\t s 26 of 29. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 27 of 29. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t s 28 of 29. From 2018.08.23 13:14:34 to 2018.08.24 23:58:51\n",
      "\t s 29 of 29. From 2018.08.27 19:03:32 to 2018.09.27 23:58:59\n",
      "10. EURUSD\n",
      "\t s 0 of 27. From 2016.01.04 00:03:00 to 2016.04.22 23:59:59\n",
      "\t s 1 of 27. From 2016.04.25 03:00:00 to 2016.06.09 11:59:59\n",
      "\t s 2 of 27. From 2016.06.09 12:22:00 to 2016.12.23 23:54:59\n",
      "\t s 3 of 27. From 2016.12.26 09:00:59 to 2017.01.11 18:42:20\n",
      "\t s 4 of 27. From 2017.01.12 00:00:00 to 2017.01.26 23:59:59\n",
      "\t s 5 of 27. From 2017.03.01 00:00:00 to 2017.08.11 23:59:59\n",
      "\t s 6 of 27. From 2017.08.14 12:28:53 to 2017.08.14 23:58:59\n",
      "\t s 7 of 27. From 2017.08.15 14:07:41 to 2017.08.25 20:06:23\n",
      "\t s 8 of 27. From 2017.08.28 00:05:02 to 2017.09.05 02:36:01\n",
      "\ts 9 of 27. Not enough entries. Skipped.\n",
      "\t s 10 of 27. From 2017.09.05 09:45:50 to 2017.10.23 01:59:34\n",
      "\t s 11 of 27. From 2017.10.23 02:33:26 to 2017.11.10 09:38:15\n",
      "\t s 12 of 27. From 2017.11.10 10:05:52 to 2017.11.24 23:58:33\n",
      "\t s 13 of 27. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 14 of 27. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t s 15 of 27. From 2017.12.12 10:13:34 to 2017.12.22 23:58:58\n",
      "\t s 16 of 27. From 2017.12.26 03:00:00 to 2017.12.29 23:58:57\n",
      "\t s 17 of 27. From 2018.01.02 03:00:00 to 2018.01.10 21:08:57\n",
      "\t s 18 of 27. From 2018.01.11 14:39:29 to 2018.01.25 08:17:37\n",
      "\t s 19 of 27. From 2018.01.25 08:49:52 to 2018.03.08 23:58:59\n",
      "\t s 20 of 27. From 2018.03.09 00:05:00 to 2018.03.20 05:04:41\n",
      "\t s 21 of 27. From 2018.03.20 05:44:29 to 2018.04.12 09:26:15\n",
      "\t s 22 of 27. From 2018.04.12 09:59:08 to 2018.05.08 03:27:51\n",
      "\t s 23 of 27. From 2018.05.08 04:24:15 to 2018.07.13 23:59:56\n",
      "\t s 24 of 27. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 25 of 27. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 26 of 27. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 27 of 27. From 2018.08.27 19:03:31 to 2018.09.27 23:58:53\n",
      "11. GBPAUD\n",
      "\t s 0 of 21. From 2016.01.04 00:00:30 to 2016.10.13 15:41:59\n",
      "\t s 1 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 2 of 21. From 2016.12.26 06:00:00 to 2017.06.08 23:59:59\n",
      "\t s 3 of 21. From 2017.06.12 00:05:00 to 2017.07.20 00:03:59\n",
      "\t s 4 of 21. From 2017.07.20 00:24:30 to 2017.09.05 23:44:35\n",
      "\t s 5 of 21. From 2017.09.05 10:03:57 to 2017.11.10 09:38:15\n",
      "\t s 6 of 21. From 2017.11.10 10:05:54 to 2017.11.24 23:58:59\n",
      "\t s 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:12:53\n",
      "\t s 9 of 21. From 2017.12.12 10:13:38 to 2017.12.22 23:58:59\n",
      "\t s 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:09:22\n",
      "\t s 12 of 21. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 13 of 21. From 2018.01.25 09:10:26 to 2018.03.08 23:58:59\n",
      "\t s 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t s 15 of 21. From 2018.03.20 05:44:32 to 2018.04.12 09:26:16\n",
      "\t s 16 of 21. From 2018.04.12 09:59:08 to 2018.05.08 03:27:53\n",
      "\t s 17 of 21. From 2018.05.08 04:24:12 to 2018.07.13 23:59:11\n",
      "\t s 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 21 of 21. From 2018.08.27 19:03:29 to 2018.09.27 23:58:56\n",
      "12. GBPCAD\n",
      "\t s 0 of 22. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "\t s 1 of 22. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 2 of 22. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t s 3 of 22. From 2017.01.02 00:01:00 to 2017.06.08 23:59:59\n",
      "\t s 4 of 22. From 2017.06.12 00:03:00 to 2017.09.04 23:45:30\n",
      "\t s 5 of 22. From 2017.09.05 10:04:17 to 2017.11.10 09:38:15\n",
      "\t s 6 of 22. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t s 7 of 22. From 2017.11.27 00:05:00 to 2017.12.08 23:58:58\n",
      "\t s 8 of 22. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t s 9 of 22. From 2017.12.12 10:13:38 to 2017.12.22 23:58:59\n",
      "\t s 10 of 22. From 2017.12.26 03:00:00 to 2017.12.29 23:58:55\n",
      "\t s 11 of 22. From 2018.01.02 03:00:00 to 2018.01.10 21:17:35\n",
      "\t s 12 of 22. From 2018.01.11 14:39:29 to 2018.01.25 08:17:37\n",
      "\t s 13 of 22. From 2018.01.25 09:10:27 to 2018.03.08 23:58:59\n",
      "\t s 14 of 22. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t s 15 of 22. From 2018.03.20 05:44:33 to 2018.04.12 09:26:16\n",
      "\t s 16 of 22. From 2018.04.12 09:59:08 to 2018.05.08 03:27:47\n",
      "\t s 17 of 22. From 2018.05.08 04:24:14 to 2018.06.22 15:30:01\n",
      "\t s 18 of 22. From 2018.06.22 16:46:00 to 2018.07.13 23:59:10\n",
      "\t s 19 of 22. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 20 of 22. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 21 of 22. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 22 of 22. From 2018.08.27 19:03:29 to 2018.09.27 23:58:58\n",
      "13. GBPCHF\n",
      "\t s 0 of 21. From 2016.01.04 00:00:30 to 2016.10.13 15:41:59\n",
      "\t s 1 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:58:59\n",
      "\t s 2 of 21. From 2016.12.26 06:00:00 to 2017.07.17 18:51:04\n",
      "\t s 3 of 21. From 2017.07.18 08:25:27 to 2017.07.18 23:45:30\n",
      "\t s 4 of 21. From 2017.07.19 02:07:47 to 2017.09.04 23:45:59\n",
      "\t s 5 of 21. From 2017.09.05 10:04:57 to 2017.11.10 09:38:15\n",
      "\t s 6 of 21. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t s 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:02\n",
      "\t s 9 of 21. From 2017.12.12 10:13:40 to 2017.12.22 23:58:59\n",
      "\t s 10 of 21. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t s 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:16:30\n",
      "\t s 12 of 21. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 13 of 21. From 2018.01.25 08:51:08 to 2018.03.08 23:58:59\n",
      "\t s 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:44\n",
      "\t s 15 of 21. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t s 16 of 21. From 2018.04.12 09:59:10 to 2018.05.08 03:27:54\n",
      "\t s 17 of 21. From 2018.05.08 04:24:15 to 2018.07.13 23:58:58\n",
      "\t s 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 21 of 21. From 2018.08.27 19:03:29 to 2018.09.27 23:58:57\n",
      "14. GBPUSD\n",
      "\t s 0 of 26. From 2016.01.04 00:00:30 to 2016.10.13 15:41:59\n",
      "\t s 1 of 26. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 2 of 26. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t s 3 of 26. From 2017.01.02 00:01:30 to 2017.04.10 02:14:15\n",
      "\t s 4 of 26. From 2017.07.10 00:03:00 to 2017.08.11 23:59:59\n",
      "\t s 5 of 26. From 2017.08.14 19:30:24 to 2017.08.14 23:58:59\n",
      "\t s 6 of 26. From 2017.08.15 04:16:31 to 2017.08.17 23:58:59\n",
      "\t s 7 of 26. From 2017.08.23 00:05:18 to 2017.08.25 20:08:31\n",
      "\t s 8 of 26. From 2017.08.28 00:05:02 to 2017.09.05 02:36:00\n",
      "\ts 9 of 26. Not enough entries. Skipped.\n",
      "\t s 10 of 26. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t s 11 of 26. From 2017.11.10 10:05:51 to 2017.11.24 23:58:59\n",
      "\t s 12 of 26. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 13 of 26. From 2017.12.11 00:05:00 to 2017.12.12 04:13:07\n",
      "\t s 14 of 26. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t s 15 of 26. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t s 16 of 26. From 2018.01.02 03:00:00 to 2018.01.10 21:13:19\n",
      "\t s 17 of 26. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 18 of 26. From 2018.01.25 08:53:48 to 2018.03.08 23:58:58\n",
      "\t s 19 of 26. From 2018.03.09 00:05:00 to 2018.03.20 05:04:43\n",
      "\t s 20 of 26. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t s 21 of 26. From 2018.04.12 09:59:08 to 2018.05.08 03:27:55\n",
      "\t s 22 of 26. From 2018.05.08 04:24:12 to 2018.07.13 23:59:57\n",
      "\t s 23 of 26. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 24 of 26. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 25 of 26. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 26 of 26. From 2018.08.27 19:03:29 to 2018.09.27 23:58:56\n",
      "15. GOLD\n",
      "\t s 0 of 20. From 2017.09.13 19:06:47 to 2017.11.03 22:58:52\n",
      "\t s 1 of 20. From 2017.11.06 01:01:00 to 2017.11.10 09:38:15\n",
      "\t s 2 of 20. From 2017.11.10 10:05:54 to 2017.11.23 19:45:52\n",
      "\t s 3 of 20. From 2017.11.24 01:00:03 to 2017.11.24 19:29:59\n",
      "\t s 4 of 20. From 2017.11.27 01:01:00 to 2017.12.08 23:58:57\n",
      "\t s 5 of 20. From 2017.12.11 01:00:59 to 2017.12.12 04:13:05\n",
      "\t s 6 of 20. From 2017.12.12 09:49:50 to 2017.12.22 23:58:58\n",
      "\t s 7 of 20. From 2017.12.26 03:00:00 to 2017.12.29 23:58:49\n",
      "\t s 8 of 20. From 2018.01.02 03:00:00 to 2018.01.10 21:10:22\n",
      "\t s 9 of 20. From 2018.01.11 14:39:29 to 2018.01.15 19:59:58\n",
      "\t s 10 of 20. From 2018.01.16 01:00:02 to 2018.01.25 08:17:38\n",
      "\t s 11 of 20. From 2018.01.25 09:10:27 to 2018.02.19 19:59:59\n",
      "\t s 12 of 20. From 2018.02.20 01:00:04 to 2018.03.08 23:58:52\n",
      "\t s 13 of 20. From 2018.03.09 01:00:00 to 2018.03.16 22:58:57\n",
      "\t s 14 of 20. From 2018.03.19 01:00:00 to 2018.03.20 05:04:41\n",
      "\t s 15 of 20. From 2018.03.20 05:44:33 to 2018.03.23 22:58:57\n",
      "\t s 16 of 20. From 2018.03.26 01:00:59 to 2018.03.29 23:58:56\n",
      "\t s 17 of 20. From 2018.04.02 01:01:00 to 2018.04.12 09:26:16\n",
      "\t s 18 of 20. From 2018.04.12 09:59:09 to 2018.05.08 03:27:53\n",
      "\t s 19 of 20. From 2018.05.08 04:24:13 to 2018.05.28 19:59:59\n",
      "\t s 20 of 20. From 2018.05.29 01:00:00 to 2018.05.31 23:58:37\n",
      "16. USDCAD\n",
      "\t s 0 of 19. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "\t s 1 of 19. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 2 of 19. From 2016.12.26 06:00:00 to 2017.09.04 23:45:30\n",
      "\t s 3 of 19. From 2017.09.05 10:05:21 to 2017.11.10 09:38:14\n",
      "\t s 4 of 19. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t s 5 of 19. From 2017.11.27 00:05:00 to 2017.12.08 23:58:58\n",
      "\t s 6 of 19. From 2017.12.11 00:05:00 to 2017.12.12 04:13:01\n",
      "\t s 7 of 19. From 2017.12.12 10:13:39 to 2017.12.22 23:58:59\n",
      "\t s 8 of 19. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 9 of 19. From 2018.01.02 03:00:00 to 2018.01.10 21:19:38\n",
      "\t s 10 of 19. From 2018.01.11 14:39:38 to 2018.01.25 08:17:38\n",
      "\t s 11 of 19. From 2018.01.25 09:10:26 to 2018.03.08 23:58:59\n",
      "\t s 12 of 19. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t s 13 of 19. From 2018.03.20 05:44:34 to 2018.04.12 09:26:07\n",
      "\t s 14 of 19. From 2018.04.12 09:59:08 to 2018.05.08 03:27:47\n",
      "\t s 15 of 19. From 2018.05.08 04:24:14 to 2018.07.13 23:59:56\n",
      "\t s 16 of 19. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 17 of 19. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 18 of 19. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 19 of 19. From 2018.08.27 19:03:29 to 2018.09.27 23:58:54\n",
      "17. USDCHF\n",
      "\t s 0 of 25. From 2016.01.04 00:00:59 to 2016.01.11 00:30:59\n",
      "\t s 1 of 25. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 25. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 25. From 2016.12.26 06:00:00 to 2016.12.30 23:58:08\n",
      "\t s 4 of 25. From 2017.01.02 09:00:00 to 2017.08.11 23:54:59\n",
      "\t s 5 of 25. From 2017.08.14 19:30:37 to 2017.08.14 23:58:59\n",
      "\t s 6 of 25. From 2017.08.15 15:13:26 to 2017.08.17 23:58:48\n",
      "\t s 7 of 25. From 2017.08.21 00:05:07 to 2017.08.25 19:45:45\n",
      "\t s 8 of 25. From 2017.08.28 00:05:01 to 2017.09.05 02:35:52\n",
      "\ts 9 of 25. Not enough entries. Skipped.\n",
      "\t s 10 of 25. From 2017.09.05 09:45:55 to 2017.11.10 09:38:15\n",
      "\t s 11 of 25. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t s 12 of 25. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 13 of 25. From 2017.12.11 00:05:00 to 2017.12.22 23:58:59\n",
      "\t s 14 of 25. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 15 of 25. From 2018.01.02 03:00:00 to 2018.01.10 21:17:59\n",
      "\t s 16 of 25. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t s 17 of 25. From 2018.01.25 09:08:40 to 2018.03.08 23:58:59\n",
      "\t s 18 of 25. From 2018.03.09 00:05:00 to 2018.03.20 05:04:49\n",
      "\t s 19 of 25. From 2018.03.20 05:44:30 to 2018.04.12 09:26:15\n",
      "\t s 20 of 25. From 2018.04.12 09:59:08 to 2018.05.08 03:27:52\n",
      "\t s 21 of 25. From 2018.05.08 04:24:15 to 2018.07.13 23:59:00\n",
      "\t s 22 of 25. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 23 of 25. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 24 of 25. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 25 of 25. From 2018.08.27 19:03:29 to 2018.09.27 23:58:58\n",
      "19. USDJPY\n",
      "\t s 0 of 27. From 2016.01.05 00:02:00 to 2016.01.19 16:54:08\n",
      "\t s 1 of 27. From 2016.01.20 00:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 27. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 27. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t s 4 of 27. From 2017.01.02 00:01:59 to 2017.07.14 00:05:30\n",
      "\t s 5 of 27. From 2017.07.14 00:27:00 to 2017.08.11 23:59:59\n",
      "\t s 6 of 27. From 2017.08.14 19:30:40 to 2017.08.14 23:58:59\n",
      "\t s 7 of 27. From 2017.08.15 03:32:14 to 2017.08.17 23:58:59\n",
      "\t s 8 of 27. From 2017.08.21 00:05:07 to 2017.08.25 19:55:41\n",
      "\t s 9 of 27. From 2017.08.28 00:05:01 to 2017.09.05 02:36:00\n",
      "\ts 10 of 27. Not enough entries. Skipped.\n",
      "\t s 11 of 27. From 2017.09.05 09:45:51 to 2017.11.10 09:38:15\n",
      "\t s 12 of 27. From 2017.11.10 10:05:51 to 2017.11.24 23:58:45\n",
      "\t s 13 of 27. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 14 of 27. From 2017.12.11 00:05:00 to 2017.12.12 04:13:06\n",
      "\t s 15 of 27. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t s 16 of 27. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 17 of 27. From 2018.01.02 03:00:00 to 2018.01.10 21:27:56\n",
      "\t s 18 of 27. From 2018.01.11 14:39:29 to 2018.01.25 08:17:36\n",
      "\t s 19 of 27. From 2018.01.25 09:10:27 to 2018.03.08 23:58:52\n",
      "\t s 20 of 27. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t s 21 of 27. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t s 22 of 27. From 2018.04.12 10:00:38 to 2018.05.08 03:27:53\n",
      "\t s 23 of 27. From 2018.05.08 04:24:16 to 2018.07.13 23:59:02\n",
      "\t s 24 of 27. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 25 of 27. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 26 of 27. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 27 of 27. From 2018.08.27 19:03:31 to 2018.09.27 23:58:59\n",
      "27. CADJPY\n",
      "\t s 0 of 22. From 2016.01.04 00:00:00 to 2016.01.15 23:59:59\n",
      "\t s 1 of 22. From 2016.01.19 00:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 22. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 22. From 2016.12.26 06:00:00 to 2017.09.11 23:01:59\n",
      "\t s 4 of 22. From 2017.09.11 23:28:00 to 2017.09.18 23:59:59\n",
      "\t s 5 of 22. From 2017.09.19 23:45:43 to 2017.10.23 01:18:29\n",
      "\t s 6 of 22. From 2017.10.23 02:02:38 to 2017.11.10 09:38:15\n",
      "\t s 7 of 22. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t s 8 of 22. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 9 of 22. From 2017.12.11 00:05:00 to 2017.12.12 04:13:05\n",
      "\t s 10 of 22. From 2017.12.12 10:13:38 to 2017.12.22 23:58:59\n",
      "\t s 11 of 22. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 12 of 22. From 2018.01.02 03:00:00 to 2018.01.10 21:17:53\n",
      "\t s 13 of 22. From 2018.01.11 14:39:29 to 2018.01.25 08:17:37\n",
      "\t s 14 of 22. From 2018.01.25 09:10:28 to 2018.03.08 23:58:59\n",
      "\t s 15 of 22. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t s 16 of 22. From 2018.03.20 05:44:32 to 2018.04.12 09:26:16\n",
      "\t s 17 of 22. From 2018.04.12 10:00:39 to 2018.05.08 03:27:53\n",
      "\t s 18 of 22. From 2018.05.08 04:24:16 to 2018.05.31 23:58:58\n",
      "\t s 19 of 22. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 20 of 22. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t s 21 of 22. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 22 of 22. From 2018.08.27 19:03:31 to 2018.09.27 23:58:59\n",
      "28. EURJPY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t s 0 of 24. From 2016.01.04 00:00:00 to 2016.01.11 00:29:59\n",
      "\t s 1 of 24. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 24. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 24. From 2016.12.26 06:00:00 to 2017.07.10 00:04:59\n",
      "\t s 4 of 24. From 2017.07.10 00:30:00 to 2017.07.14 00:04:59\n",
      "\t s 5 of 24. From 2017.07.14 00:27:00 to 2017.09.11 23:01:59\n",
      "\ts 6 of 24. Not enough entries. Skipped.\n",
      "\t s 7 of 24. From 2017.09.11 23:47:00 to 2017.09.19 23:59:59\n",
      "\t s 8 of 24. From 2017.09.21 08:10:57 to 2017.11.10 09:38:15\n",
      "\t s 9 of 24. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t s 10 of 24. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 11 of 24. From 2017.12.11 00:05:00 to 2017.12.12 04:12:51\n",
      "\t s 12 of 24. From 2017.12.12 10:13:36 to 2017.12.22 23:58:59\n",
      "\t s 13 of 24. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 14 of 24. From 2018.01.02 03:00:00 to 2018.01.10 21:26:10\n",
      "\t s 15 of 24. From 2018.01.11 14:39:33 to 2018.01.25 08:17:38\n",
      "\t s 16 of 24. From 2018.01.25 09:08:40 to 2018.03.08 23:58:59\n",
      "\t s 17 of 24. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t s 18 of 24. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t s 19 of 24. From 2018.04.12 09:59:08 to 2018.05.08 03:27:54\n",
      "\t s 20 of 24. From 2018.05.08 04:24:13 to 2018.07.13 23:59:56\n",
      "\t s 21 of 24. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 22 of 24. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 23 of 24. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 24 of 24. From 2018.08.27 19:03:31 to 2018.09.27 23:58:59\n",
      "29. AUDJPY\n",
      "\t s 0 of 21. From 2016.01.04 00:00:00 to 2016.01.11 00:24:59\n",
      "\t s 1 of 21. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 21. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t s 4 of 21. From 2017.01.02 09:00:00 to 2017.01.27 23:54:59\n",
      "\t s 5 of 21. From 2017.01.31 00:12:00 to 2017.11.09 23:59:59\n",
      "\t s 6 of 21. From 2017.11.20 00:05:00 to 2017.11.24 23:58:59\n",
      "\t s 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:54\n",
      "\t s 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t s 9 of 21. From 2017.12.12 10:13:40 to 2017.12.22 23:58:58\n",
      "\t s 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t s 11 of 21. From 2018.01.02 02:59:59 to 2018.01.10 21:13:01\n",
      "\t s 12 of 21. From 2018.01.11 14:39:33 to 2018.01.25 08:17:37\n",
      "\t s 13 of 21. From 2018.01.25 09:10:26 to 2018.03.08 23:58:54\n",
      "\t s 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t s 15 of 21. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t s 16 of 21. From 2018.04.12 10:00:38 to 2018.05.08 03:27:55\n",
      "\t s 17 of 21. From 2018.05.08 04:24:13 to 2018.07.13 23:59:08\n",
      "\t s 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t s 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 21 of 21. From 2018.08.27 19:03:36 to 2018.09.27 23:58:59\n",
      "30. CHFJPY\n",
      "\t s 0 of 21. From 2016.01.04 01:00:00 to 2016.01.11 00:19:59\n",
      "\t s 1 of 21. From 2016.01.11 01:00:00 to 2016.03.18 22:59:59\n",
      "\t s 2 of 21. From 2016.03.21 01:00:00 to 2016.10.13 15:41:59\n",
      "\t s 3 of 21. From 2016.10.13 17:52:00 to 2016.10.18 00:01:34\n",
      "\t s 4 of 21. From 2016.10.18 02:28:18 to 2016.12.23 23:59:59\n",
      "\t s 5 of 21. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t s 6 of 21. From 2017.01.02 09:00:00 to 2017.11.24 23:58:59\n",
      "\t s 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:56\n",
      "\t s 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:07\n",
      "\t s 9 of 21. From 2017.12.12 10:13:40 to 2017.12.22 23:58:58\n",
      "\t s 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:58\n",
      "\t s 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:09:34\n",
      "\t s 12 of 21. From 2018.01.15 11:16:28 to 2018.01.25 08:17:38\n",
      "\t s 13 of 21. From 2018.01.25 09:10:26 to 2018.03.08 23:58:59\n",
      "\t s 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t s 15 of 21. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t s 16 of 21. From 2018.04.12 09:59:08 to 2018.05.08 03:27:53\n",
      "\t s 17 of 21. From 2018.05.08 04:24:15 to 2018.07.13 23:59:56\n",
      "\t s 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 21 of 21. From 2018.08.27 19:03:31 to 2018.09.27 23:58:57\n",
      "31. GBPJPY\n",
      "\t s 0 of 23. From 2016.01.04 00:00:30 to 2016.01.11 00:17:59\n",
      "\t s 1 of 23. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t s 2 of 23. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 23. From 2016.12.26 06:00:00 to 2017.08.14 00:41:30\n",
      "\ts 4 of 23. Not enough entries. Skipped.\n",
      "\t s 5 of 23. From 2017.08.14 15:07:00 to 2017.09.18 23:59:59\n",
      "\t s 6 of 23. From 2017.09.19 23:46:08 to 2017.11.10 09:38:15\n",
      "\t s 7 of 23. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t s 8 of 23. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t s 9 of 23. From 2017.12.11 00:05:00 to 2017.12.12 04:13:09\n",
      "\t s 10 of 23. From 2017.12.12 10:13:39 to 2017.12.22 23:58:59\n",
      "\t s 11 of 23. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t s 12 of 23. From 2018.01.02 03:00:00 to 2018.01.10 21:28:58\n",
      "\t s 13 of 23. From 2018.01.11 14:39:32 to 2018.01.25 08:17:38\n",
      "\t s 14 of 23. From 2018.01.25 08:49:51 to 2018.03.08 23:58:59\n",
      "\t s 15 of 23. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t s 16 of 23. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t s 17 of 23. From 2018.04.12 09:59:09 to 2018.05.08 03:27:56\n",
      "\t s 18 of 23. From 2018.05.08 04:24:15 to 2018.07.13 23:59:56\n",
      "\t s 19 of 23. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 20 of 23. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t s 21 of 23. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 22 of 23. From 2018.08.27 19:03:31 to 2018.09.06 04:36:04\n",
      "\t s 23 of 23. From 2018.09.07 00:05:02 to 2018.09.27 23:58:59\n",
      "32. NZDUSD\n",
      "\t s 0 of 22. From 2016.01.04 00:00:30 to 2016.10.13 00:01:05\n",
      "\t s 1 of 22. From 2016.10.13 01:47:11 to 2016.10.13 15:41:59\n",
      "\t s 2 of 22. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t s 3 of 22. From 2016.12.26 06:00:00 to 2017.09.11 23:01:59\n",
      "\t s 4 of 22. From 2017.09.11 23:47:00 to 2017.09.28 13:45:59\n",
      "\t s 5 of 22. From 2017.09.28 14:10:00 to 2017.11.16 23:59:59\n",
      "\t s 6 of 22. From 2017.11.20 00:05:01 to 2017.11.24 23:58:59\n",
      "\t s 7 of 22. From 2017.11.27 00:05:00 to 2017.12.08 23:58:57\n",
      "\t s 8 of 22. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t s 9 of 22. From 2017.12.12 10:13:36 to 2017.12.22 23:58:59\n",
      "\t s 10 of 22. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t s 11 of 22. From 2018.01.02 03:00:00 to 2018.01.10 21:10:40\n",
      "\t s 12 of 22. From 2018.01.11 14:39:33 to 2018.01.23 08:12:03\n",
      "\t s 13 of 22. From 2018.01.24 00:05:18 to 2018.01.25 08:17:37\n",
      "\t s 14 of 22. From 2018.01.25 09:10:33 to 2018.03.08 23:58:59\n",
      "\t s 15 of 22. From 2018.03.09 00:05:00 to 2018.03.20 05:04:46\n",
      "\t s 16 of 22. From 2018.03.20 05:44:40 to 2018.04.12 09:26:11\n",
      "\t s 17 of 22. From 2018.04.12 09:59:08 to 2018.05.08 03:27:56\n",
      "\t s 18 of 22. From 2018.05.08 04:24:16 to 2018.07.13 23:59:00\n",
      "\t s 19 of 22. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t s 20 of 22. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t s 21 of 22. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t s 22 of 22. From 2018.08.27 19:03:32 to 2018.09.27 23:58:59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. AUDCAD\n",
      "\t s 0 of 21. From 2016.01.04 00:00:08 to 2016.10.13 15:41:59\n",
      "(83840918,)\n"
     ]
    }
   ],
   "source": [
    "thisAsset = data.AllAssets[str(1)]\n",
    "print(str(0)+\". \"+thisAsset)\n",
    "    \n",
    "group_raw = f_raw[thisAsset]\n",
    "# load separators\n",
    "separators = load_separators(data, thisAsset, separators_directory, from_txt=1)\n",
    "nE = separators.index[0+1]-separators.index[0]+1\n",
    "# check if number of events is not enough to build two features and one return\n",
    "if nE>=2*data.nEventsPerStat:\n",
    "    print(\"\\t\"+\" s {0:d} of {1:d}\".format(int(0/2),int(len(separators)/2-1))+\n",
    "          \". From \"+separators.DateTime.iloc[0]+\" to \"+separators.DateTime.iloc[0+1])\n",
    "    DateTime = group_raw[\"DateTime\"]\n",
    "    SymbolBid = group_raw[\"SymbolBid\"]\n",
    "    SymbolAsk = group_raw[\"SymbolAsk\"]\n",
    "    print(DateTime.shape)\n",
    "    #features = get_features_from_tsfresh(data, DateTime, SymbolBid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-411d192a51e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mnExS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnEventsPerStat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovingWindow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msecsInDay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m86400.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import datetime as dt\n",
    "\n",
    "nExS = data.nEventsPerStat\n",
    "mW = data.movingWindow\n",
    "secsInDay = 86400.0\n",
    "# return per bid\n",
    "#returnBid = SymbolBid.iloc[nExS:]-SymbolBid.iloc[:-nExS+1]\n",
    "nE = SymbolBid.shape[0]\n",
    "# max number of features\n",
    "m = int(np.floor((nE/nExS-1)*nExS/mW)+1)\n",
    "# format TSFRESH input\n",
    "features = pd.DataFrame()\n",
    "list_inputs = []\n",
    "list_DateTime = []\n",
    "batch_size = 100\n",
    "par_batches = 10#int(np.ceil(m/batch_size))\n",
    "l_index = 0\n",
    "# loop over batched\n",
    "for b in range(par_batches):\n",
    "    # get m of batch\n",
    "    m_i = np.min([batch_size, m-b*batch_size])\n",
    "    i_range = b*batch_size*nExS\n",
    "    e_range = (b*batch_size+m_i)*nExS\n",
    "    #print(range(i_range,e_range))\n",
    "    print(\"Batch \"+str(b)+\"out of \"+str(par_batches-1))\n",
    "    input_ts = pd.DataFrame(data=0.0,index=range(i_range,e_range),columns=['SymbolBid','id','time'])\n",
    "    datetimes = pd.DataFrame(data='',index=range(i_range,e_range),columns=['DateTime'])\n",
    "    # loop over this batch\n",
    "    for mm in range(m_i):\n",
    "        # get indexes\n",
    "        startIndex = l_index+mm*mW\n",
    "        endIndex = startIndex+nExS\n",
    "        # period range\n",
    "        thisPeriod = range(startIndex,endIndex)\n",
    "        input_ts.SymbolBid.iloc[mm*nExS:(mm+1)*nExS] = SymbolBid[thisPeriod]\n",
    "        datetimes.DateTime.iloc[mm*nExS:(mm+1)*nExS] = DateTime[thisPeriod]\n",
    "        input_ts.id.iloc[mm*nExS:(mm+1)*nExS] = b*batch_size+mm\n",
    "        input_ts.time.iloc[mm*nExS:(mm+1)*nExS] = range(nExS)\n",
    "    l_index = startIndex+mW\n",
    "    #print(input_ts.shape)\n",
    "    #print(input_ts.head())\n",
    "    #print(input_ts.iloc[-1])\n",
    "    #list_inputs.append(input_ts)\n",
    "    #list_DateTime.append(datetimes)\n",
    "    # build feature vector\n",
    "    this_feats = extract_features(input_ts, column_id=\"id\", column_sort=\"time\")\n",
    "    features = features.append(this_feats)\n",
    "    print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [01:09<10:26, 69.60s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [01:12<06:36, 49.52s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [02:09<06:02, 51.72s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [03:03<03:41, 44.37s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [03:09<02:10, 32.74s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:39<01:35, 31.96s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:41<00:45, 22.99s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [04:06<00:23, 23.72s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:09<00:00, 17.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 794)\n",
      "Batch 1 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:29<04:21, 29.03s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:30<02:45, 20.75s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:55<02:34, 22.10s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:56<01:34, 15.74s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:22<01:33, 18.74s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:26<00:57, 14.39s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:48<00:49, 16.62s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:52<00:25, 12.83s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:16<00:16, 16.06s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:19<00:00, 12.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 794)\n",
      "Batch 2 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:13, 28.15s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:29<02:39, 19.96s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:57<02:37, 22.53s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:57<01:35, 15.83s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:23<01:34, 18.92s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:48<00:51, 17.01s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:49<00:24, 12.01s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:14<00:15, 16.00s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:15<00:00, 11.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 794)\n",
      "Batch 3 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:20, 28.90s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:30<02:44, 20.56s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:30, 21.53s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:31, 15.20s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.09s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:20<00:51, 12.99s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:48, 16.11s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.60s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:14, 14.98s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 794)\n",
      "Batch 4 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:15, 28.36s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:39, 19.99s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:30, 21.53s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:31, 15.32s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.16s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:21<00:52, 13.15s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:45<00:49, 16.53s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:47<00:24, 12.15s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:09<00:15, 15.28s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:11<00:00, 11.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 794)\n",
      "Batch 5 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:57, 26.41s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:29, 18.69s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:25, 20.80s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:28, 14.79s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:27, 17.44s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.92s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:48, 16.23s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:45<00:23, 11.97s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:09<00:15, 15.66s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:11<00:00, 11.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 794)\n",
      "Batch 6 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:55, 26.13s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:28, 18.55s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:21, 20.22s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:51<01:25, 14.24s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:28, 17.74s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:51, 12.82s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:42<00:48, 16.04s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.87s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:06<00:14, 14.82s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 10.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 794)\n",
      "Batch 7 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:49, 25.52s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:26, 18.28s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:25, 20.76s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:28, 14.74s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:21<01:33, 18.65s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:22<00:52, 13.20s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:49<00:51, 17.21s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:50<00:24, 12.43s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:15<00:16, 16.36s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:17<00:00, 11.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 794)\n",
      "Batch 8 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:19, 28.87s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:08<03:02, 26.10s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:31<02:31, 25.22s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:52<01:59, 23.91s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:32<01:55, 28.83s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [02:46<01:12, 24.30s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:30<01:00, 30.37s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [03:31<00:21, 21.35s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:06<00:00, 25.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 794)\n",
      "Batch 9 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:45<06:51, 45.74s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:56<04:42, 35.29s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:25<03:52, 33.22s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:29<02:28, 24.70s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:53<02:01, 24.39s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:57<01:13, 18.32s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [02:22<01:00, 20.33s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [02:26<00:30, 15.48s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:48<00:17, 17.39s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:52<00:00, 13.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 794)\n",
      "Batch 10 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<04:01, 26.83s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:36, 22.41s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:51<01:35, 15.92s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:16<01:33, 18.65s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:54, 13.70s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:42<00:49, 16.56s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:24, 12.36s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:09<00:16, 16.10s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 794)\n",
      "Batch 11 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:14, 28.26s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:29<02:40, 20.04s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:29, 21.30s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:30, 15.07s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:18<01:29, 17.84s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.65s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:44<00:49, 16.55s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:10<00:15, 15.51s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 794)\n",
      "Batch 12 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:04, 27.16s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:32, 19.06s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:28, 21.24s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:55<01:32, 15.34s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.05s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:21<00:52, 13.19s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:45<00:49, 16.57s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:48<00:24, 12.30s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:13<00:16, 16.16s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:15<00:00, 11.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 794)\n",
      "Batch 13 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:58, 26.55s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:30, 18.78s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:23, 20.46s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:51<01:26, 14.36s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:18<01:30, 18.11s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.73s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:48, 16.19s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.78s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:08<00:15, 15.33s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 794)\n",
      "Batch 14 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:54, 26.10s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:29, 18.69s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:26, 20.89s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:57<01:33, 15.67s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:29, 17.83s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:22<00:53, 13.30s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:44<00:47, 15.89s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:48<00:24, 12.18s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:09<00:14, 14.94s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:12<00:00, 11.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 794)\n",
      "Batch 15 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:29<04:28, 29.81s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:30<02:47, 20.98s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:56<02:37, 22.53s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:56<01:35, 15.88s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:22<01:33, 18.78s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:22<00:53, 13.34s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:47<00:49, 16.62s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:47<00:23, 11.85s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:17<00:17, 17.03s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:18<00:00, 12.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 794)\n",
      "Batch 16 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:29<04:24, 29.37s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:29<02:45, 20.74s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:01<02:48, 24.10s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:02<01:42, 17.03s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:27<01:37, 19.43s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:28<00:56, 14.03s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:53<00:51, 17.22s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:55<00:25, 12.53s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:19<00:15, 15.94s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:20<00:00, 11.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 794)\n",
      "Batch 17 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:03, 27.06s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:34, 19.25s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:26, 20.87s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:30, 15.04s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:18<01:28, 17.73s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:21<00:53, 13.32s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:46<00:50, 16.92s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:49<00:25, 12.65s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:12<00:15, 15.71s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:13<00:00, 11.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 794)\n",
      "Batch 18 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:51, 25.74s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:26, 18.34s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:21, 20.23s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:52<01:26, 14.42s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:16<01:26, 17.40s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.64s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:42<00:48, 16.01s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.91s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:06<00:15, 15.04s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 11.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 794)\n",
      "Batch 19 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:04, 27.11s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:34, 19.26s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:26, 20.94s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:28, 14.73s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:18<01:28, 17.78s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.61s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:49, 16.43s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.65s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:08<00:15, 15.30s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 794)\n",
      "Batch 20 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:49, 25.47s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:26, 18.33s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:48<02:15, 19.32s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:50<01:24, 14.08s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:10<01:19, 15.90s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:12<00:46, 11.59s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:34<00:43, 14.65s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:35<00:21, 10.58s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:56<00:13, 13.93s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:58<00:00, 10.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 794)\n",
      "Batch 21 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:22<03:23, 22.60s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:22<02:07, 15.88s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:08, 18.40s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:47<01:18, 13.09s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:12<01:22, 16.50s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:12<00:46, 11.63s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:37<00:46, 15.55s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:37<00:22, 11.07s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:01<00:14, 15.00s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:02<00:00, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 794)\n",
      "Batch 22 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:56, 26.30s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:27, 18.46s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:50<02:21, 20.19s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:52<01:28, 14.76s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:16<01:26, 17.30s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:52, 13.15s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:41<00:47, 15.79s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:45<00:24, 12.14s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:09<00:15, 15.69s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 11.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 794)\n",
      "Batch 23 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:08, 27.64s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:37, 19.70s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:00<02:43, 23.32s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:02<01:40, 16.77s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:28<01:38, 19.63s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:30<00:57, 14.29s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:55<00:53, 17.69s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:56<00:25, 12.56s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:22<00:16, 16.50s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:22<00:00, 11.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 794)\n",
      "Batch 24 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:03, 27.07s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:32, 19.07s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:26, 20.91s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:28, 14.79s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:28, 17.75s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:51, 12.75s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:42<00:47, 15.97s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.68s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:15, 15.12s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 11.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 794)\n",
      "Batch 25 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:57, 26.34s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:28, 18.55s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:22, 20.36s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:52<01:26, 14.47s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:29, 17.85s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.63s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:49, 16.42s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:43<00:23, 11.59s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:15, 15.22s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 794)\n",
      "Batch 26 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:59, 26.57s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:29, 18.71s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:24, 20.64s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:52<01:27, 14.58s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:18<01:29, 17.96s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:20<00:52, 13.16s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:44<00:49, 16.59s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:45<00:23, 11.93s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:09<00:15, 15.49s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:11<00:00, 11.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 794)\n",
      "Batch 27 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:09, 27.70s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:36, 19.52s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:29, 21.33s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:30, 15.08s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.15s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.80s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:45<00:50, 16.68s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:46<00:23, 11.86s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:11<00:15, 15.86s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:11<00:00, 11.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 794)\n",
      "Batch 28 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:54, 26.05s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:27, 18.45s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:50<02:19, 19.92s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:52<01:28, 14.78s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:28, 17.77s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.62s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:48, 16.27s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:43<00:22, 11.48s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:15, 15.42s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 10.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2900, 794)\n",
      "Batch 29 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:09, 27.71s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:37, 19.68s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:27, 21.10s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:30, 15.03s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:27, 17.49s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:17<00:49, 12.34s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:41<00:47, 15.92s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:42<00:22, 11.49s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:15, 15.56s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 794)\n",
      "Batch 30 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:16, 28.48s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:29<02:41, 20.19s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:28, 21.19s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:30, 15.04s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:28, 17.66s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.98s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:42<00:48, 16.05s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.88s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:15, 15.28s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 794)\n",
      "Batch 31 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:09, 27.73s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:36, 19.58s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:27, 21.03s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:30, 15.16s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:28, 17.74s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.91s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:45<00:50, 16.79s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:46<00:23, 11.94s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:10<00:15, 15.69s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:12<00:00, 11.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 794)\n",
      "Batch 32 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:50, 25.59s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:26, 18.37s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:50<02:19, 19.94s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:52<01:26, 14.35s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:28, 17.66s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:18<00:50, 12.55s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:49, 16.34s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:45<00:24, 12.03s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:15, 15.23s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 11.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 794)\n",
      "Batch 33 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:56, 26.25s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:27, 18.47s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:23, 20.44s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:51<01:26, 14.35s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:29, 17.89s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:52, 13.05s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:45<00:50, 16.74s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:49<00:26, 13.03s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:11<00:15, 15.90s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:14<00:00, 11.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3400, 794)\n",
      "Batch 34 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<04:02, 26.92s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:31, 18.94s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:26, 20.86s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:28, 14.81s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:18<01:28, 17.80s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.79s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:48, 16.25s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.57s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:10<00:15, 15.88s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 794)\n",
      "Batch 35 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:58, 26.55s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:32, 19.08s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:23, 20.54s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:29, 14.85s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:27, 17.55s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:21<00:54, 13.51s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:42<00:47, 15.85s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:45<00:23, 11.90s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:08<00:15, 15.25s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 11.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 794)\n",
      "Batch 36 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:04, 27.16s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:32, 19.08s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:51<02:25, 20.73s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:30, 15.13s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:31, 18.31s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.86s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:47<00:51, 17.14s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:47<00:24, 12.22s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:20<00:18, 18.37s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:21<00:00, 13.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3700, 794)\n",
      "Batch 37 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:30<04:31, 30.17s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:30<02:49, 21.24s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:57<02:41, 23.06s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:58<01:37, 16.22s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:25<01:37, 19.48s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:53<00:53, 17.93s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:55<00:25, 12.94s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:26<00:18, 18.34s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:27<00:00, 13.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3800, 794)\n",
      "Batch 38 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:10, 27.88s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:36, 19.56s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:27, 21.10s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:31, 15.25s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:27, 17.49s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.92s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:48, 16.15s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.71s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:08<00:15, 15.32s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 11.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 794)\n",
      "Batch 39 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:45, 25.02s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:23, 17.96s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:09, 18.55s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:48<01:20, 13.48s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:08<01:18, 15.68s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:10<00:45, 11.45s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:31<00:42, 14.24s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:33<00:21, 10.54s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:53<00:13, 13.59s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:55<00:00,  9.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 794)\n",
      "Batch 40 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:28, 23.12s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:11, 16.48s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:43<02:01, 17.35s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:48<01:21, 13.53s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:06<01:14, 14.94s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:09<00:45, 11.44s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:28<00:41, 13.71s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:32<00:21, 10.89s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:51<00:13, 13.25s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:54<00:00, 10.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4100, 794)\n",
      "Batch 41 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:27, 23.07s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:23<02:09, 16.24s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:07, 18.22s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:16, 12.83s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:09<01:18, 15.74s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:09<00:45, 11.29s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:32<00:44, 14.78s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:55<00:13, 13.69s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:55<00:00, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 794)\n",
      "Batch 42 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:24<03:41, 24.66s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:25<02:19, 17.39s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:12, 18.99s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:48<01:20, 13.40s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:10<01:20, 16.08s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:10<00:45, 11.30s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:32<00:43, 14.44s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:32<00:20, 10.17s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:55<00:14, 14.13s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:56<00:00, 10.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4300, 794)\n",
      "Batch 43 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:35, 23.95s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:25<02:17, 17.13s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:11, 18.82s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:49<01:22, 13.72s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:11<01:20, 16.07s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:13<00:47, 11.82s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:34<00:43, 14.65s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:38<00:22, 11.33s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:56<00:13, 13.38s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:59<00:00, 10.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4400, 794)\n",
      "Batch 44 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:24<03:43, 24.82s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:26, 18.32s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:10, 18.71s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:51<01:25, 14.23s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:12<01:21, 16.34s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:14<00:48, 12.14s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:36<00:44, 14.84s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:37<00:21, 10.77s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:00<00:14, 14.52s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:00<00:00, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 794)\n",
      "Batch 45 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:57, 26.37s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:56<02:40, 22.98s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:56<01:37, 16.19s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.19s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:20<00:51, 12.94s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:43<00:47, 15.91s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:44<00:23, 11.51s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:08<00:15, 15.15s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:08<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 794)\n",
      "Batch 46 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:22<03:22, 22.52s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:23<02:09, 16.19s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:06, 18.01s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:48<01:19, 13.17s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:10<01:19, 16.00s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:12<00:46, 11.69s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:35<00:45, 15.07s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:36<00:22, 11.05s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:59<00:14, 14.59s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:00<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4700, 794)\n",
      "Batch 47 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:31, 23.52s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:45<02:17, 19.70s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:25, 14.18s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:06<01:20, 16.07s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:09<00:48, 12.06s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:38<00:51, 17.10s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:42<00:26, 13.24s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:07<00:16, 16.80s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:10<00:00, 12.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 794)\n",
      "Batch 48 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<03:54, 26.10s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:26<02:26, 18.34s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:50<02:19, 19.99s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:50<01:24, 14.09s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:15<01:27, 17.47s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:16<00:50, 12.53s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:40<00:47, 15.87s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:41<00:22, 11.34s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:04<00:14, 14.78s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:05<00:00, 10.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, 794)\n",
      "Batch 49 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:04, 27.16s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:33, 19.17s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:25, 20.80s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:53<01:30, 15.07s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:17<01:27, 17.50s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:19<00:51, 12.97s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:40<00:46, 15.38s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:43<00:23, 11.56s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:02<00:13, 13.93s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:04<00:00, 10.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 794)\n",
      "Batch 50 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:24<03:36, 24.06s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:15, 16.96s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:09, 18.45s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:17, 12.98s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:08<01:17, 15.54s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:08<00:44, 11.00s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:31<00:43, 14.54s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:32<00:21, 10.54s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:52<00:13, 13.34s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:53<00:00,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5100, 794)\n",
      "Batch 51 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:26<04:02, 26.96s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:34, 19.34s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:52<02:25, 20.80s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:55<01:31, 15.26s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.05s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:21<00:53, 13.32s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:44<00:48, 16.25s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:46<00:23, 11.89s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:11<00:15, 15.86s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:13<00:00, 11.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 794)\n",
      "Batch 52 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:09, 27.77s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:29<02:40, 20.03s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:27, 21.13s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:56<01:35, 15.85s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:20<01:30, 18.04s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:24<00:55, 13.94s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:46<00:49, 16.49s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:50<00:25, 12.74s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:14<00:16, 16.00s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:17<00:00, 12.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5300, 794)\n",
      "Batch 53 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:28<04:13, 28.14s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:39, 19.93s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:56<02:35, 22.28s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:57<01:34, 15.71s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:25<01:37, 19.55s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:26<00:55, 13.92s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [02:08<01:07, 22.34s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [02:11<00:33, 16.72s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:55<00:24, 24.68s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [03:03<00:00, 19.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 794)\n",
      "Batch 54 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:40<06:08, 40.97s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [01:02<04:41, 35.21s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:21<03:32, 30.38s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [02:18<03:49, 38.25s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:22<02:20, 28.02s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [03:28<02:37, 39.42s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:50<01:42, 34.22s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [04:26<01:09, 34.81s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [04:53<00:32, 32.21s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [05:01<00:00, 25.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 794)\n",
      "Batch 55 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:11, 27.94s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:28<02:36, 19.62s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:29, 21.39s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:56<01:35, 15.93s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:20<01:30, 18.20s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:25<00:56, 14.24s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:46<00:48, 16.22s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:52<00:26, 13.37s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:13<00:15, 15.52s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:18<00:00, 12.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 794)\n",
      "Batch 56 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:27<04:05, 27.24s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:27<02:34, 19.26s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:53<02:27, 21.13s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:54<01:30, 15.05s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:19<01:30, 18.16s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:22<00:53, 13.44s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:45<00:49, 16.45s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:46<00:23, 11.78s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [02:11<00:15, 15.69s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [02:11<00:00, 11.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5700, 794)\n",
      "Batch 57 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:36<05:32, 36.96s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:43<03:41, 27.66s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:23<03:41, 31.65s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:26<02:17, 22.95s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:11<02:28, 29.67s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:15<01:27, 21.84s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [02:53<01:19, 26.56s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:06<00:45, 22.60s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [03:36<00:24, 24.87s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [03:49<00:00, 21.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5800, 794)\n",
      "Batch 58 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:52<07:51, 52.40s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:52<04:54, 36.79s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:37<04:33, 39.06s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:46<03:00, 30.15s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:23<02:40, 32.18s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:38<01:48, 27.08s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:07<01:22, 27.62s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:26<00:50, 25.10s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [03:49<00:24, 24.53s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:00<00:00, 20.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 794)\n",
      "Batch 59 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:47<07:07, 47.51s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:58<04:51, 36.44s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:45<04:38, 39.76s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:59<03:12, 32.02s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:50<03:08, 37.73s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:52<01:47, 26.91s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:28<01:29, 29.73s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:33<00:44, 22.30s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [04:09<00:26, 26.34s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:18<00:00, 21.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 794)\n",
      "Batch 60 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:46<06:56, 46.26s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [01:07<05:09, 38.63s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:41<04:20, 37.28s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [02:17<03:42, 37.13s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:36<02:38, 31.68s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [03:13<02:12, 33.13s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:29<01:24, 28.05s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [04:01<00:58, 29.25s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [04:32<00:29, 29.64s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:45<00:00, 24.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6100, 794)\n",
      "Batch 61 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:57<08:34, 57.16s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [01:39<07:01, 52.65s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [02:07<05:16, 45.22s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [03:05<04:54, 49.09s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [03:20<03:15, 39.07s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [04:06<02:43, 40.95s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [04:35<01:51, 37.31s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [04:49<01:00, 30.30s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [05:24<00:31, 31.85s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [05:42<00:00, 27.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6200, 794)\n",
      "Batch 62 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:48<07:20, 48.97s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:50<04:37, 34.75s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:35<04:23, 37.67s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:38<02:44, 27.43s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:19<02:37, 31.57s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:27<01:37, 24.27s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:02<01:22, 27.59s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:23<00:51, 25.65s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [03:48<00:25, 25.57s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:08<00:00, 23.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 794)\n",
      "Batch 63 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:46<06:58, 46.55s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:58<04:50, 36.25s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:37<04:18, 36.98s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:53<03:04, 30.77s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:19<02:26, 29.31s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:41<01:48, 27.09s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [03:09<01:21, 27.20s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [03:38<00:55, 27.74s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [04:04<00:27, 27.29s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [04:25<00:00, 25.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 794)\n",
      "Batch 64 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:49<07:21, 49.09s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:56<04:52, 36.55s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [01:29<04:07, 35.39s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [01:42<02:52, 28.69s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [02:23<02:42, 32.53s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [02:33<01:42, 25.74s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [02:51<01:10, 23.39s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [02:58<00:37, 18.56s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [03:15<00:18, 18.15s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [03:20<00:00, 14.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6500, 794)\n",
      "Batch 65 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:32, 23.64s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:13, 16.68s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:45<02:06, 18.08s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:17, 12.85s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:08<01:19, 15.85s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:09<00:44, 11.24s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:31<00:43, 14.56s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:34<00:21, 10.90s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:54<00:13, 13.80s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:56<00:00, 10.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6600, 794)\n",
      "Batch 66 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:50, 25.56s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:25<02:23, 17.97s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:48<02:15, 19.32s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:09<01:23, 16.76s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:10<00:47, 11.98s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:32<00:45, 15.01s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:33<00:21, 10.84s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:59<00:15, 15.18s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:59<00:00, 10.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 794)\n",
      "Batch 67 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:35, 23.94s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:25<02:17, 17.14s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:10, 18.62s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:48<01:21, 13.53s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:09<01:18, 15.70s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:12<00:47, 11.79s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:31<00:42, 14.11s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:34<00:21, 10.75s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:54<00:13, 13.53s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:56<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 794)\n",
      "Batch 68 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:29, 23.26s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:13, 16.63s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:09, 18.49s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:47<01:18, 13.03s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:10<01:19, 15.91s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:10<00:45, 11.28s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:33<00:44, 14.87s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:34<00:20, 10.48s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:55<00:13, 13.84s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:56<00:00,  9.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6900, 794)\n",
      "Batch 69 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:22<03:22, 22.45s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:22<02:06, 15.84s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:43<02:00, 17.28s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:44<01:15, 12.54s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:05<01:15, 15.04s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:06<00:43, 10.87s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:28<00:42, 14.12s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:33<00:22, 11.37s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:49<00:12, 12.81s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:54<00:00, 10.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 794)\n",
      "Batch 70 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:30, 23.44s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:12, 16.62s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:45<02:06, 18.09s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:45<01:16, 12.70s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:07<01:16, 15.39s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:08<00:43, 10.95s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:30<00:43, 14.45s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:30<00:20, 10.16s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:52<00:13, 13.69s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:53<00:00,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7100, 794)\n",
      "Batch 71 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:24<03:36, 24.07s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:25<02:17, 17.14s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:09, 18.48s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:47<01:18, 13.09s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:09<01:19, 15.85s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:10<00:45, 11.40s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:33<00:44, 14.74s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:33<00:20, 10.45s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:56<00:14, 14.37s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:57<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 794)\n",
      "Batch 72 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:25<03:49, 25.52s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:25<02:23, 17.95s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:47<02:14, 19.19s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:48<01:21, 13.65s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:10<01:20, 16.19s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:11<00:46, 11.68s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:33<00:44, 14.73s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:34<00:20, 10.46s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:56<00:13, 13.92s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:57<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7300, 794)\n",
      "Batch 73 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:28, 23.22s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:23<02:10, 16.29s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:44<02:04, 17.77s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:45<01:15, 12.61s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:06<01:16, 15.26s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:07<00:43, 10.84s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:28<00:41, 13.91s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:28<00:19,  9.92s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:50<00:13, 13.32s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:50<00:00,  9.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7400, 794)\n",
      "Batch 74 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:22<03:26, 22.90s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:23<02:10, 16.32s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:07, 18.14s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:17, 12.91s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:08<01:17, 15.58s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:09<00:44, 11.21s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:30<00:42, 14.09s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:31<00:20, 10.22s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:51<00:13, 13.13s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:53<00:00,  9.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 794)\n",
      "Batch 75 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:27, 23.07s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:23<02:10, 16.32s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:45<02:05, 17.88s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:18, 13.04s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:06<01:14, 14.86s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:09<00:46, 11.59s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:30<00:42, 14.22s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:31<00:20, 10.35s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:53<00:13, 13.72s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:54<00:00,  9.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600, 794)\n",
      "Batch 76 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:32, 23.63s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:13, 16.66s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:45<02:07, 18.23s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:47<01:18, 13.13s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:09<01:20, 16.01s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:10<00:46, 11.54s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:33<00:44, 14.71s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:33<00:21, 10.55s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:56<00:14, 14.02s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:57<00:00, 10.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7700, 794)\n",
      "Batch 77 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:29, 23.24s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:23<02:11, 16.38s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:45<02:06, 18.07s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:17, 12.89s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:07<01:16, 15.34s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:08<00:44, 11.05s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:29<00:42, 14.05s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:30<00:20, 10.13s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:51<00:13, 13.48s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:52<00:00,  9.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7800, 794)\n",
      "Batch 78 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:24<03:37, 24.21s/it]\n",
      "Feature Extraction:  20%|███████████████                                                            | 2/10 [00:24<02:16, 17.03s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:08, 18.38s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:07<01:20, 16.13s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:29<00:43, 14.58s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:30<00:20, 10.35s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:52<00:14, 14.08s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:54<00:00, 10.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7900, 794)\n",
      "Batch 79 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]\n",
      "Feature Extraction:  10%|███████▌                                                                   | 1/10 [00:23<03:29, 23.30s/it]\n",
      "Feature Extraction:  30%|██████████████████████▌                                                    | 3/10 [00:46<02:18, 19.72s/it]\n",
      "Feature Extraction:  40%|██████████████████████████████                                             | 4/10 [00:46<01:23, 13.93s/it]\n",
      "Feature Extraction:  50%|█████████████████████████████████████▌                                     | 5/10 [01:08<01:21, 16.28s/it]\n",
      "Feature Extraction:  60%|█████████████████████████████████████████████                              | 6/10 [01:08<00:46, 11.53s/it]\n",
      "Feature Extraction:  70%|████████████████████████████████████████████████████▌                      | 7/10 [01:30<00:43, 14.60s/it]\n",
      "Feature Extraction:  80%|████████████████████████████████████████████████████████████               | 8/10 [01:30<00:20, 10.32s/it]\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [01:52<00:13, 13.76s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████████████████| 10/10 [01:53<00:00,  9.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 794)\n",
      "Batch 80 out of 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|                                                                                   | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-de413f4ead99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m#list_DateTime.append(datetimes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# build feature vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mthis_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_feats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor)\u001b[0m\n\u001b[0;32m    157\u001b[0m                                 \u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                                 \u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                                 distributor=distributor)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# Impute the result if requested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36m_do_extraction\u001b[1;34m(df, column_id, column_value, column_kind, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, distributor)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_fc_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind_to_fc_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     result = distributor.map_reduce(_do_extraction_on_chunk, data=data_in_chunks, chunk_size=chunk_size,\n\u001b[1;32m--> 240\u001b[1;33m                                     function_kwargs=kwargs)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0mdistributor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tsfresh\\utilities\\distribution.py\u001b[0m in \u001b[0;36mmap_reduce\u001b[1;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_function_with_partly_reduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "\n",
    "# extract featues\n",
    "nExS = data.nEventsPerStat\n",
    "mW = data.movingWindow\n",
    "secsInDay = 86400.0\n",
    "# return per bid\n",
    "#returnBid = SymbolBid.iloc[nExS:]-SymbolBid.iloc[:-nExS+1]\n",
    "nE = SymbolBid.shape[0]\n",
    "# max number of features\n",
    "m = int(np.floor((nE/nExS-1)*nExS/mW)+1)\n",
    "# format TSFRESH input\n",
    "features = pd.DataFrame()\n",
    "list_inputs = []\n",
    "list_DateTime = []\n",
    "batch_size = 100\n",
    "par_batches = 100#int(np.ceil(m/batch_size))\n",
    "l_index = 0\n",
    "# loop over batched\n",
    "for b in range(par_batches):\n",
    "    # get m of batch\n",
    "    m_i = np.min([batch_size, m-b*batch_size])\n",
    "    i_range = b*batch_size*nExS\n",
    "    e_range = (b*batch_size+m_i)*nExS\n",
    "    #print(range(i_range,e_range))\n",
    "    print(\"Batch \"+str(b)+\" out of \"+str(par_batches-1))\n",
    "    input_ts = pd.DataFrame(data=0.0,index=range(i_range,e_range),columns=['SymbolBid','id','time'])\n",
    "    datetimes = pd.DataFrame(data='',index=range(i_range,e_range),columns=['DateTime'])\n",
    "    # loop over this batch\n",
    "    for mm in range(m_i):\n",
    "        # get indexes\n",
    "        startIndex = l_index+mm*mW\n",
    "        endIndex = startIndex+nExS\n",
    "        # period range\n",
    "        thisPeriod = range(startIndex,endIndex)\n",
    "        input_ts.SymbolBid.iloc[mm*nExS:(mm+1)*nExS] = SymbolBid[thisPeriod]\n",
    "        datetimes.DateTime.iloc[mm*nExS:(mm+1)*nExS] = DateTime[thisPeriod]\n",
    "        input_ts.id.iloc[mm*nExS:(mm+1)*nExS] = b*batch_size+mm\n",
    "        input_ts.time.iloc[mm*nExS:(mm+1)*nExS] = range(nExS)\n",
    "    l_index = startIndex+mW\n",
    "    #print(input_ts.shape)\n",
    "    #print(input_ts.head())\n",
    "    #print(input_ts.iloc[-1])\n",
    "    #list_inputs.append(input_ts)\n",
    "    #list_DateTime.append(datetimes)\n",
    "    # build feature vector\n",
    "    this_feats = extract_features(input_ts, column_id=\"id\", column_sort=\"time\")\n",
    "    features = features.append(this_feats)\n",
    "    print(features.shape)\n",
    "\n",
    "# filter features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import datetime as dt\n",
    "# get outputs\n",
    "init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            separators.DateTime.iloc[0],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            separators.DateTime.iloc[0+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "group_name = thisAsset+'/'+init_date+end_date\n",
    "filename_prep_IO = (hdf5_directory+'IO_mW'+str(data.movingWindow)+'_nE'+\n",
    "                        str(data.nEventsPerStat)+'_nF'+str(data.nFeatures)+'.hdf5')\n",
    "f_prep_IO = h5py.File(filename_prep_IO,'r')\n",
    "group = f_prep_IO[group_name]\n",
    "returns = group['returns']\n",
    "y = returns[:features.shape[0],data.lookAheadIndex]\n",
    "# filter features\n",
    "impute(features)\n",
    "features_filtered = select_features(features, y)\n",
    "print(features_filtered.head())\n",
    "print(features_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered regression as machine learning task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable  SymbolBid__maximum  SymbolBid__minimum  SymbolBid__quantile__q_0.9  \\\n",
      "id                                                                             \n",
      "0.0                  1.01031             1.00595                    1.008620   \n",
      "1.0                  1.01031             1.00671                    1.009950   \n",
      "2.0                  1.01031             1.00671                    1.010030   \n",
      "3.0                  1.01153             1.00671                    1.010150   \n",
      "4.0                  1.01169             1.00714                    1.011111   \n",
      "\n",
      "variable  SymbolBid__quantile__q_0.1  \\\n",
      "id                                     \n",
      "0.0                         1.006840   \n",
      "1.0                         1.006939   \n",
      "2.0                         1.007199   \n",
      "3.0                         1.007220   \n",
      "4.0                         1.007480   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_70__attr_\"imag\"  \\\n",
      "id                                                            \n",
      "0.0                                                0.011053   \n",
      "1.0                                                0.009066   \n",
      "2.0                                                0.008255   \n",
      "3.0                                                0.013307   \n",
      "4.0                                                0.010562   \n",
      "\n",
      "variable  SymbolBid__quantile__q_0.8  SymbolBid__abs_energy  \\\n",
      "id                                                            \n",
      "0.0                         1.008430            1015.455025   \n",
      "1.0                         1.008620            1016.155474   \n",
      "2.0                         1.009900            1016.776061   \n",
      "3.0                         1.010012            1017.393216   \n",
      "4.0                         1.010150            1018.265723   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_0__attr_\"real\"  \\\n",
      "id                                                           \n",
      "0.0                                             1007.69757   \n",
      "1.0                                             1008.04491   \n",
      "2.0                                             1008.35260   \n",
      "3.0                                             1008.65840   \n",
      "4.0                                             1009.09068   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_0__attr_\"abs\"  SymbolBid__mean  \\\n",
      "id                                                                           \n",
      "0.0                                            1007.69757         1.007698   \n",
      "1.0                                            1008.04491         1.008045   \n",
      "2.0                                            1008.35260         1.008353   \n",
      "3.0                                            1008.65840         1.008658   \n",
      "4.0                                            1009.09068         1.009091   \n",
      "\n",
      "variable                         ...                          \\\n",
      "id                               ...                           \n",
      "0.0                              ...                           \n",
      "1.0                              ...                           \n",
      "2.0                              ...                           \n",
      "3.0                              ...                           \n",
      "4.0                              ...                           \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_49__attr_\"angle\"  \\\n",
      "id                                                             \n",
      "0.0                                              108.126485    \n",
      "1.0                                              105.532813    \n",
      "2.0                                               99.885232    \n",
      "3.0                                               94.962914    \n",
      "4.0                                               95.885328    \n",
      "\n",
      "variable  SymbolBid__number_peaks__n_1  \\\n",
      "id                                       \n",
      "0.0                              308.0   \n",
      "1.0                              294.0   \n",
      "2.0                              285.0   \n",
      "3.0                              283.0   \n",
      "4.0                              272.0   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_83__attr_\"real\"  \\\n",
      "id                                                            \n",
      "0.0                                               -0.003079   \n",
      "1.0                                               -0.002563   \n",
      "2.0                                               -0.002161   \n",
      "3.0                                               -0.001960   \n",
      "4.0                                               -0.000497   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_73__attr_\"angle\"  \\\n",
      "id                                                             \n",
      "0.0                                              104.764047    \n",
      "1.0                                              142.030264    \n",
      "2.0                                               63.972827    \n",
      "3.0                                               95.647119    \n",
      "4.0                                              113.351216    \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_75__attr_\"real\"  \\\n",
      "id                                                            \n",
      "0.0                                               -0.001071   \n",
      "1.0                                               -0.002916   \n",
      "2.0                                               -0.001147   \n",
      "3.0                                               -0.002027   \n",
      "4.0                                               -0.001975   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_87__attr_\"real\"  \\\n",
      "id                                                            \n",
      "0.0                                               -0.002485   \n",
      "1.0                                               -0.001034   \n",
      "2.0                                               -0.003014   \n",
      "3.0                                               -0.002256   \n",
      "4.0                                               -0.001120   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_50__attr_\"angle\"  \\\n",
      "id                                                             \n",
      "0.0                                               96.120511    \n",
      "1.0                                               95.997350    \n",
      "2.0                                               96.249695    \n",
      "3.0                                               97.059571    \n",
      "4.0                                              101.533444    \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_68__attr_\"angle\"  \\\n",
      "id                                                             \n",
      "0.0                                              102.902232    \n",
      "1.0                                               76.956297    \n",
      "2.0                                              107.512153    \n",
      "3.0                                              116.310040    \n",
      "4.0                                              111.703359    \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_85__attr_\"real\"  \\\n",
      "id                                                            \n",
      "0.0                                               -0.004416   \n",
      "1.0                                               -0.001253   \n",
      "2.0                                               -0.001854   \n",
      "3.0                                               -0.002557   \n",
      "4.0                                               -0.000582   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_96__attr_\"angle\"  \n",
      "id                                                            \n",
      "0.0                                              100.912987   \n",
      "1.0                                              124.046341   \n",
      "2.0                                               92.310670   \n",
      "3.0                                              101.007583   \n",
      "4.0                                              126.240124   \n",
      "\n",
      "[5 rows x 231 columns]\n",
      "(8000, 231)\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import datetime as dt\n",
    "# get outputs\n",
    "init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            separators.DateTime.iloc[0],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            separators.DateTime.iloc[0+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "group_name = thisAsset+'/'+init_date+end_date\n",
    "filename_prep_IO = (hdf5_directory+'IO_mW'+str(data.movingWindow)+'_nE'+\n",
    "                        str(data.nEventsPerStat)+'_nF'+str(data.nFeatures)+'.hdf5')\n",
    "f_prep_IO = h5py.File(filename_prep_IO,'r')\n",
    "group = f_prep_IO[group_name]\n",
    "returns = group['returns']\n",
    "y = returns[:features.shape[0],data.lookAheadIndex]\n",
    "# filter features\n",
    "impute(features)\n",
    "features_filtered = select_features(features, y)\n",
    "print(features_filtered.head())\n",
    "print(features_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309819, 7)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "#print(input_ts.iloc[200:210])\n",
    "#print(input_ts.iloc[1100:1110])\n",
    "#print(input_ts.iloc[2000:2010])\n",
    "import datetime as dt\n",
    "init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            separators.DateTime.iloc[0],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            separators.DateTime.iloc[0+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "group_name = thisAsset+'/'+init_date+end_date\n",
    "# get group from filef_prep_IO\n",
    "filename_prep_IO = (hdf5_directory+'IO_mW'+str(data.movingWindow)+'_nE'+\n",
    "                        str(data.nEventsPerStat)+'_nF'+str(data.nFeatures)+'.hdf5')\n",
    "f_prep_IO = h5py.File(filename_prep_IO,'r')\n",
    "group = f_prep_IO[group_name]\n",
    "returns = group['returns']\n",
    "print(returns.shape)\n",
    "y = returns[:features.shape[0],data.lookAheadIndex]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_filtered.to_csv('./feats_filt.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable  SymbolBid__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.2__ql_0.0  \\\n",
      "id                                                                                \n",
      "0.0                                            2.507823e-09                       \n",
      "1.0                                            2.500400e-09                       \n",
      "2.0                                            3.540164e-09                       \n",
      "3.0                                            3.611154e-09                       \n",
      "4.0                                            1.311085e-09                       \n",
      "\n",
      "variable  SymbolBid__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.2__ql_0.0  \\\n",
      "id                                                                               \n",
      "0.0                                            1.639956e-09                      \n",
      "1.0                                            1.648129e-09                      \n",
      "2.0                                            1.931948e-09                      \n",
      "3.0                                            1.928673e-09                      \n",
      "4.0                                            5.410020e-10                      \n",
      "\n",
      "variable  SymbolBid__approximate_entropy__m_2__r_0.5  \\\n",
      "id                                                     \n",
      "0.0                                         0.034874   \n",
      "1.0                                         0.023972   \n",
      "2.0                                         0.020643   \n",
      "3.0                                         0.017112   \n",
      "4.0                                         0.012553   \n",
      "\n",
      "variable  SymbolBid__approximate_entropy__m_2__r_0.7  \\\n",
      "id                                                     \n",
      "0.0                                         0.020802   \n",
      "1.0                                         0.015161   \n",
      "2.0                                         0.012499   \n",
      "3.0                                         0.010012   \n",
      "4.0                                         0.009528   \n",
      "\n",
      "variable  SymbolBid__approximate_entropy__m_2__r_0.3  \\\n",
      "id                                                     \n",
      "0.0                                         0.061246   \n",
      "1.0                                         0.047441   \n",
      "2.0                                         0.038502   \n",
      "3.0                                         0.033284   \n",
      "4.0                                         0.025227   \n",
      "\n",
      "variable  SymbolBid__ar_coefficient__k_10__coeff_0  \\\n",
      "id                                                   \n",
      "0.0                                      -0.000836   \n",
      "1.0                                      -0.000418   \n",
      "2.0                                       0.000123   \n",
      "3.0                                      -0.000691   \n",
      "4.0                                       0.000353   \n",
      "\n",
      "variable  SymbolBid__approximate_entropy__m_2__r_0.9  \\\n",
      "id                                                     \n",
      "0.0                                         0.014879   \n",
      "1.0                                         0.010955   \n",
      "2.0                                         0.009792   \n",
      "3.0                                         0.008081   \n",
      "4.0                                         0.010082   \n",
      "\n",
      "variable  SymbolBid__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.2__ql_0.0  \\\n",
      "id                                                                                \n",
      "0.0                                                0.000030                       \n",
      "1.0                                                0.000029                       \n",
      "2.0                                                0.000040                       \n",
      "3.0                                                0.000041                       \n",
      "4.0                                                0.000028                       \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_50__attr_\"abs\"  \\\n",
      "id                                                           \n",
      "0.0                                               0.013746   \n",
      "1.0                                               0.013728   \n",
      "2.0                                               0.011931   \n",
      "3.0                                               0.017666   \n",
      "4.0                                               0.013405   \n",
      "\n",
      "variable  SymbolBid__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.4__ql_0.0  \\\n",
      "id                                                                                \n",
      "0.0                                            2.922301e-09                       \n",
      "1.0                                            2.117401e-09                       \n",
      "2.0                                            2.240021e-09                       \n",
      "3.0                                            2.217903e-09                       \n",
      "4.0                                            1.065593e-09                       \n",
      "\n",
      "variable                  ...                    \\\n",
      "id                        ...                     \n",
      "0.0                       ...                     \n",
      "1.0                       ...                     \n",
      "2.0                       ...                     \n",
      "3.0                       ...                     \n",
      "4.0                       ...                     \n",
      "\n",
      "variable  SymbolBid__autocorrelation__lag_7  \\\n",
      "id                                            \n",
      "0.0                                0.947205   \n",
      "1.0                                0.977465   \n",
      "2.0                                0.991137   \n",
      "3.0                                0.975099   \n",
      "4.0                                0.988285   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_61__attr_\"abs\"  \\\n",
      "id                                                           \n",
      "0.0                                               0.013211   \n",
      "1.0                                               0.012337   \n",
      "2.0                                               0.010062   \n",
      "3.0                                               0.012153   \n",
      "4.0                                               0.009093   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_30__attr_\"imag\"  \\\n",
      "id                                                            \n",
      "0.0                                                0.029725   \n",
      "1.0                                                0.024801   \n",
      "2.0                                                0.019563   \n",
      "3.0                                                0.028755   \n",
      "4.0                                                0.026774   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_70__attr_\"real\"  \\\n",
      "id                                                            \n",
      "0.0                                               -0.001658   \n",
      "1.0                                                0.000789   \n",
      "2.0                                                0.000902   \n",
      "3.0                                               -0.001578   \n",
      "4.0                                               -0.001798   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_92__attr_\"abs\"  \\\n",
      "id                                                           \n",
      "0.0                                               0.010603   \n",
      "1.0                                               0.006822   \n",
      "2.0                                               0.002875   \n",
      "3.0                                               0.004609   \n",
      "4.0                                               0.007607   \n",
      "\n",
      "variable  SymbolBid__approximate_entropy__m_2__r_0.1  \\\n",
      "id                                                     \n",
      "0.0                                         0.271983   \n",
      "1.0                                         0.203705   \n",
      "2.0                                         0.171262   \n",
      "3.0                                         0.134841   \n",
      "4.0                                         0.102620   \n",
      "\n",
      "variable  SymbolBid__autocorrelation__lag_6  \\\n",
      "id                                            \n",
      "0.0                                0.953972   \n",
      "1.0                                0.981016   \n",
      "2.0                                0.992593   \n",
      "3.0                                0.978870   \n",
      "4.0                                0.990139   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_31__attr_\"abs\"  \\\n",
      "id                                                           \n",
      "0.0                                               0.028388   \n",
      "1.0                                               0.022416   \n",
      "2.0                                               0.015236   \n",
      "3.0                                               0.019007   \n",
      "4.0                                               0.015038   \n",
      "\n",
      "variable  SymbolBid__fft_coefficient__coeff_90__attr_\"abs\"  \\\n",
      "id                                                           \n",
      "0.0                                               0.009544   \n",
      "1.0                                               0.006979   \n",
      "2.0                                               0.005460   \n",
      "3.0                                               0.007829   \n",
      "4.0                                               0.007808   \n",
      "\n",
      "variable  SymbolBid__range_count__max_1__min_-1  \n",
      "id                                               \n",
      "0.0                                         0.0  \n",
      "1.0                                         0.0  \n",
      "2.0                                         0.0  \n",
      "3.0                                         0.0  \n",
      "4.0                                         0.0  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 rows x 36 columns]\n",
      "(1000, 36)\n"
     ]
    }
   ],
   "source": [
    "print(features_filtered.head())\n",
    "print(features_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_from_tsfresh(data, DateTime, SymbolBid):\n",
    "    \n",
    "    # extract featues\n",
    "    nExS = data.nEventsPerStat\n",
    "    mW = data.movingWindow\n",
    "    secsInDay = 86400.0\n",
    "    # return per bid\n",
    "    #returnBid = SymbolBid.iloc[nExS:]-SymbolBid.iloc[:-nExS+1]\n",
    "    nE = SymbolBid.shape[0]\n",
    "    # max number of features\n",
    "    m = int(np.floor((nE/nExS-1)*nExS/mW)+1)\n",
    "    # format TSFRESH input\n",
    "    features = pd.DataFrame()\n",
    "    list_inputs = []\n",
    "    list_DateTime = []\n",
    "    batch_size = 100\n",
    "    par_batches = 1#int(np.ceil(m/batch_size))\n",
    "    l_index = 0\n",
    "    # loop over batched\n",
    "    for b in range(par_batches):\n",
    "        # get m of batch\n",
    "        m_i = np.min([batch_size, m-b*batch_size])\n",
    "        i_range = b*batch_size*nExS\n",
    "        e_range = (b*batch_size+m_i)*nExS\n",
    "        #print(range(i_range,e_range))\n",
    "        print(\"Batch \"+str(b)+\" out of \"+str(par_batches-1))\n",
    "        input_ts = pd.DataFrame(data=0.0,index=range(i_range,e_range),columns=['SymbolBid','id','time'])\n",
    "        datetimes = pd.DataFrame(data='',index=range(i_range,e_range),columns=['DateTime'])\n",
    "        # loop over this batch\n",
    "        for mm in range(m_i):\n",
    "            # get indexes\n",
    "            startIndex = l_index+mm*mW\n",
    "            endIndex = startIndex+nExS\n",
    "            # period range\n",
    "            thisPeriod = range(startIndex,endIndex)\n",
    "            input_ts.SymbolBid.iloc[mm*nExS:(mm+1)*nExS] = SymbolBid[thisPeriod]\n",
    "            datetimes.DateTime.iloc[mm*nExS:(mm+1)*nExS] = DateTime[thisPeriod]\n",
    "            input_ts.id.iloc[mm*nExS:(mm+1)*nExS] = b*batch_size+mm\n",
    "            input_ts.time.iloc[mm*nExS:(mm+1)*nExS] = range(nExS)\n",
    "        l_index = startIndex+mW\n",
    "        #print(input_ts.shape)\n",
    "        #print(input_ts.head())\n",
    "        #print(input_ts.iloc[-1])\n",
    "        #list_inputs.append(input_ts)\n",
    "        #list_DateTime.append(datetimes)\n",
    "        # build feature vector\n",
    "        this_feats = extract_features(input_ts, column_id=\"id\", column_sort=\"time\")\n",
    "        features = features.append(this_feats)\n",
    "        print(features.shape)\n",
    "\n",
    "    # filter features\n",
    "    \n",
    "    # get outputs\n",
    "    init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                separators.DateTime.iloc[0],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "    end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                separators.DateTime.iloc[0+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "    group_name = thisAsset+'/'+init_date+end_date\n",
    "    filename_prep_IO = (hdf5_directory+'IO_mW'+str(data.movingWindow)+'_nE'+\n",
    "                            str(data.nEventsPerStat)+'_nF'+str(data.nFeatures)+'.hdf5')\n",
    "    f_prep_IO = h5py.File(filename_prep_IO,'r')\n",
    "    group = f_prep_IO[group_name]\n",
    "    returns = group['returns']\n",
    "    y = returns[:features.shape[0],data.lookAheadIndex]\n",
    "    # filter features\n",
    "    impute(features)\n",
    "    features_filtered = select_features(features, y)\n",
    "    \n",
    "    print(features_filtered.shape)\n",
    "    \n",
    "    return features_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run get_features_from_tsfresh for all assets and chuncks\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import datetime as dt\n",
    "\n",
    "list_features_filtered = []\n",
    "for ass in data.assets:\n",
    "    thisAsset = data.AllAssets[str(ass)]\n",
    "    print(str(ass)+\". \"+thisAsset)\n",
    "    #tic = time.time()\n",
    "    # open file for read\n",
    "    \n",
    "    group_raw = f_raw[thisAsset]\n",
    "    #bid_means[ass_idx] = np.mean(group_raw[\"SymbolBid\"])\n",
    "    # load separators\n",
    "    separators = load_separators(data, thisAsset, separators_directory, from_txt=1)\n",
    "    # loop over separators\n",
    "    for s in range(0,len(separators)-1,2):\n",
    "        nE = separators.index[s+1]-separators.index[s]+1\n",
    "        # check if number of events is not enough to build two features and one return\n",
    "        if nE>=2*data.nEventsPerStat:\n",
    "            print(\"\\t\"+\" s {0:d} of {1:d}\".format(int(s/2),int(len(separators)/2-1))+\n",
    "                      \". From \"+separators.DateTime.iloc[s]+\" to \"+separators.DateTime.iloc[s+1])\n",
    "            DateTime = group_raw[\"DateTime\"]\n",
    "            SymbolBid = group_raw[\"SymbolBid\"]\n",
    "            SymbolAsk = group_raw[\"SymbolAsk\"]\n",
    "            features_filtered = get_features_from_tsfresh(data, DateTime, SymbolBid)\n",
    "            features_filtered.to_csv('../features/'+thisAsset+'c'+str(int(s/2)))\n",
    "            list_features_filtered.append(features_filtered)\n",
    "        else:\n",
    "            print(\"\\ts {0:d} of {1:d}. Not enough entries. Skipped.\".format(int(s/2),int(len(separators)/2-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AUDCAD\n",
      "\t s 0 of 21. From 2016.01.04 00:00:08 to 2016.10.13 15:41:59\n",
      "Batch 0 out of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 1/1 [00:03<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 794)\n",
      "Batch 1 out of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|████████████████████████| 1/1 [00:03<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 794)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered regression as machine learning task\n",
      "WARNING:tsfresh.feature_selection.relevance:No feature was found relevant for regression for fdr level = 0.05. Consider using a lower fdr level or other features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0)\n"
     ]
    }
   ],
   "source": [
    "# All in one\n",
    "\n",
    "# run get_features_from_tsfresh for all assets and chuncks\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import datetime as dt\n",
    "from inputs import Data, load_separators\n",
    "\n",
    "data = Data(movingWindow=100,nEventsPerStat=1000)\n",
    "\n",
    "# load raw data\n",
    "hdf5_directory = 'D:/SDC/py/HDF5/'\n",
    "filename_raw = hdf5_directory+'tradeinfo.hdf5'\n",
    "separators_directory = hdf5_directory+'separators/'\n",
    "f_raw = h5py.File(filename_raw,'r')\n",
    "\n",
    "filename_prep_IO = (hdf5_directory+'IO_mW'+str(data.movingWindow)+'_nE'+\n",
    "                    str(data.nEventsPerStat)+'_nF'+str(data.nFeatures)+'.hdf5')\n",
    "f_prep_IO = h5py.File(filename_prep_IO,'r')\n",
    "\n",
    "list_features_filtered = []\n",
    "\n",
    "for ass in data.assets[:1]:\n",
    "    thisAsset = data.AllAssets[str(ass)]\n",
    "    print(str(ass)+\". \"+thisAsset)\n",
    "    #tic = time.time()\n",
    "    # open file for read\n",
    "    \n",
    "    group_raw = f_raw[thisAsset]\n",
    "    DateTime = group_raw[\"DateTime\"]\n",
    "    SymbolBid = group_raw[\"SymbolBid\"]\n",
    "    SymbolAsk = group_raw[\"SymbolAsk\"]\n",
    "    #bid_means[ass_idx] = np.mean(group_raw[\"SymbolBid\"])\n",
    "    # load separators\n",
    "    separators = load_separators(data, thisAsset, separators_directory, from_txt=1)\n",
    "    # loop over separators\n",
    "    for s in range(0,1,2):#len(separators)-1\n",
    "        nE = separators.index[s+1]-separators.index[s]+1\n",
    "        # check if number of events is not enough to build two features and one return\n",
    "        if nE>=2*data.nEventsPerStat:\n",
    "            print(\"\\t\"+\" s {0:d} of {1:d}\".format(int(s/2),int(len(separators)/2-1))+\n",
    "                      \". From \"+separators.DateTime.iloc[s]+\" to \"+separators.DateTime.iloc[s+1])\n",
    "            \n",
    "            # get outputs\n",
    "            init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                        separators.DateTime.iloc[s],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "            end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                        separators.DateTime.iloc[s+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "            group_name = thisAsset+'/'+init_date+end_date\n",
    "            \n",
    "            group = f_prep_IO[group_name]\n",
    "            returns = group['returns']\n",
    "            \n",
    "            SB = SymbolBid[separators.index[s]:separators.index[s+1]+1]\n",
    "            DT = DateTime[separators.index[s]:separators.index[s+1]+1]\n",
    "            \n",
    "            # extract featues\n",
    "            nExS = data.nEventsPerStat\n",
    "            mW = data.movingWindow\n",
    "            secsInDay = 86400.0\n",
    "            # return per bid\n",
    "            #returnBid = SymbolBid.iloc[nExS:]-SymbolBid.iloc[:-nExS+1]\n",
    "            nE = SB.shape[0]\n",
    "            # max number of features\n",
    "            m = int(np.floor((nE/nExS-1)*nExS/mW)+1)\n",
    "            # format TSFRESH input\n",
    "            features = pd.DataFrame()\n",
    "            list_inputs = []\n",
    "            list_DateTime = []\n",
    "            batch_size = 1\n",
    "            par_batches = min(int(np.ceil(m/batch_size)),2)\n",
    "            l_index = 0\n",
    "            # loop over batched\n",
    "            for b in range(par_batches):\n",
    "                # get m of batch\n",
    "                m_i = np.min([batch_size, m-b*batch_size])\n",
    "                i_range = b*batch_size*nExS\n",
    "                e_range = (b*batch_size+m_i)*nExS\n",
    "                #print(range(i_range,e_range))\n",
    "                print(\"Batch \"+str(b)+\" out of \"+str(par_batches-1))\n",
    "                input_ts = pd.DataFrame(data=0.0,index=range(i_range,e_range),columns=['SymbolBid','id','time'])\n",
    "                datetimes = pd.DataFrame(data='',index=range(i_range,e_range),columns=['DateTime'])\n",
    "                # loop over this batch\n",
    "                for mm in range(m_i):\n",
    "                    # get indexes\n",
    "                    startIndex = l_index+mm*mW\n",
    "                    endIndex = startIndex+nExS\n",
    "                    # period range\n",
    "                    thisPeriod = range(startIndex,endIndex)\n",
    "                    input_ts.SymbolBid.iloc[mm*nExS:(mm+1)*nExS] = SB[thisPeriod]\n",
    "                    datetimes.DateTime.iloc[mm*nExS:(mm+1)*nExS] = DT[thisPeriod]\n",
    "                    input_ts.id.iloc[mm*nExS:(mm+1)*nExS] = b*batch_size+mm\n",
    "                    input_ts.time.iloc[mm*nExS:(mm+1)*nExS] = range(nExS)\n",
    "                l_index = startIndex+mW\n",
    "                #print(input_ts.shape)\n",
    "                #print(input_ts.head())\n",
    "                #print(input_ts.iloc[-1])\n",
    "                #list_inputs.append(input_ts)\n",
    "                #list_DateTime.append(datetimes)\n",
    "                # build feature vector\n",
    "                this_feats = extract_features(input_ts, column_id=\"id\", column_sort=\"time\")\n",
    "                print(this_feats.shape)\n",
    "                features = features.append(this_feats)\n",
    "                \n",
    "            # filter features\n",
    "            if returns.shape[0]<features.shape[0]:\n",
    "                features = features[:returns.shape[0]-1]\n",
    "            y = returns[:features.shape[0],data.lookAheadIndex]\n",
    "\n",
    "            # filter features\n",
    "            impute(features)\n",
    "            features_filtered = select_features(features, y)\n",
    "\n",
    "            print(features_filtered.shape)\n",
    "            #features_filtered.iloc[:1].to_csv('../features/'+thisAsset+'c'+str(int(s/2))+'.csv')\n",
    "            list_features_filtered.append(features_filtered)\n",
    "        else:\n",
    "            print(\"\\ts {0:d} of {1:d}. Not enough entries. Skipped.\".format(int(s/2),int(len(separators)/2-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "12. GBPCAD\n",
      "\t chuck 0 of 22. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "\t Getting features from raw data...\n",
      "\t batch 0 out of 7\n",
      "\t getting features of GBPCAD/160104000000161013154159/37\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/37 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/38 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/39 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/40 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/41 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/42 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/43 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/44 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/45 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/46 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/47 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/48 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/49 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/50 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/51 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/52 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/53 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/54 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/55 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/56 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/57 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/58 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/59 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/60 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/61 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/62 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/63 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/64 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/65 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/66 found in file. Skipping\n",
      "\t GBPCAD/160104000000161013154159/67 found in file. Skipping\n",
      "\t batch 1 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t batch 2 out of 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-d7d51efb4861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    149\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t getting features of \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgroup_name_feat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                             \u001b[1;32melif\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgroup_name_feat\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" found in file. Skipping\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                             \u001b[0mc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_new_feats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get features from tsfresh tool\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from inputs import Data, load_separators\n",
    "import h5py\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "def feval(funcName, *args):\n",
    "    return eval(funcName)(*args)\n",
    "\n",
    "#def get_features_tsfresh():\n",
    "if 1:\n",
    "    \"\"\"\n",
    "    Extract and save most common features based on TSFRESH tool\n",
    "    \"\"\"\n",
    "    # config stuff\n",
    "    hdf5_directory = 'D:/SDC/py/HDF5/'\n",
    "    save_stats = True\n",
    "    # init stuff\n",
    "    filename_raw = hdf5_directory+'tradeinfo.hdf5'\n",
    "    separators_directory = hdf5_directory+'separators/'\n",
    "    \n",
    "    f_raw = h5py.File(filename_raw,'r')\n",
    "    \n",
    "    data=Data(movingWindow=100,\n",
    "              nEventsPerStat=1000,\n",
    "              dateTest = [                                          '2018.03.09',\n",
    "                '2018.03.12','2018.03.13','2018.03.14','2018.03.15','2018.03.16',\n",
    "                '2018.03.19','2018.03.20','2018.03.21','2018.03.22','2018.03.23',\n",
    "                '2018.03.26','2018.03.27','2018.03.28','2018.03.29','2018.03.30',\n",
    "                '2018.04.02','2018.04.03','2018.04.04','2018.04.05','2018.04.06',\n",
    "                '2018.04.09','2018.04.10','2018.04.11','2018.04.12','2018.04.13',\n",
    "                '2018.04.16','2018.04.17','2018.04.18','2018.04.19','2018.04.20',\n",
    "                '2018.04.23','2018.04.24','2018.04.25','2018.04.26','2018.04.27',\n",
    "                '2018.04.30','2018.05.01','2018.05.02','2018.05.03','2018.05.04',\n",
    "                '2018.05.07','2018.05.08','2018.05.09','2018.05.10','2018.05.11',\n",
    "                '2018.05.14','2018.05.15','2018.05.16','2018.05.17','2018.05.18',\n",
    "                '2018.05.21','2018.05.22','2018.05.23','2018.05.24','2018.05.25',\n",
    "                '2018.05.28','2018.05.29','2018.05.30','2018.05.31','2018.06.01',\n",
    "                '2018.06.04','2018.06.05','2018.06.06','2018.06.07','2018.06.08',\n",
    "                '2018.06.11','2018.06.12','2018.06.13','2018.06.14','2018.06.15',\n",
    "                '2018.06.18','2018.06.19','2018.06.20','2018.06.21','2018.06.22',\n",
    "                '2018.06.25','2018.06.26','2018.06.27','2018.06.28','2018.06.29',\n",
    "                '2018.07.02','2018.07.03','2018.07.04','2018.07.05','2018.07.06',\n",
    "                '2018.07.09','2018.07.10','2018.07.11','2018.07.12','2018.07.13',\n",
    "                '2018.07.30','2018.07.31','2018.08.01','2018.08.02','2018.08.03',\n",
    "                '2018.08.06','2018.08.07','2018.08.08','2018.08.09','2018.08.10']+\n",
    "               ['2018.08.13','2018.08.14','2018.08.15','2018.08.16','2018.08.17',\n",
    "                '2018.08.20','2018.08.21','2018.08.22','2018.08.23','2018.08.24',\n",
    "                '2018.08.27','2018.08.28','2018.08.29','2018.08.30','2018.08.31',\n",
    "                '2018.09.03','2018.09.04','2018.09.05','2018.09.06','2018.09.07',\n",
    "                '2018.09.10','2018.09.11','2018.09.12','2018.09.13','2018.09.14',\n",
    "                '2018.09.17','2018.09.18','2018.09.19','2018.09.20','2018.09.21',\n",
    "                '2018.09.24','2018.09.25','2018.09.26','2018.09.27'])\n",
    "    filename_features_tsf = (hdf5_directory+'feats_tsf_mW'+str(data.movingWindow)+'_nE'+\n",
    "                            str(data.nEventsPerStat)+'.hdf5')\n",
    "    batch_size = 50000\n",
    "    window_size = data.nEventsPerStat\n",
    "    sprite_length = data.movingWindow\n",
    "    nMaxChannels = int(window_size/sprite_length)\n",
    "    features_tsfresh = data.feature_keys_tsfresh\n",
    "    n_feats_tsfresh = data.n_feats_tsfresh\n",
    "    file_features_tsf = h5py.File(filename_features_tsf,'a')\n",
    "    tic_t = time.time()\n",
    "    # run over assets\n",
    "    for ass in data.assets[8:9]:\n",
    "        tic_ass = time.time()\n",
    "        # retrieve this asset's name\n",
    "        thisAsset = data.AllAssets[str(ass)]\n",
    "        print(str(ass)+\". \"+thisAsset)\n",
    "        # load separators\n",
    "        separators = load_separators(data, thisAsset, \n",
    "                                     separators_directory, \n",
    "                                     from_txt=1)\n",
    "        # get raw data\n",
    "        SymbolBid = f_raw[thisAsset][\"SymbolBid\"]\n",
    "        # init normalization stats\n",
    "        stats = {\"means_t_in\":np.zeros((nMaxChannels,n_feats_tsfresh)),\n",
    "                \"stds_t_in\":np.zeros((nMaxChannels,n_feats_tsfresh)),\n",
    "                \"m_t_in\":0}\n",
    "        # run over separators\n",
    "        for s in range(0,len(separators)-1,2):#\n",
    "            tic = time.time()\n",
    "            print(\"\\t chuck {0:d} of {1:d}\".format(int(s/2),int(len(separators)/2-1))+\n",
    "                      \". From \"+separators.DateTime.iloc[s]+\" to \"+separators.DateTime.iloc[s+1])\n",
    "            \n",
    "            # number of events in this chunck\n",
    "            n_events = separators.index[s+1]-separators.index[s]+1\n",
    "            if n_events>=2*window_size:\n",
    "                print(\"\\t Getting features from raw data...\")\n",
    "                tic = time.time()\n",
    "                tic_chunck = tic\n",
    "                # init and end dates in string format\n",
    "                init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                        separators.DateTime.iloc[s],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "                end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                        separators.DateTime.iloc[s+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "                # hdf5 group name\n",
    "                group_name_chunck = thisAsset+'/'+init_date+end_date\n",
    "                # create or retrieve group\n",
    "                # create new gruop if not yet in file\n",
    "                # bids in this chunck\n",
    "                events = SymbolBid[separators.index[s]:separators.index[s+1]+1]\n",
    "                # number of samples\n",
    "                m = int(np.floor((n_events/window_size-1)*window_size/sprite_length)+1)\n",
    "                # group ts in m chunks\n",
    "                # number of batches\n",
    "                batches = int(np.ceil(m/batch_size))\n",
    "                l_index = 0\n",
    "                m_counter = 0\n",
    "                features = np.zeros((m,n_feats_tsfresh))\n",
    "                # loop over batched\n",
    "                for b in range(batches):\n",
    "                    print(\"\\t batch \"+str(b)+\" out of \"+str(batches-1))\n",
    "                    # get batch size\n",
    "                    m_i = np.min([batch_size, m-b*batch_size])\n",
    "                    #print(\"Batch \"+str(b)+\" out of \"+str(batches-1)+\", m_i=\"+str(m_i))\n",
    "                    # init and end of event index\n",
    "                    i_event = l_index\n",
    "                    e_event = i_event+(m_i-1)*sprite_length+window_size\n",
    "                    # init and position of the batch\n",
    "                    i_batch = b*batch_size*window_size\n",
    "                    e_batch = (b*batch_size+m_i)*window_size\n",
    "                    # serial input\n",
    "                    x_ser = events[i_event:e_event]\n",
    "                    #print(\"x_ser length=\"+str(x_ser.shape[0]))\n",
    "                    # loop over this batch samples\n",
    "                    for mm in range(m_i):\n",
    "                        # get sample indexes\n",
    "                        i_sample = mm*sprite_length\n",
    "                        e_sample = i_sample+window_size\n",
    "                        #print(\"i_sample=\"+str(i_sample)+\" e_sample=\"+str(e_sample))\n",
    "                        x = x_ser[i_sample:e_sample]\n",
    "                        c = 0\n",
    "                        # extract features\n",
    "                        for f in features_tsfresh:\n",
    "                            group_name_feat = group_name_chunck+'/'+str(f)\n",
    "                            params = data.AllFeatures[str(f)]\n",
    "                            n_new_feats = params[-1]\n",
    "                            if group_name_feat not in file_features_tsf:\n",
    "                                params = data.AllFeatures[str(f)]\n",
    "                                new_feats = feval(params[0],x,params[1:])\n",
    "                                n_new_feats = params[-1]\n",
    "                                features[m_counter,c:c+n_new_feats] = new_feats                                \n",
    "                                if b==0 and mm<10:\n",
    "                                    print(\"\\t getting features of \"+group_name_feat)\n",
    "                            elif b==0 and mm<10:\n",
    "                                print(\"\\t \"+group_name_feat+\" found in file. Skipping\")\n",
    "                            c += n_new_feats\n",
    "                        #assert(c==n_feats_tsfresh)\n",
    "                        m_counter += 1\n",
    "                    # serial loop\n",
    "                    l_index = e_event-window_size+sprite_length\n",
    "                # end of for b in range(batches):\n",
    "                print(\"\\t time for feature extraction: \"+str(time.time()-tic))\n",
    "                #print(\"\\r\"+\"e_event=\"+str(e_event)+\" events=\"+str(events.shape[0]))#, sep=' ', end='\\n', flush=True\n",
    "                \n",
    "                c = 0\n",
    "                # save features in HDF5 file\n",
    "                for f in features_tsfresh:\n",
    "                    group_name_feat = group_name_chunck+'/'+str(f)\n",
    "                    params = data.AllFeatures[str(f)]\n",
    "                    n_new_feats = params[-1]\n",
    "                    #if group_name_feat in file_features_tsf:\n",
    "                    #    del file_features_tsf[group_name_feat]\n",
    "                    if group_name_feat not in file_features_tsf:\n",
    "                        group_chunck = file_features_tsf.create_group(group_name_feat)\n",
    "                        group_features = group_chunck.create_dataset(\"feature\", (m,n_new_feats),dtype=float)\n",
    "                        group_features[:,:] = features[:,c:c+n_new_feats]\n",
    "                        file_features_tsf.flush()\n",
    "                        print(group_name_feat+\" saved in file\")\n",
    "                    else: # load features from HDF5 file if they are saved already\n",
    "                        success = False\n",
    "                        tries = 0\n",
    "                        while not success and tries<10:\n",
    "                            try:\n",
    "                                group_chunck = file_features_tsf[group_name_feat]\n",
    "                                print(\"features from \"+group_name_feat+\" loaded\")\n",
    "                                success = True\n",
    "                            except KeyError:\n",
    "                                print(\"KeyError reading \"+group_name_feat)\n",
    "                                tries += 1\n",
    "                        if not success:\n",
    "                            raise KeyError(group_name_feat+\" File corrupted. Delete and retrieve again\")\n",
    "                            \n",
    "                        features[:,c:c+n_new_feats] = group_chunck[\"feature\"]\n",
    "                    c += n_new_feats\n",
    "                # end of for f in features_tsfresh:\n",
    "                # Calculate normalization stats\n",
    "                tic = time.time()\n",
    "                # open temporal file for variations\n",
    "                try:\n",
    "                    # create file\n",
    "                    ft = h5py.File(hdf5_directory+'temp.hdf5','w')\n",
    "                    # create group\n",
    "                    group_temp = ft.create_group('temp')\n",
    "                    # reserve memory space for variations and normalized variations\n",
    "                    variations = group_temp.create_dataset(\"variations\", (features.shape[0],features.shape[1],nMaxChannels), \n",
    "                                                           dtype=float)\n",
    "                    print(\"\\t getting variations\")\n",
    "                    # loop over channels\n",
    "                    for r in range(nMaxChannels):\n",
    "                        variations[r+1:,:,r] = features[:-(r+1),:]\n",
    "                    print(\"\\t time for variations: \"+str(time.time()-tic))\n",
    "                    # init stats    \n",
    "                    means_in = np.zeros((nMaxChannels,features.shape[1]))\n",
    "                    stds_in = np.zeros((nMaxChannels,features.shape[1]))\n",
    "                    print(\"\\t getting means and stds\")\n",
    "                    # loop over channels\n",
    "                    for r in range(nMaxChannels):\n",
    "                        #nonZeros = variations[:,0,r]!=999\n",
    "                        #print(np.sum(nonZeros))\n",
    "                        means_in[r,:] = np.mean(variations[nMaxChannels:,:,r],axis=0,keepdims=1)\n",
    "                        stds_in[r,:] = np.std(variations[nMaxChannels:,:,r],axis=0,keepdims=1)  \n",
    "                    print(\"\\t time for stats: \"+str(time.time()-tic))\n",
    "                except KeyboardInterrupt:\n",
    "                    ft.close()\n",
    "                    print(\"KeyboardInterrupt! Closing file and exiting.\")\n",
    "                    raise KeyboardInterrupt\n",
    "                ft.close()\n",
    "                # end of normalization stats\n",
    "                # save normalization stats\n",
    "                for f in features_tsfresh:\n",
    "                    group_name_feat = group_name_chunck+'/'+str(f)\n",
    "                    n_new_feats = data.AllFeatures[str(f)][-1]\n",
    "                    group_feature = file_features_tsf[group_name_feat]\n",
    "                    # save means and variances as atributes\n",
    "                    group_feature.attrs.create(\"means_in\", means_in[:,c:c+n_new_feats], dtype=float)\n",
    "                    group_feature.attrs.create(\"stds_in\", stds_in[:,c:c+n_new_feats], dtype=float)\n",
    "                    c += n_new_feats\n",
    "                # update total stats\n",
    "                stats[\"means_t_in\"] += m*means_in\n",
    "                stats[\"stds_t_in\"] += m*stds_in\n",
    "                stats[\"m_t_in\"] += m\n",
    "                means_in\n",
    "                print(\"\\t this chunck time: \"+str(np.floor(time.time()-tic_chunck))+\"s\")\n",
    "            else:\n",
    "                print(\"\\t chunck {0:d} of {1:d}. Not enough entries. Skipped.\".format(int(s/2),int(len(separators)/2-1)))\n",
    "            # end of if n_events>=2*window_size:\n",
    "        # end of for s in range(0,len(separators)-1,2):\n",
    "        means_t_in = stats[\"means_t_in\"]/stats[\"m_t_in\"]\n",
    "        stds_t_in = stats[\"stds_t_in\"]/stats[\"m_t_in\"]\n",
    "        if save_stats:\n",
    "            c = 0\n",
    "            for f in features_tsfresh:\n",
    "                group_name_feat = thisAsset\n",
    "                n_new_feats = data.AllFeatures[str(f)][-1]\n",
    "                group_feature = file_features_tsf[group_name_feat]\n",
    "                # save means and variances as atributes\n",
    "                group_feature.attrs.create(\"means_in\"+str(f), means_t_in[:,c:c+n_new_feats], dtype=float)\n",
    "                group_feature.attrs.create(\"stds_in\"+str(f), stds_t_in[:,c:c+n_new_feats], dtype=float)\n",
    "                c += n_new_feats\n",
    "        print(\"\\t this asset time: \"+str(np.floor(time.time()-tic_ass)/60)+\" minutes\")\n",
    "    # end of for ass in data.assets:\n",
    "    file_features_tsf.close()\n",
    "    print(\"DONE. Total time: \"+str(np.floor(time.time()-tic_t)/60)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AUDCAD\n",
      "\t chuck 0 of 21. From 2016.01.04 00:00:08 to 2016.10.13 15:41:59\n",
      "\t chuck 1 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 2 of 21. From 2016.12.26 06:00:00 to 2016.12.30 23:58:30\n",
      "\t chuck 3 of 21. From 2017.01.02 09:00:00 to 2017.01.26 23:59:59\n",
      "\t chuck 4 of 21. From 2017.01.30 00:05:00 to 2017.09.05 23:59:59\n",
      "\t chuck 5 of 21. From 2017.09.06 20:25:01 to 2017.11.10 09:38:15\n",
      "KeyError: Unable to open object (Corrupt object header) AUDCAD/170906202501171110093815/38\n",
      "<HDF5 dataset \"feature\": shape (31806, 1), type \"<f8\">\n",
      "\t chuck 6 of 21. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:07\n",
      "\t chuck 9 of 21. From 2017.12.12 09:55:53 to 2017.12.22 23:58:59\n",
      "\t chuck 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:42\n",
      "\t chuck 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:25:25\n",
      "\t chuck 12 of 21. From 2018.01.11 14:39:34 to 2018.01.25 08:17:37\n",
      "\t chuck 13 of 21. From 2018.01.25 08:53:48 to 2018.03.08 23:58:59\n",
      "\t chuck 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t chuck 15 of 21. From 2018.03.20 05:44:39 to 2018.04.12 09:26:13\n",
      "\t chuck 16 of 21. From 2018.04.12 10:00:43 to 2018.05.08 03:27:47\n",
      "\t chuck 17 of 21. From 2018.05.08 04:24:14 to 2018.07.13 23:59:56\n",
      "\t chuck 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 21 of 21. From 2018.08.27 19:03:29 to 2018.09.27 23:58:58\n",
      "2. EURAUD\n",
      "\t chuck 0 of 31. From 2016.01.04 00:02:59 to 2016.04.22 23:59:59\n",
      "\t chuck 1 of 31. From 2016.04.25 03:00:00 to 2016.06.09 11:59:59\n",
      "\t chuck 2 of 31. From 2016.06.09 12:22:30 to 2016.11.04 22:54:59\n",
      "\t chuck 3 of 31. From 2016.11.07 01:27:12 to 2016.11.07 23:59:59\n",
      "\t chuck 4 of 31. From 2016.11.09 13:29:47 to 2016.11.11 23:54:59\n",
      "\t chuck 5 of 31. From 2016.11.18 00:05:14 to 2016.12.23 23:54:59\n",
      "\t chuck 6 of 31. From 2016.12.26 09:00:00 to 2016.12.26 11:40:30\n",
      "\t chuck 7 of 31. From 2016.12.26 12:06:59 to 2016.12.26 15:17:59\n",
      "\t chuck 9 of 31. From 2016.12.26 19:42:30 to 2016.12.29 23:59:59\n",
      "\t chuck 10 of 31. From 2017.01.02 00:02:30 to 2017.04.25 16:55:09\n",
      "\t chuck 11 of 31. From 2017.04.27 12:00:16 to 2017.07.20 00:03:59\n",
      "\t chuck 12 of 31. From 2017.07.20 00:25:00 to 2017.09.05 02:36:00\n",
      "\t chuck 15 of 31. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t chuck 16 of 31. From 2017.11.10 10:05:51 to 2017.11.24 23:58:59\n",
      "\t chuck 17 of 31. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 18 of 31. From 2017.12.11 00:05:00 to 2017.12.12 04:13:03\n",
      "\t chuck 19 of 31. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t chuck 20 of 31. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 21 of 31. From 2018.01.02 03:00:00 to 2018.01.10 21:30:14\n",
      "\t chuck 22 of 31. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 23 of 31. From 2018.01.25 08:49:52 to 2018.03.08 07:51:45\n",
      "\t chuck 24 of 31. From 2018.03.09 00:05:00 to 2018.03.20 05:04:46\n",
      "\t chuck 25 of 31. From 2018.03.20 05:44:29 to 2018.04.12 09:26:15\n",
      "\t chuck 26 of 31. From 2018.04.12 09:59:08 to 2018.05.08 03:27:55\n",
      "\t chuck 27 of 31. From 2018.05.08 04:24:14 to 2018.07.13 23:59:57\n",
      "\t chuck 28 of 31. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 29 of 31. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t chuck 30 of 31. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 31 of 31. From 2018.08.27 19:03:32 to 2018.09.27 23:58:54\n",
      "3. EURCAD\n",
      "\t chuck 0 of 23. From 2016.01.04 00:00:00 to 2016.01.11 00:17:59\n",
      "\t chuck 1 of 23. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 23. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 23. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t chuck 4 of 23. From 2017.01.02 00:01:00 to 2017.08.24 23:44:59\n",
      "\t chuck 5 of 23. From 2017.08.28 00:05:02 to 2017.09.05 02:35:52\n",
      "\t chuck 7 of 23. From 2017.09.05 09:45:51 to 2017.11.10 09:38:15\n",
      "\t chuck 8 of 23. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t chuck 9 of 23. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 10 of 23. From 2017.12.11 00:05:00 to 2017.12.12 04:13:04\n",
      "\t chuck 11 of 23. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t chuck 12 of 23. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 13 of 23. From 2018.01.02 03:00:00 to 2018.01.10 21:19:40\n",
      "\t chuck 14 of 23. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 15 of 23. From 2018.01.25 09:10:26 to 2018.03.07 23:58:59\n",
      "\t chuck 16 of 23. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t chuck 17 of 23. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t chuck 18 of 23. From 2018.04.12 09:59:08 to 2018.05.08 03:27:46\n",
      "\t chuck 19 of 23. From 2018.05.08 04:24:14 to 2018.07.13 23:59:55\n",
      "\t chuck 20 of 23. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 21 of 23. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 22 of 23. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 23 of 23. From 2018.08.27 19:03:29 to 2018.09.27 23:58:59\n",
      "4. EURCHF\n",
      "\t chuck 0 of 28. From 2016.01.04 00:00:00 to 2016.01.11 00:20:59\n",
      "\t chuck 1 of 28. From 2016.01.11 01:00:00 to 2016.08.15 00:08:59\n",
      "\t chuck 2 of 28. From 2016.08.15 00:29:00 to 2016.10.13 15:41:59\n",
      "\t chuck 3 of 28. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 4 of 28. From 2016.12.26 06:00:00 to 2017.08.11 23:59:59\n",
      "\t chuck 5 of 28. From 2017.08.14 19:30:49 to 2017.08.14 23:58:59\n",
      "\t chuck 6 of 28. From 2017.08.15 02:21:35 to 2017.08.15 20:17:18\n",
      "\t chuck 7 of 28. From 2017.08.15 05:00:06 to 2017.08.15 12:51:32\n",
      "\t chuck 8 of 28. From 2017.08.15 20:17:22 to 2017.08.17 23:58:50\n",
      "\t chuck 9 of 28. From 2017.08.21 00:05:08 to 2017.08.25 19:54:33\n",
      "\t chuck 10 of 28. From 2017.08.28 00:05:02 to 2017.09.05 02:35:52\n",
      "\t chuck 12 of 28. From 2017.09.05 09:45:51 to 2017.11.10 09:38:15\n",
      "\t chuck 13 of 28. From 2017.11.10 10:05:51 to 2017.11.24 23:58:59\n",
      "\t chuck 14 of 28. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 15 of 28. From 2017.12.11 00:05:00 to 2017.12.12 04:12:53\n",
      "\t chuck 16 of 28. From 2017.12.12 10:13:34 to 2017.12.22 23:58:52\n",
      "\t chuck 17 of 28. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t chuck 18 of 28. From 2018.01.02 03:00:00 to 2018.01.10 20:51:51\n",
      "\t chuck 19 of 28. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 20 of 28. From 2018.01.25 09:10:27 to 2018.03.07 23:58:59\n",
      "\t chuck 21 of 28. From 2018.03.09 00:05:00 to 2018.03.20 05:04:42\n",
      "\t chuck 22 of 28. From 2018.03.20 05:44:29 to 2018.04.12 09:26:15\n",
      "\t chuck 23 of 28. From 2018.04.12 09:59:09 to 2018.05.08 03:27:51\n",
      "\t chuck 24 of 28. From 2018.05.08 04:24:15 to 2018.07.13 23:59:04\n",
      "\t chuck 25 of 28. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 26 of 28. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 27 of 28. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 28 of 28. From 2018.08.27 19:03:32 to 2018.09.27 23:58:58\n",
      "7. EURGBP\n",
      "\t chuck 0 of 21. From 2017.01.02 00:00:30 to 2017.08.14 23:45:59\n",
      "\t chuck 1 of 21. From 2017.08.15 02:30:32 to 2017.08.17 23:58:59\n",
      "\t chuck 2 of 21. From 2017.08.21 00:05:08 to 2017.08.25 19:58:59\n",
      "\t chuck 3 of 21. From 2017.08.28 00:05:01 to 2017.09.05 02:36:00\n",
      "\t chuck 5 of 21. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t chuck 6 of 21. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:09\n",
      "\t chuck 9 of 21. From 2017.12.12 10:13:34 to 2017.12.22 23:58:50\n",
      "\t chuck 10 of 21. From 2017.12.26 03:00:01 to 2017.12.29 23:58:57\n",
      "\t chuck 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:29:03\n",
      "\t chuck 12 of 21. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 13 of 21. From 2018.01.25 09:10:26 to 2018.03.07 23:58:59\n",
      "\t chuck 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:41\n",
      "\t chuck 15 of 21. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t chuck 16 of 21. From 2018.04.12 09:59:08 to 2018.05.08 03:27:48\n",
      "\t chuck 17 of 21. From 2018.05.08 04:24:15 to 2018.07.13 23:59:06\n",
      "\t chuck 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 21 of 21. From 2018.08.27 19:03:32 to 2018.09.27 23:58:56\n",
      "8. EURNZD\n",
      "\t chuck 0 of 29. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 1 of 29. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 2 of 29. From 2016.12.26 06:00:00 to 2016.12.30 23:58:02\n",
      "\t chuck 3 of 29. From 2017.03.08 00:01:00 to 2017.03.17 22:54:59\n",
      "\t chuck 4 of 29. From 2017.03.20 01:08:01 to 2017.03.24 22:59:59\n",
      "\t chuck 5 of 29. From 2017.03.27 01:18:09 to 2017.03.27 23:59:59\n",
      "\t chuck 6 of 29. From 2017.03.28 02:31:26 to 2017.03.28 23:59:59\n",
      "\t chuck 7 of 29. From 2017.03.29 02:09:06 to 2017.03.30 23:59:59\n",
      "\t chuck 8 of 29. From 2017.03.31 02:39:18 to 2017.03.31 23:59:59\n",
      "\t chuck 9 of 29. From 2017.04.03 02:27:33 to 2017.04.03 23:59:59\n",
      "\t chuck 10 of 29. From 2017.04.04 02:32:37 to 2017.07.14 00:04:30\n",
      "\t chuck 11 of 29. From 2017.07.14 00:27:00 to 2017.09.05 02:36:00\n",
      "\t chuck 13 of 29. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t chuck 14 of 29. From 2017.11.10 10:05:51 to 2017.11.24 23:58:57\n",
      "\t chuck 15 of 29. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 16 of 29. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t chuck 17 of 29. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t chuck 18 of 29. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t chuck 19 of 29. From 2018.01.02 03:00:00 to 2018.01.10 21:13:01\n",
      "\t chuck 20 of 29. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 21 of 29. From 2018.01.25 09:10:27 to 2018.03.07 23:58:59\n",
      "\t chuck 22 of 29. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t chuck 23 of 29. From 2018.03.20 05:44:28 to 2018.04.12 09:26:15\n",
      "\t chuck 24 of 29. From 2018.04.12 09:59:09 to 2018.05.08 03:27:49\n",
      "\t chuck 25 of 29. From 2018.05.08 04:24:15 to 2018.07.13 23:59:10\n",
      "\t chuck 26 of 29. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 27 of 29. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t chuck 28 of 29. From 2018.08.23 13:14:34 to 2018.08.24 23:58:51\n",
      "\t chuck 29 of 29. From 2018.08.27 19:03:32 to 2018.09.27 23:58:59\n",
      "10. EURUSD\n",
      "\t chuck 0 of 27. From 2016.01.04 00:03:00 to 2016.04.22 23:59:59\n",
      "\t chuck 1 of 27. From 2016.04.25 03:00:00 to 2016.06.09 11:59:59\n",
      "\t chuck 2 of 27. From 2016.06.09 12:22:00 to 2016.12.23 23:54:59\n",
      "\t chuck 3 of 27. From 2016.12.26 09:00:59 to 2017.01.11 18:42:20\n",
      "\t chuck 4 of 27. From 2017.01.12 00:00:00 to 2017.01.26 23:59:59\n",
      "\t chuck 5 of 27. From 2017.03.01 00:00:00 to 2017.08.11 23:59:59\n",
      "\t chuck 6 of 27. From 2017.08.14 12:28:53 to 2017.08.14 23:58:59\n",
      "\t chuck 7 of 27. From 2017.08.15 14:07:41 to 2017.08.25 20:06:23\n",
      "\t chuck 8 of 27. From 2017.08.28 00:05:02 to 2017.09.05 02:36:01\n",
      "\t chuck 10 of 27. From 2017.09.05 09:45:50 to 2017.10.23 01:59:34\n",
      "\t chuck 11 of 27. From 2017.10.23 02:33:26 to 2017.11.10 09:38:15\n",
      "\t chuck 12 of 27. From 2017.11.10 10:05:52 to 2017.11.24 23:58:33\n",
      "\t chuck 13 of 27. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 14 of 27. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t chuck 15 of 27. From 2017.12.12 10:13:34 to 2017.12.22 23:58:58\n",
      "\t chuck 16 of 27. From 2017.12.26 03:00:00 to 2017.12.29 23:58:57\n",
      "\t chuck 17 of 27. From 2018.01.02 03:00:00 to 2018.01.10 21:08:57\n",
      "\t chuck 18 of 27. From 2018.01.11 14:39:29 to 2018.01.25 08:17:37\n",
      "\t chuck 19 of 27. From 2018.01.25 08:49:52 to 2018.03.08 23:58:59\n",
      "\t chuck 20 of 27. From 2018.03.09 00:05:00 to 2018.03.20 05:04:41\n",
      "\t chuck 21 of 27. From 2018.03.20 05:44:29 to 2018.04.12 09:26:15\n",
      "\t chuck 22 of 27. From 2018.04.12 09:59:08 to 2018.05.08 03:27:51\n",
      "\t chuck 23 of 27. From 2018.05.08 04:24:15 to 2018.07.13 23:59:56\n",
      "\t chuck 24 of 27. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 25 of 27. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 26 of 27. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 27 of 27. From 2018.08.27 19:03:31 to 2018.09.27 23:58:53\n",
      "11. GBPAUD\n",
      "\t chuck 0 of 21. From 2016.01.04 00:00:30 to 2016.10.13 15:41:59\n",
      "Group GBPAUD/160104000030161013154159/37 not in file\n",
      "\t chuck 1 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 2 of 21. From 2016.12.26 06:00:00 to 2017.06.08 23:59:59\n",
      "\t chuck 3 of 21. From 2017.06.12 00:05:00 to 2017.07.20 00:03:59\n",
      "\t chuck 4 of 21. From 2017.07.20 00:24:30 to 2017.09.05 23:44:35\n",
      "\t chuck 5 of 21. From 2017.09.05 10:03:57 to 2017.11.10 09:38:15\n",
      "\t chuck 6 of 21. From 2017.11.10 10:05:54 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:12:53\n",
      "\t chuck 9 of 21. From 2017.12.12 10:13:38 to 2017.12.22 23:58:59\n",
      "\t chuck 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:09:22\n",
      "\t chuck 12 of 21. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 13 of 21. From 2018.01.25 09:10:26 to 2018.03.08 23:58:59\n",
      "\t chuck 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t chuck 15 of 21. From 2018.03.20 05:44:32 to 2018.04.12 09:26:16\n",
      "\t chuck 16 of 21. From 2018.04.12 09:59:08 to 2018.05.08 03:27:53\n",
      "\t chuck 17 of 21. From 2018.05.08 04:24:12 to 2018.07.13 23:59:11\n",
      "\t chuck 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 21 of 21. From 2018.08.27 19:03:29 to 2018.09.27 23:58:56\n",
      "12. GBPCAD\n",
      "\t chuck 0 of 22. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "Group GBPCAD/160104000000161013154159/37 not in file\n",
      "\t chuck 1 of 22. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 2 of 22. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t chuck 3 of 22. From 2017.01.02 00:01:00 to 2017.06.08 23:59:59\n",
      "\t chuck 4 of 22. From 2017.06.12 00:03:00 to 2017.09.04 23:45:30\n",
      "\t chuck 5 of 22. From 2017.09.05 10:04:17 to 2017.11.10 09:38:15\n",
      "\t chuck 6 of 22. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 22. From 2017.11.27 00:05:00 to 2017.12.08 23:58:58\n",
      "\t chuck 8 of 22. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t chuck 9 of 22. From 2017.12.12 10:13:38 to 2017.12.22 23:58:59\n",
      "\t chuck 10 of 22. From 2017.12.26 03:00:00 to 2017.12.29 23:58:55\n",
      "\t chuck 11 of 22. From 2018.01.02 03:00:00 to 2018.01.10 21:17:35\n",
      "\t chuck 12 of 22. From 2018.01.11 14:39:29 to 2018.01.25 08:17:37\n",
      "\t chuck 13 of 22. From 2018.01.25 09:10:27 to 2018.03.08 23:58:59\n",
      "\t chuck 14 of 22. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t chuck 15 of 22. From 2018.03.20 05:44:33 to 2018.04.12 09:26:16\n",
      "\t chuck 16 of 22. From 2018.04.12 09:59:08 to 2018.05.08 03:27:47\n",
      "\t chuck 17 of 22. From 2018.05.08 04:24:14 to 2018.06.22 15:30:01\n",
      "\t chuck 18 of 22. From 2018.06.22 16:46:00 to 2018.07.13 23:59:10\n",
      "\t chuck 19 of 22. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 20 of 22. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 21 of 22. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 22 of 22. From 2018.08.27 19:03:29 to 2018.09.27 23:58:58\n",
      "13. GBPCHF\n",
      "\t chuck 0 of 21. From 2016.01.04 00:00:30 to 2016.10.13 15:41:59\n",
      "Group GBPCHF/160104000030161013154159/37 not in file\n",
      "\t chuck 1 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:58:59\n",
      "\t chuck 2 of 21. From 2016.12.26 06:00:00 to 2017.07.17 18:51:04\n",
      "\t chuck 3 of 21. From 2017.07.18 08:25:27 to 2017.07.18 23:45:30\n",
      "\t chuck 4 of 21. From 2017.07.19 02:07:47 to 2017.09.04 23:45:59\n",
      "\t chuck 5 of 21. From 2017.09.05 10:04:57 to 2017.11.10 09:38:15\n",
      "\t chuck 6 of 21. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:02\n",
      "\t chuck 9 of 21. From 2017.12.12 10:13:40 to 2017.12.22 23:58:59\n",
      "\t chuck 10 of 21. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t chuck 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:16:30\n",
      "\t chuck 12 of 21. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 13 of 21. From 2018.01.25 08:51:08 to 2018.03.08 23:58:59\n",
      "\t chuck 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:44\n",
      "\t chuck 15 of 21. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t chuck 16 of 21. From 2018.04.12 09:59:10 to 2018.05.08 03:27:54\n",
      "\t chuck 17 of 21. From 2018.05.08 04:24:15 to 2018.07.13 23:58:58\n",
      "\t chuck 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 21 of 21. From 2018.08.27 19:03:29 to 2018.09.27 23:58:57\n",
      "14. GBPUSD\n",
      "\t chuck 0 of 26. From 2016.01.04 00:00:30 to 2016.10.13 15:41:59\n",
      "Group GBPUSD/160104000030161013154159/37 not in file\n",
      "\t chuck 1 of 26. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 2 of 26. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t chuck 3 of 26. From 2017.01.02 00:01:30 to 2017.04.10 02:14:15\n",
      "\t chuck 4 of 26. From 2017.07.10 00:03:00 to 2017.08.11 23:59:59\n",
      "\t chuck 5 of 26. From 2017.08.14 19:30:24 to 2017.08.14 23:58:59\n",
      "\t chuck 6 of 26. From 2017.08.15 04:16:31 to 2017.08.17 23:58:59\n",
      "\t chuck 7 of 26. From 2017.08.23 00:05:18 to 2017.08.25 20:08:31\n",
      "\t chuck 8 of 26. From 2017.08.28 00:05:02 to 2017.09.05 02:36:00\n",
      "\t chuck 10 of 26. From 2017.09.05 09:45:50 to 2017.11.10 09:38:15\n",
      "\t chuck 11 of 26. From 2017.11.10 10:05:51 to 2017.11.24 23:58:59\n",
      "\t chuck 12 of 26. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 13 of 26. From 2017.12.11 00:05:00 to 2017.12.12 04:13:07\n",
      "\t chuck 14 of 26. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t chuck 15 of 26. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t chuck 16 of 26. From 2018.01.02 03:00:00 to 2018.01.10 21:13:19\n",
      "\t chuck 17 of 26. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 18 of 26. From 2018.01.25 08:53:48 to 2018.03.08 23:58:58\n",
      "\t chuck 19 of 26. From 2018.03.09 00:05:00 to 2018.03.20 05:04:43\n",
      "\t chuck 20 of 26. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t chuck 21 of 26. From 2018.04.12 09:59:08 to 2018.05.08 03:27:55\n",
      "\t chuck 22 of 26. From 2018.05.08 04:24:12 to 2018.07.13 23:59:57\n",
      "\t chuck 23 of 26. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 24 of 26. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 25 of 26. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 26 of 26. From 2018.08.27 19:03:29 to 2018.09.27 23:58:56\n",
      "15. GOLD\n",
      "\t chuck 0 of 20. From 2017.09.13 19:06:47 to 2017.11.03 22:58:52\n",
      "Group GOLD/170913190647171103225852/37 not in file\n",
      "\t chuck 1 of 20. From 2017.11.06 01:01:00 to 2017.11.10 09:38:15\n",
      "\t chuck 2 of 20. From 2017.11.10 10:05:54 to 2017.11.23 19:45:52\n",
      "\t chuck 3 of 20. From 2017.11.24 01:00:03 to 2017.11.24 19:29:59\n",
      "\t chuck 4 of 20. From 2017.11.27 01:01:00 to 2017.12.08 23:58:57\n",
      "\t chuck 5 of 20. From 2017.12.11 01:00:59 to 2017.12.12 04:13:05\n",
      "\t chuck 6 of 20. From 2017.12.12 09:49:50 to 2017.12.22 23:58:58\n",
      "\t chuck 7 of 20. From 2017.12.26 03:00:00 to 2017.12.29 23:58:49\n",
      "\t chuck 8 of 20. From 2018.01.02 03:00:00 to 2018.01.10 21:10:22\n",
      "\t chuck 9 of 20. From 2018.01.11 14:39:29 to 2018.01.15 19:59:58\n",
      "\t chuck 10 of 20. From 2018.01.16 01:00:02 to 2018.01.25 08:17:38\n",
      "\t chuck 11 of 20. From 2018.01.25 09:10:27 to 2018.02.19 19:59:59\n",
      "\t chuck 12 of 20. From 2018.02.20 01:00:04 to 2018.03.08 23:58:52\n",
      "\t chuck 13 of 20. From 2018.03.09 01:00:00 to 2018.03.16 22:58:57\n",
      "\t chuck 14 of 20. From 2018.03.19 01:00:00 to 2018.03.20 05:04:41\n",
      "\t chuck 15 of 20. From 2018.03.20 05:44:33 to 2018.03.23 22:58:57\n",
      "\t chuck 16 of 20. From 2018.03.26 01:00:59 to 2018.03.29 23:58:56\n",
      "\t chuck 17 of 20. From 2018.04.02 01:01:00 to 2018.04.12 09:26:16\n",
      "\t chuck 18 of 20. From 2018.04.12 09:59:09 to 2018.05.08 03:27:53\n",
      "\t chuck 19 of 20. From 2018.05.08 04:24:13 to 2018.05.28 19:59:59\n",
      "\t chuck 20 of 20. From 2018.05.29 01:00:00 to 2018.05.31 23:58:37\n",
      "16. USDCAD\n",
      "\t chuck 0 of 19. From 2016.01.04 00:00:00 to 2016.10.13 15:41:59\n",
      "Group USDCAD/160104000000161013154159/37 not in file\n",
      "\t chuck 1 of 19. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 2 of 19. From 2016.12.26 06:00:00 to 2017.09.04 23:45:30\n",
      "\t chuck 3 of 19. From 2017.09.05 10:05:21 to 2017.11.10 09:38:14\n",
      "\t chuck 4 of 19. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t chuck 5 of 19. From 2017.11.27 00:05:00 to 2017.12.08 23:58:58\n",
      "\t chuck 6 of 19. From 2017.12.11 00:05:00 to 2017.12.12 04:13:01\n",
      "\t chuck 7 of 19. From 2017.12.12 10:13:39 to 2017.12.22 23:58:59\n",
      "\t chuck 8 of 19. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 9 of 19. From 2018.01.02 03:00:00 to 2018.01.10 21:19:38\n",
      "\t chuck 10 of 19. From 2018.01.11 14:39:38 to 2018.01.25 08:17:38\n",
      "\t chuck 11 of 19. From 2018.01.25 09:10:26 to 2018.03.08 23:58:59\n",
      "\t chuck 12 of 19. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t chuck 13 of 19. From 2018.03.20 05:44:34 to 2018.04.12 09:26:07\n",
      "\t chuck 14 of 19. From 2018.04.12 09:59:08 to 2018.05.08 03:27:47\n",
      "\t chuck 15 of 19. From 2018.05.08 04:24:14 to 2018.07.13 23:59:56\n",
      "\t chuck 16 of 19. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 17 of 19. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 18 of 19. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 19 of 19. From 2018.08.27 19:03:29 to 2018.09.27 23:58:54\n",
      "17. USDCHF\n",
      "\t chuck 0 of 25. From 2016.01.04 00:00:59 to 2016.01.11 00:30:59\n",
      "Group USDCHF/160104000059160111003059/37 not in file\n",
      "\t chuck 1 of 25. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 25. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 25. From 2016.12.26 06:00:00 to 2016.12.30 23:58:08\n",
      "\t chuck 4 of 25. From 2017.01.02 09:00:00 to 2017.08.11 23:54:59\n",
      "\t chuck 5 of 25. From 2017.08.14 19:30:37 to 2017.08.14 23:58:59\n",
      "\t chuck 6 of 25. From 2017.08.15 15:13:26 to 2017.08.17 23:58:48\n",
      "\t chuck 7 of 25. From 2017.08.21 00:05:07 to 2017.08.25 19:45:45\n",
      "\t chuck 8 of 25. From 2017.08.28 00:05:01 to 2017.09.05 02:35:52\n",
      "\t chuck 10 of 25. From 2017.09.05 09:45:55 to 2017.11.10 09:38:15\n",
      "\t chuck 11 of 25. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t chuck 12 of 25. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 13 of 25. From 2017.12.11 00:05:00 to 2017.12.22 23:58:59\n",
      "\t chuck 14 of 25. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 15 of 25. From 2018.01.02 03:00:00 to 2018.01.10 21:17:59\n",
      "\t chuck 16 of 25. From 2018.01.11 14:39:29 to 2018.01.25 08:17:38\n",
      "\t chuck 17 of 25. From 2018.01.25 09:08:40 to 2018.03.08 23:58:59\n",
      "\t chuck 18 of 25. From 2018.03.09 00:05:00 to 2018.03.20 05:04:49\n",
      "\t chuck 19 of 25. From 2018.03.20 05:44:30 to 2018.04.12 09:26:15\n",
      "\t chuck 20 of 25. From 2018.04.12 09:59:08 to 2018.05.08 03:27:52\n",
      "\t chuck 21 of 25. From 2018.05.08 04:24:15 to 2018.07.13 23:59:00\n",
      "\t chuck 22 of 25. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 23 of 25. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 24 of 25. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 25 of 25. From 2018.08.27 19:03:29 to 2018.09.27 23:58:58\n",
      "19. USDJPY\n",
      "\t chuck 0 of 27. From 2016.01.05 00:02:00 to 2016.01.19 16:54:08\n",
      "\t chuck 1 of 27. From 2016.01.20 00:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 27. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 27. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t chuck 4 of 27. From 2017.01.02 00:01:59 to 2017.07.14 00:05:30\n",
      "\t chuck 5 of 27. From 2017.07.14 00:27:00 to 2017.08.11 23:59:59\n",
      "\t chuck 6 of 27. From 2017.08.14 19:30:40 to 2017.08.14 23:58:59\n",
      "\t chuck 7 of 27. From 2017.08.15 03:32:14 to 2017.08.17 23:58:59\n",
      "\t chuck 8 of 27. From 2017.08.21 00:05:07 to 2017.08.25 19:55:41\n",
      "\t chuck 9 of 27. From 2017.08.28 00:05:01 to 2017.09.05 02:36:00\n",
      "\t chuck 11 of 27. From 2017.09.05 09:45:51 to 2017.11.10 09:38:15\n",
      "\t chuck 12 of 27. From 2017.11.10 10:05:51 to 2017.11.24 23:58:45\n",
      "\t chuck 13 of 27. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 14 of 27. From 2017.12.11 00:05:00 to 2017.12.12 04:13:06\n",
      "\t chuck 15 of 27. From 2017.12.12 10:13:34 to 2017.12.22 23:58:59\n",
      "\t chuck 16 of 27. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 17 of 27. From 2018.01.02 03:00:00 to 2018.01.10 21:27:56\n",
      "\t chuck 18 of 27. From 2018.01.11 14:39:29 to 2018.01.25 08:17:36\n",
      "\t chuck 19 of 27. From 2018.01.25 09:10:27 to 2018.03.08 23:58:52\n",
      "\t chuck 20 of 27. From 2018.03.09 00:05:00 to 2018.03.20 05:04:47\n",
      "\t chuck 21 of 27. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t chuck 22 of 27. From 2018.04.12 10:00:38 to 2018.05.08 03:27:53\n",
      "\t chuck 23 of 27. From 2018.05.08 04:24:16 to 2018.07.13 23:59:02\n",
      "\t chuck 24 of 27. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 25 of 27. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 26 of 27. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 27 of 27. From 2018.08.27 19:03:31 to 2018.09.27 23:58:59\n",
      "27. CADJPY\n",
      "\t chuck 0 of 22. From 2016.01.04 00:00:00 to 2016.01.15 23:59:59\n",
      "\t chuck 1 of 22. From 2016.01.19 00:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 22. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 22. From 2016.12.26 06:00:00 to 2017.09.11 23:01:59\n",
      "\t chuck 4 of 22. From 2017.09.11 23:28:00 to 2017.09.18 23:59:59\n",
      "\t chuck 5 of 22. From 2017.09.19 23:45:43 to 2017.10.23 01:18:29\n",
      "\t chuck 6 of 22. From 2017.10.23 02:02:38 to 2017.11.10 09:38:15\n",
      "\t chuck 7 of 22. From 2017.11.10 10:05:52 to 2017.11.24 23:58:59\n",
      "\t chuck 8 of 22. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 9 of 22. From 2017.12.11 00:05:00 to 2017.12.12 04:13:05\n",
      "\t chuck 10 of 22. From 2017.12.12 10:13:38 to 2017.12.22 23:58:59\n",
      "\t chuck 11 of 22. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 12 of 22. From 2018.01.02 03:00:00 to 2018.01.10 21:17:53\n",
      "\t chuck 13 of 22. From 2018.01.11 14:39:29 to 2018.01.25 08:17:37\n",
      "\t chuck 14 of 22. From 2018.01.25 09:10:28 to 2018.03.08 23:58:59\n",
      "\t chuck 15 of 22. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t chuck 16 of 22. From 2018.03.20 05:44:32 to 2018.04.12 09:26:16\n",
      "\t chuck 17 of 22. From 2018.04.12 10:00:39 to 2018.05.08 03:27:53\n",
      "\t chuck 18 of 22. From 2018.05.08 04:24:16 to 2018.05.31 23:58:58\n",
      "\t chuck 19 of 22. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 20 of 22. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t chuck 21 of 22. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 22 of 22. From 2018.08.27 19:03:31 to 2018.09.27 23:58:59\n",
      "28. EURJPY\n",
      "\t chuck 0 of 24. From 2016.01.04 00:00:00 to 2016.01.11 00:29:59\n",
      "\t chuck 1 of 24. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 24. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 24. From 2016.12.26 06:00:00 to 2017.07.10 00:04:59\n",
      "\t chuck 4 of 24. From 2017.07.10 00:30:00 to 2017.07.14 00:04:59\n",
      "\t chuck 5 of 24. From 2017.07.14 00:27:00 to 2017.09.11 23:01:59\n",
      "\t chuck 7 of 24. From 2017.09.11 23:47:00 to 2017.09.19 23:59:59\n",
      "\t chuck 8 of 24. From 2017.09.21 08:10:57 to 2017.11.10 09:38:15\n",
      "\t chuck 9 of 24. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t chuck 10 of 24. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 11 of 24. From 2017.12.11 00:05:00 to 2017.12.12 04:12:51\n",
      "\t chuck 12 of 24. From 2017.12.12 10:13:36 to 2017.12.22 23:58:59\n",
      "\t chuck 13 of 24. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 14 of 24. From 2018.01.02 03:00:00 to 2018.01.10 21:26:10\n",
      "\t chuck 15 of 24. From 2018.01.11 14:39:33 to 2018.01.25 08:17:38\n",
      "\t chuck 16 of 24. From 2018.01.25 09:08:40 to 2018.03.08 23:58:59\n",
      "\t chuck 17 of 24. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t chuck 18 of 24. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t chuck 19 of 24. From 2018.04.12 09:59:08 to 2018.05.08 03:27:54\n",
      "\t chuck 20 of 24. From 2018.05.08 04:24:13 to 2018.07.13 23:59:56\n",
      "\t chuck 21 of 24. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 22 of 24. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 23 of 24. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 24 of 24. From 2018.08.27 19:03:31 to 2018.09.27 23:58:59\n",
      "29. AUDJPY\n",
      "\t chuck 0 of 21. From 2016.01.04 00:00:00 to 2016.01.11 00:24:59\n",
      "\t chuck 1 of 21. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 21. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 21. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t chuck 4 of 21. From 2017.01.02 09:00:00 to 2017.01.27 23:54:59\n",
      "\t chuck 5 of 21. From 2017.01.31 00:12:00 to 2017.11.09 23:59:59\n",
      "\t chuck 6 of 21. From 2017.11.20 00:05:00 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:54\n",
      "\t chuck 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t chuck 9 of 21. From 2017.12.12 10:13:40 to 2017.12.22 23:58:58\n",
      "\t chuck 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:59\n",
      "\t chuck 11 of 21. From 2018.01.02 02:59:59 to 2018.01.10 21:13:01\n",
      "\t chuck 12 of 21. From 2018.01.11 14:39:33 to 2018.01.25 08:17:37\n",
      "\t chuck 13 of 21. From 2018.01.25 09:10:26 to 2018.03.08 23:58:54\n",
      "\t chuck 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t chuck 15 of 21. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t chuck 16 of 21. From 2018.04.12 10:00:38 to 2018.05.08 03:27:55\n",
      "\t chuck 17 of 21. From 2018.05.08 04:24:13 to 2018.07.13 23:59:08\n",
      "\t chuck 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t chuck 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 21 of 21. From 2018.08.27 19:03:36 to 2018.09.27 23:58:59\n",
      "30. CHFJPY\n",
      "\t chuck 0 of 21. From 2016.01.04 01:00:00 to 2016.01.11 00:19:59\n",
      "\t chuck 1 of 21. From 2016.01.11 01:00:00 to 2016.03.18 22:59:59\n",
      "\t chuck 2 of 21. From 2016.03.21 01:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 3 of 21. From 2016.10.13 17:52:00 to 2016.10.18 00:01:34\n",
      "\t chuck 4 of 21. From 2016.10.18 02:28:18 to 2016.12.23 23:59:59\n",
      "\t chuck 5 of 21. From 2016.12.26 06:00:00 to 2016.12.29 23:59:59\n",
      "\t chuck 6 of 21. From 2017.01.02 09:00:00 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 21. From 2017.11.27 00:05:00 to 2017.12.08 23:58:56\n",
      "\t chuck 8 of 21. From 2017.12.11 00:05:00 to 2017.12.12 04:13:07\n",
      "\t chuck 9 of 21. From 2017.12.12 10:13:40 to 2017.12.22 23:58:58\n",
      "\t chuck 10 of 21. From 2017.12.26 03:00:00 to 2017.12.29 23:58:58\n",
      "\t chuck 11 of 21. From 2018.01.02 03:00:00 to 2018.01.10 21:09:34\n",
      "\t chuck 12 of 21. From 2018.01.15 11:16:28 to 2018.01.25 08:17:38\n",
      "\t chuck 13 of 21. From 2018.01.25 09:10:26 to 2018.03.08 23:58:59\n",
      "\t chuck 14 of 21. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t chuck 15 of 21. From 2018.03.20 05:44:30 to 2018.04.12 09:26:16\n",
      "\t chuck 16 of 21. From 2018.04.12 09:59:08 to 2018.05.08 03:27:53\n",
      "\t chuck 17 of 21. From 2018.05.08 04:24:15 to 2018.07.13 23:59:56\n",
      "\t chuck 18 of 21. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 19 of 21. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 20 of 21. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 21 of 21. From 2018.08.27 19:03:31 to 2018.09.27 23:58:57\n",
      "31. GBPJPY\n",
      "\t chuck 0 of 23. From 2016.01.04 00:00:30 to 2016.01.11 00:17:59\n",
      "\t chuck 1 of 23. From 2016.01.11 01:00:00 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 23. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 23. From 2016.12.26 06:00:00 to 2017.08.14 00:41:30\n",
      "\t chuck 5 of 23. From 2017.08.14 15:07:00 to 2017.09.18 23:59:59\n",
      "\t chuck 6 of 23. From 2017.09.19 23:46:08 to 2017.11.10 09:38:15\n",
      "\t chuck 7 of 23. From 2017.11.10 10:05:53 to 2017.11.24 23:58:59\n",
      "\t chuck 8 of 23. From 2017.11.27 00:05:00 to 2017.12.08 23:58:59\n",
      "\t chuck 9 of 23. From 2017.12.11 00:05:00 to 2017.12.12 04:13:09\n",
      "\t chuck 10 of 23. From 2017.12.12 10:13:39 to 2017.12.22 23:58:59\n",
      "\t chuck 11 of 23. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t chuck 12 of 23. From 2018.01.02 03:00:00 to 2018.01.10 21:28:58\n",
      "\t chuck 13 of 23. From 2018.01.11 14:39:32 to 2018.01.25 08:17:38\n",
      "\t chuck 14 of 23. From 2018.01.25 08:49:51 to 2018.03.08 23:58:59\n",
      "\t chuck 15 of 23. From 2018.03.09 00:05:00 to 2018.03.20 05:04:48\n",
      "\t chuck 16 of 23. From 2018.03.20 05:44:29 to 2018.04.12 09:26:16\n",
      "\t chuck 17 of 23. From 2018.04.12 09:59:09 to 2018.05.08 03:27:56\n",
      "\t chuck 18 of 23. From 2018.05.08 04:24:15 to 2018.07.13 23:59:56\n",
      "\t chuck 19 of 23. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 20 of 23. From 2018.08.13 07:37:02 to 2018.08.23 12:52:32\n",
      "\t chuck 21 of 23. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 22 of 23. From 2018.08.27 19:03:31 to 2018.09.06 04:36:04\n",
      "\t chuck 23 of 23. From 2018.09.07 00:05:02 to 2018.09.27 23:58:59\n",
      "32. NZDUSD\n",
      "\t chuck 0 of 22. From 2016.01.04 00:00:30 to 2016.10.13 00:01:05\n",
      "\t chuck 1 of 22. From 2016.10.13 01:47:11 to 2016.10.13 15:41:59\n",
      "\t chuck 2 of 22. From 2016.10.13 17:52:00 to 2016.12.23 23:59:59\n",
      "\t chuck 3 of 22. From 2016.12.26 06:00:00 to 2017.09.11 23:01:59\n",
      "\t chuck 4 of 22. From 2017.09.11 23:47:00 to 2017.09.28 13:45:59\n",
      "\t chuck 5 of 22. From 2017.09.28 14:10:00 to 2017.11.16 23:59:59\n",
      "\t chuck 6 of 22. From 2017.11.20 00:05:01 to 2017.11.24 23:58:59\n",
      "\t chuck 7 of 22. From 2017.11.27 00:05:00 to 2017.12.08 23:58:57\n",
      "\t chuck 8 of 22. From 2017.12.11 00:05:00 to 2017.12.12 04:13:10\n",
      "\t chuck 9 of 22. From 2017.12.12 10:13:36 to 2017.12.22 23:58:59\n",
      "\t chuck 10 of 22. From 2017.12.26 03:00:01 to 2017.12.29 23:58:59\n",
      "\t chuck 11 of 22. From 2018.01.02 03:00:00 to 2018.01.10 21:10:40\n",
      "\t chuck 12 of 22. From 2018.01.11 14:39:33 to 2018.01.23 08:12:03\n",
      "\t chuck 13 of 22. From 2018.01.24 00:05:18 to 2018.01.25 08:17:37\n",
      "\t chuck 14 of 22. From 2018.01.25 09:10:33 to 2018.03.08 23:58:59\n",
      "\t chuck 15 of 22. From 2018.03.09 00:05:00 to 2018.03.20 05:04:46\n",
      "\t chuck 16 of 22. From 2018.03.20 05:44:40 to 2018.04.12 09:26:11\n",
      "\t chuck 17 of 22. From 2018.04.12 09:59:08 to 2018.05.08 03:27:56\n",
      "\t chuck 18 of 22. From 2018.05.08 04:24:16 to 2018.07.13 23:59:00\n",
      "\t chuck 19 of 22. From 2018.07.30 00:05:00 to 2018.08.10 23:58:59\n",
      "\t chuck 20 of 22. From 2018.08.13 07:37:02 to 2018.08.23 12:52:28\n",
      "\t chuck 21 of 22. From 2018.08.23 13:14:34 to 2018.08.24 23:58:59\n",
      "\t chuck 22 of 22. From 2018.08.27 19:03:32 to 2018.09.27 23:58:59\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of feautures file\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from inputs import Data, load_separators\n",
    "import h5py\n",
    "import datetime as dt\n",
    "\n",
    "hdf5_directory = 'D:/SDC/py/HDF5/'\n",
    "filename_raw = hdf5_directory+'tradeinfo.hdf5'\n",
    "separators_directory = hdf5_directory+'separators/'\n",
    "data=Data(movingWindow=100,\n",
    "              nEventsPerStat=1000,\n",
    "              dateTest = [                                          '2018.03.09',\n",
    "                '2018.03.12','2018.03.13','2018.03.14','2018.03.15','2018.03.16',\n",
    "                '2018.03.19','2018.03.20','2018.03.21','2018.03.22','2018.03.23',\n",
    "                '2018.03.26','2018.03.27','2018.03.28','2018.03.29','2018.03.30',\n",
    "                '2018.04.02','2018.04.03','2018.04.04','2018.04.05','2018.04.06',\n",
    "                '2018.04.09','2018.04.10','2018.04.11','2018.04.12','2018.04.13',\n",
    "                '2018.04.16','2018.04.17','2018.04.18','2018.04.19','2018.04.20',\n",
    "                '2018.04.23','2018.04.24','2018.04.25','2018.04.26','2018.04.27',\n",
    "                '2018.04.30','2018.05.01','2018.05.02','2018.05.03','2018.05.04',\n",
    "                '2018.05.07','2018.05.08','2018.05.09','2018.05.10','2018.05.11',\n",
    "                '2018.05.14','2018.05.15','2018.05.16','2018.05.17','2018.05.18',\n",
    "                '2018.05.21','2018.05.22','2018.05.23','2018.05.24','2018.05.25',\n",
    "                '2018.05.28','2018.05.29','2018.05.30','2018.05.31','2018.06.01',\n",
    "                '2018.06.04','2018.06.05','2018.06.06','2018.06.07','2018.06.08',\n",
    "                '2018.06.11','2018.06.12','2018.06.13','2018.06.14','2018.06.15',\n",
    "                '2018.06.18','2018.06.19','2018.06.20','2018.06.21','2018.06.22',\n",
    "                '2018.06.25','2018.06.26','2018.06.27','2018.06.28','2018.06.29',\n",
    "                '2018.07.02','2018.07.03','2018.07.04','2018.07.05','2018.07.06',\n",
    "                '2018.07.09','2018.07.10','2018.07.11','2018.07.12','2018.07.13',\n",
    "                '2018.07.30','2018.07.31','2018.08.01','2018.08.02','2018.08.03',\n",
    "                '2018.08.06','2018.08.07','2018.08.08','2018.08.09','2018.08.10']+\n",
    "               ['2018.08.13','2018.08.14','2018.08.15','2018.08.16','2018.08.17',\n",
    "                '2018.08.20','2018.08.21','2018.08.22','2018.08.23','2018.08.24',\n",
    "                '2018.08.27','2018.08.28','2018.08.29','2018.08.30','2018.08.31',\n",
    "                '2018.09.03','2018.09.04','2018.09.05','2018.09.06','2018.09.07',\n",
    "                '2018.09.10','2018.09.11','2018.09.12','2018.09.13','2018.09.14',\n",
    "                '2018.09.17','2018.09.18','2018.09.19','2018.09.20','2018.09.21',\n",
    "                '2018.09.24','2018.09.25','2018.09.26','2018.09.27'])\n",
    "filename_features_tsf = (hdf5_directory+'feats_tsf_mW'+str(data.movingWindow)+'_nE'+\n",
    "                         str(data.nEventsPerStat)+'.hdf5')\n",
    "window_size = data.nEventsPerStat\n",
    "sprite_length = data.movingWindow\n",
    "features_tsfresh = data.feature_keys_tsfresh\n",
    "n_feats_tsfresh = data.n_feats_tsfresh\n",
    "file_features_tsf = h5py.File(filename_features_tsf,'a')\n",
    "for ass in data.assets:\n",
    "    thisAsset = data.AllAssets[str(ass)]\n",
    "    print(str(ass)+\". \"+thisAsset)\n",
    "    # load separators\n",
    "    separators = load_separators(data, thisAsset, \n",
    "                                     separators_directory, \n",
    "                                     from_txt=1)\n",
    "    for s in range(0,len(separators)-1,2):\n",
    "        \n",
    "        \n",
    "        n_events = separators.index[s+1]-separators.index[s]+1\n",
    "        if n_events>=2*window_size:\n",
    "            print(\"\\t chuck {0:d} of {1:d}\".format(int(s/2),int(len(separators)/2-1))+\n",
    "                      \". From \"+separators.DateTime.iloc[s]+\" to \"+separators.DateTime.iloc[s+1])\n",
    "\n",
    "            # init and end dates in string format\n",
    "            init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                    separators.DateTime.iloc[s],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "            end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                    separators.DateTime.iloc[s+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "            # hdf5 group name\n",
    "            group_name_chunck = thisAsset+'/'+init_date+end_date\n",
    "            for f in features_tsfresh:\n",
    "                group_name_feat = group_name_chunck+'/'+str(f)\n",
    "                count = 0\n",
    "                success = 0\n",
    "                if group_name_feat in file_features_tsf:\n",
    "                    #if 1:\n",
    "                    while count<10 and not success:\n",
    "                        try:\n",
    "                            group_chunck = file_features_tsf[group_name_feat]\n",
    "                            success = 1\n",
    "                            #print(success)\n",
    "                        except KeyError:\n",
    "                            print(\"KeyError: Unable to open object (Corrupt object header) \"+group_name_feat)\n",
    "                            #del file_features_tsf[group_name_feat]\n",
    "                            #print(group_name_feat+\" deleted\")\n",
    "                            \n",
    "                            count += 1\n",
    "                    if count>0:\n",
    "                        print(group_chunck[\"feature\"])\n",
    "                else:\n",
    "                    print(\"Group \"+group_name_feat+\" not in file\")\n",
    "                    if group_name_feat not in file_features_tsf:\n",
    "                        print(\"Group \"+group_name_feat+\" not in file\")\n",
    "                \n",
    "file_features_tsf.close()\n",
    "print(\"DONE\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a location (Invalid object id)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-114f1b38c0ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgroup_name_feat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_features_tsf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgroup_chunck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_features_tsf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup_name_feat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1496885653697\\work\\h5py\\_objects.c:2867)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1496885653697\\work\\h5py\\_objects.c:2825)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1496885653697\\work\\h5py\\_objects.c:2867)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (C:\\Minonda\\conda-bld\\h5py_1496885653697\\work\\h5py\\_objects.c:2825)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open (C:\\Minonda\\conda-bld\\h5py_1496885653697\\work\\h5py\\h5o.c:3628)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not a location (Invalid object id)"
     ]
    }
   ],
   "source": [
    "group_name_feat in file_features_tsf\n",
    "group_chunck = file_features_tsf[group_name_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "310\n",
      "AUDCAD/160104000008161013154159/37 deleted\n",
      "AUDCAD/160104000008161013154159/38 deleted\n",
      "AUDCAD/160104000008161013154159/39 deleted\n",
      "AUDCAD/160104000008161013154159/40 deleted\n",
      "AUDCAD/160104000008161013154159/41 deleted\n",
      "AUDCAD/160104000008161013154159/42 deleted\n",
      "AUDCAD/160104000008161013154159/43 deleted\n",
      "AUDCAD/160104000008161013154159/44 deleted\n",
      "AUDCAD/160104000008161013154159/45 deleted\n",
      "AUDCAD/160104000008161013154159/46 deleted\n",
      "AUDCAD/160104000008161013154159/47 deleted\n",
      "AUDCAD/160104000008161013154159/48 deleted\n",
      "AUDCAD/160104000008161013154159/49 deleted\n",
      "AUDCAD/160104000008161013154159/50 deleted\n",
      "AUDCAD/160104000008161013154159/51 deleted\n",
      "AUDCAD/160104000008161013154159/52 deleted\n",
      "AUDCAD/160104000008161013154159/53 deleted\n",
      "AUDCAD/160104000008161013154159/54 deleted\n",
      "AUDCAD/160104000008161013154159/55 deleted\n",
      "AUDCAD/160104000008161013154159/56 deleted\n",
      "AUDCAD/160104000008161013154159/57 deleted\n",
      "AUDCAD/160104000008161013154159/58 deleted\n",
      "AUDCAD/160104000008161013154159/59 deleted\n",
      "AUDCAD/160104000008161013154159/60 deleted\n",
      "AUDCAD/160104000008161013154159/61 deleted\n",
      "AUDCAD/160104000008161013154159/62 deleted\n",
      "AUDCAD/160104000008161013154159/63 deleted\n",
      "AUDCAD/160104000008161013154159/64 deleted\n",
      "AUDCAD/160104000008161013154159/65 deleted\n",
      "AUDCAD/160104000008161013154159/66 deleted\n",
      "AUDCAD/160104000008161013154159/67 deleted\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(309829, 76)\n",
      "310\n",
      "ft already closed\n"
     ]
    }
   ],
   "source": [
    "# formatear features file\n",
    "''''\n",
    "print(b)\n",
    "print(batches)\n",
    "cwt_coeff = [3,9,2,3,11,12,5,4,8,14,7,6,13,10,13,10,5,11,5,13,14,3,1,4,12,6,\n",
    "                 10,4,7,2,9,8,9,1,12,5,2,1,8,11,4,7,6,2]\n",
    "\n",
    "file_features_tsf = h5py.File(filename_features_tsf,'a')\n",
    "for ass in data.assets[:1]:\n",
    "    thisAsset = data.AllAssets[str(ass)]\n",
    "    # load separators\n",
    "    separators = load_separators(data, thisAsset, \n",
    "                                     separators_directory, \n",
    "                                     from_txt=1)\n",
    "    for s in range(0,len(separators)-1,2):\n",
    "        init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                            separators.DateTime.iloc[s],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "        end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                            separators.DateTime.iloc[s+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "        # hdf5 group name\n",
    "        group_name_chunck = thisAsset+'/'+init_date+end_date\n",
    "        for f in features_tsfresh:\n",
    "            group_name_feat = group_name_chunck+'/'+str(f)\n",
    "            if group_name_feat in file_features_tsf:\n",
    "                del file_features_tsf[group_name_feat]\n",
    "                print(group_name_feat+\" deleted\")\n",
    "file_features_tsf.close()\n",
    "\n",
    "print(features)\n",
    "print(features.shape)\n",
    "print(batches)\n",
    "try:\n",
    "    ft.close()\n",
    "except:\n",
    "    print(\"ft already closed\")\n",
    "''''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.assets\n",
    "file_features_tsf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "USDJPY/171226030000171229235859/41 deleted\n",
      "USDJPY/171226030000171229235859/42 deleted\n",
      "USDJPY/171226030000171229235859/43 deleted\n",
      "USDJPY/171226030000171229235859/44 deleted\n",
      "USDJPY/171226030000171229235859/45 deleted\n",
      "USDJPY/171226030000171229235859/46 deleted\n",
      "USDJPY/171226030000171229235859/47 deleted\n",
      "USDJPY/171226030000171229235859/48 deleted\n",
      "USDJPY/171226030000171229235859/49 deleted\n",
      "USDJPY/171226030000171229235859/50 deleted\n",
      "USDJPY/171226030000171229235859/51 deleted\n",
      "USDJPY/171226030000171229235859/52 deleted\n",
      "USDJPY/171226030000171229235859/53 deleted\n",
      "USDJPY/171226030000171229235859/54 deleted\n",
      "USDJPY/171226030000171229235859/55 deleted\n",
      "USDJPY/171226030000171229235859/56 deleted\n",
      "USDJPY/171226030000171229235859/57 deleted\n",
      "USDJPY/171226030000171229235859/58 deleted\n",
      "USDJPY/171226030000171229235859/59 deleted\n",
      "USDJPY/171226030000171229235859/60 deleted\n",
      "USDJPY/171226030000171229235859/61 deleted\n",
      "USDJPY/171226030000171229235859/62 deleted\n",
      "USDJPY/171226030000171229235859/63 deleted\n",
      "USDJPY/171226030000171229235859/64 deleted\n",
      "USDJPY/171226030000171229235859/65 deleted\n",
      "USDJPY/171226030000171229235859/66 deleted\n",
      "USDJPY/171226030000171229235859/67 deleted\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n",
      "\t Getting features from raw data...\n"
     ]
    }
   ],
   "source": [
    "file_features_tsf = h5py.File(filename_features_tsf,'a')\n",
    "for ass in data.assets[14:15]:\n",
    "    for s in range(30,len(separators)-1,2):\n",
    "        n_events = separators.index[s+1]-separators.index[s]+1\n",
    "        if n_events>=2*window_size:\n",
    "            print(\"\\t Getting features from raw data...\")\n",
    "            tic = time.time()\n",
    "            tic_chunck = tic\n",
    "            # init and end dates in string format\n",
    "            init_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                    separators.DateTime.iloc[s],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "            end_date = dt.datetime.strftime(dt.datetime.strptime(\n",
    "                    separators.DateTime.iloc[s+1],'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "            # hdf5 group name\n",
    "            group_name_chunck = thisAsset+'/'+init_date+end_date\n",
    "            for f in features_tsfresh:\n",
    "                group_name_feat = group_name_chunck+'/'+str(f)\n",
    "                if group_name_feat in file_features_tsf:\n",
    "                    print(group_name_feat+\" deleted\")\n",
    "                    del file_features_tsf[group_name_feat]\n",
    "file_features_tsf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "# save features in HDF5 file\n",
    "for f in features_tsfresh:\n",
    "    group_name_feat = group_name_chunck+'/'+str(f)\n",
    "    params = data.AllFeatures[str(f)]\n",
    "    n_new_feats = params[-1]\n",
    "    #if group_name_feat in file_features_tsf:\n",
    "    #    del file_features_tsf[group_name_feat]\n",
    "    if group_name_feat not in file_features_tsf:\n",
    "        group_chunck = file_features_tsf.create_group(group_name_feat)\n",
    "        group_features = group_chunck.create_dataset(\"feature\", (m,n_new_feats),dtype=float)\n",
    "        group_features[:,:] = features[:,c:c+n_new_feats]\n",
    "    else: # load features from HDF5 file if they are saved already\n",
    "        params = data.AllFeatures[str(f)]\n",
    "        n_new_feats = params[-1]\n",
    "        group_chunck = file_features_tsf[group_name_feat]\n",
    "        features[:,c:c+n_new_feats] = group_chunck[\"feature\"]\n",
    "        c += n_new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AUDCAD\n",
      "AUDCADc0 # features 375\n",
      "AUDCADc1 # features 130\n",
      "AUDCADc2 # features 426\n",
      "AUDCADc3 # features 422\n",
      "AUDCADc4 # features 276\n",
      "AUDCADc5 # features 382\n",
      "AUDCADc6 # features 109\n",
      "AUDCADc7 # features 330\n",
      "AUDCADc8 # features 128\n",
      "AUDCADc9 # features 110\n",
      "AUDCADc10 # features 101\n",
      "AUDCADc11 # features 104\n",
      "AUDCADc12 # features 173\n",
      "AUDCADc13 # features 267\n",
      "AUDCADc14 # features 122\n",
      "AUDCADc15 # features 115\n",
      "AUDCADc16 # features 405\n",
      "AUDCADc17 # features 297\n",
      "AUDCADc18 # features 117\n",
      "AUDCADc19 # features 105\n",
      "AUDCADc20 # features 7\n",
      "AUDCADc21 # features 110\n",
      "2. EURAUD\n",
      "EURAUDc0 # features 111\n",
      "EURAUDc1 # features 308\n",
      "EURAUDc2 # features 406\n",
      "EURAUDc3 # features 16\n",
      "EURAUDc4 # features 235\n",
      "EURAUDc5 # features 441\n",
      "EURAUDc6 # features 229\n",
      "EURAUDc7 # features 101\n",
      "EURAUDc9 # features 227\n",
      "EURAUDc10 # features 448\n",
      "EURAUDc11 # features 38\n",
      "EURAUDc12 # features 385\n",
      "EURAUDc15 # features 373\n",
      "EURAUDc16 # features 107\n",
      "EURAUDc17 # features 93\n",
      "EURAUDc18 # features 459\n",
      "EURAUDc19 # features 312\n",
      "EURAUDc20 # features 216\n",
      "EURAUDc21 # features 135\n",
      "EURAUDc22 # features 290\n",
      "EURAUDc23 # features 331\n",
      "EURAUDc24 # features 134\n",
      "EURAUDc25 # features 8\n",
      "EURAUDc26 # features 34\n",
      "EURAUDc27 # features 261\n",
      "EURAUDc28 # features 305\n",
      "EURAUDc29 # features 258\n",
      "EURAUDc30 # features 38\n",
      "EURAUDc31 # features 84\n",
      "3. EURCAD\n",
      "EURCADc0 # features 21\n",
      "EURCADc1 # features 214\n",
      "EURCADc2 # features 387\n",
      "EURCADc3 # features 141\n",
      "EURCADc4 # features 263\n",
      "EURCADc5 # features 88\n",
      "EURCADc7 # features 389\n",
      "EURCADc8 # features 299\n",
      "EURCADc9 # features 264\n",
      "EURCADc10 # features 103\n",
      "EURCADc11 # features 123\n",
      "EURCADc12 # features 94\n",
      "EURCADc13 # features 309\n",
      "EURCADc14 # features 317\n",
      "EURCADc15 # features 387\n",
      "EURCADc16 # features 159\n",
      "EURCADc17 # features 124\n",
      "EURCADc18 # features 337\n",
      "EURCADc19 # features 23\n",
      "EURCADc20 # features 144\n",
      "EURCADc21 # features 111\n",
      "EURCADc22 # features 131\n",
      "EURCADc23 # features 249\n",
      "4. EURCHF\n",
      "EURCHFc0 # features 331\n",
      "7. EURGBP\n",
      "8. EURNZD\n",
      "10. EURUSD\n",
      "11. GBPAUD\n",
      "12. GBPCAD\n",
      "13. GBPCHF\n",
      "14. GBPUSD\n",
      "15. GOLD\n",
      "16. USDCAD\n",
      "17. USDCHF\n",
      "19. USDJPY\n",
      "27. CADJPY\n",
      "28. EURJPY\n",
      "29. AUDJPY\n",
      "30. CHFJPY\n",
      "31. GBPJPY\n",
      "32. NZDUSD\n",
      "(671, 2)\n",
      "Max possible score=75\n",
      "                      features scores\n",
      "4           SymbolBid__maximum     59\n",
      "7           SymbolBid__minimum     59\n",
      "15  SymbolBid__quantile__q_0.1     59\n",
      "59 score: 3 times\n",
      "Cummulated sum: 3\n",
      "58 score: 14 times\n",
      "Cummulated sum: 17\n",
      "57 score: 2 times\n",
      "Cummulated sum: 19\n",
      "56 score: 43 times\n",
      "Cummulated sum: 62\n",
      "55 score: 13 times\n",
      "Cummulated sum: 75\n",
      "54 score: 0 times\n",
      "Cummulated sum: 75\n",
      "53 score: 0 times\n",
      "Cummulated sum: 75\n",
      "52 score: 0 times\n",
      "Cummulated sum: 75\n",
      "51 score: 1 times\n",
      "Cummulated sum: 76\n",
      "50 score: 0 times\n",
      "Cummulated sum: 76\n",
      "49 score: 0 times\n",
      "Cummulated sum: 76\n",
      "48 score: 0 times\n",
      "Cummulated sum: 76\n",
      "47 score: 0 times\n",
      "Cummulated sum: 76\n",
      "46 score: 0 times\n",
      "Cummulated sum: 76\n",
      "45 score: 0 times\n",
      "Cummulated sum: 76\n",
      "44 score: 0 times\n",
      "Cummulated sum: 76\n",
      "43 score: 1 times\n",
      "Cummulated sum: 77\n",
      "42 score: 0 times\n",
      "Cummulated sum: 77\n",
      "41 score: 2 times\n",
      "Cummulated sum: 79\n",
      "40 score: 5 times\n",
      "Cummulated sum: 84\n",
      "39 score: 2 times\n",
      "Cummulated sum: 86\n",
      "38 score: 8 times\n",
      "Cummulated sum: 94\n",
      "37 score: 27 times\n",
      "Cummulated sum: 121\n",
      "36 score: 34 times\n",
      "Cummulated sum: 155\n",
      "35 score: 29 times\n",
      "Cummulated sum: 184\n",
      "34 score: 24 times\n",
      "Cummulated sum: 208\n",
      "33 score: 2 times\n",
      "Cummulated sum: 210\n",
      "32 score: 7 times\n",
      "Cummulated sum: 217\n",
      "31 score: 2 times\n",
      "Cummulated sum: 219\n",
      "30 score: 2 times\n",
      "Cummulated sum: 221\n",
      "29 score: 7 times\n",
      "Cummulated sum: 228\n",
      "28 score: 4 times\n",
      "Cummulated sum: 232\n",
      "27 score: 13 times\n",
      "Cummulated sum: 245\n",
      "26 score: 19 times\n",
      "Cummulated sum: 264\n",
      "25 score: 20 times\n",
      "Cummulated sum: 284\n",
      "24 score: 16 times\n",
      "Cummulated sum: 300\n",
      "23 score: 15 times\n",
      "Cummulated sum: 315\n",
      "22 score: 10 times\n",
      "Cummulated sum: 325\n",
      "21 score: 15 times\n",
      "Cummulated sum: 340\n",
      "20 score: 11 times\n",
      "Cummulated sum: 351\n",
      "19 score: 11 times\n",
      "Cummulated sum: 362\n",
      "18 score: 7 times\n",
      "Cummulated sum: 369\n",
      "17 score: 14 times\n",
      "Cummulated sum: 383\n",
      "16 score: 22 times\n",
      "Cummulated sum: 405\n",
      "15 score: 13 times\n",
      "Cummulated sum: 418\n",
      "14 score: 16 times\n",
      "Cummulated sum: 434\n",
      "13 score: 19 times\n",
      "Cummulated sum: 453\n",
      "12 score: 24 times\n",
      "Cummulated sum: 477\n",
      "11 score: 27 times\n",
      "Cummulated sum: 504\n",
      "10 score: 16 times\n",
      "Cummulated sum: 520\n",
      "9 score: 24 times\n",
      "Cummulated sum: 544\n",
      "8 score: 29 times\n",
      "Cummulated sum: 573\n",
      "7 score: 17 times\n",
      "Cummulated sum: 590\n",
      "6 score: 12 times\n",
      "Cummulated sum: 602\n",
      "5 score: 12 times\n",
      "Cummulated sum: 614\n",
      "4 score: 25 times\n",
      "Cummulated sum: 639\n",
      "3 score: 12 times\n",
      "Cummulated sum: 651\n",
      "2 score: 10 times\n",
      "Cummulated sum: 661\n",
      "1 score: 10 times\n",
      "Cummulated sum: 671\n"
     ]
    }
   ],
   "source": [
    "# extract most common filtered features from csv iles\n",
    "import pandas as pd\n",
    "from inputs import Data,load_separators\n",
    "import os\n",
    "\n",
    "hdf5_directory = 'D:/SDC/py/HDF5/'\n",
    "separators_directory = hdf5_directory+'separators/'\n",
    "file_extension = '.csv'\n",
    "data = Data(movingWindow=100,nEventsPerStat=1000)\n",
    "# init scores of most common features\n",
    "feature_scores = pd.DataFrame(columns=['features','scores'])\n",
    "counter = 0\n",
    "# loop over assets\n",
    "for ass in data.assets:\n",
    "    thisAsset = data.AllAssets[str(ass)]\n",
    "    print(str(ass)+\". \"+thisAsset)\n",
    "    # load separators\n",
    "    separators = load_separators(data, thisAsset, separators_directory, from_txt=1)\n",
    "    # loop over chuncks\n",
    "    for s in range(0,len(separators)-1,2):\n",
    "        filename = thisAsset+'c'+str(int(s/2))\n",
    "        # read csv file\n",
    "        if os.path.exists('../features/'+filename+file_extension):\n",
    "            counter += 1\n",
    "            this_df = pd.read_csv('../features/'+filename+file_extension)\n",
    "            print(filename+\" # features \"+str(this_df.shape[1]))\n",
    "            # increase scores\n",
    "            for c in this_df.columns[1:]:\n",
    "                if (feature_scores.features.str.find(c)==0).sum()>0:\n",
    "                    feature_scores.scores[feature_scores.features==c] += 1\n",
    "                else:\n",
    "                    feature_scores = feature_scores.append(pd.DataFrame({'features':c,'scores':1},index=[0]),ignore_index=True)\n",
    "print(feature_scores.shape)\n",
    "#feature_scores.scores.sort_values(ascending=False)\n",
    "feature_scores_ordered = feature_scores.loc[feature_scores.scores.sort_values(ascending=False).index]\n",
    "\n",
    "max_score = feature_scores.scores.max()\n",
    "reps_max_score = (feature_scores.scores==max_score).sum()\n",
    "print(\"Max possible score=\"+str(counter))\n",
    "print(feature_scores_ordered.iloc[:reps_max_score])\n",
    "cum_sum = 0\n",
    "for sc in range(max_score,0,-1):\n",
    "    tsum = (feature_scores.scores==sc).sum()\n",
    "    print(str(sc)+\" score: \"+str(tsum)+\" times\")\n",
    "    cum_sum += tsum\n",
    "    print(\"Cummulated sum: \"+str(cum_sum))\n",
    "last_r=\"\"\"\n",
    "24 score: 14 times\n",
    "23 score: 48 times\n",
    "22 score: 13 times\n",
    "21 score: 0 times\n",
    "20 score: 0 times\n",
    "19 score: 1 times\n",
    "18 score: 0 times\n",
    "17 score: 0 times\n",
    "16 score: 0 times\n",
    "15 score: 3 times\n",
    "14 score: 3 times\n",
    "13 score: 16 times\n",
    "12 score: 86 times\n",
    "11 score: 35 times\n",
    "10 score: 51 times\n",
    "9 score: 63 times\n",
    "8 score: 42 times\n",
    "7 score: 36 times\n",
    "6 score: 44 times\n",
    "5 score: 57 times\n",
    "4 score: 42 times\n",
    "3 score: 34 times\n",
    "2 score: 39 times\n",
    "1 score: 37 times\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 27, 28, 29, 30, 31, 32]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SymbolBid__fft_coefficient__coeff_0__attr_\"real\"\n",
      "1008.04491\n",
      "1008.04491\n",
      "SymbolBid__linear_trend__attr_\"slope\"\n",
      "3.0449038649e-06\n",
      "3.0449038649e-06\n",
      "SymbolBid__agg_linear_trend__f_agg_\"min\"__chunk_len_50__attr_\"intercept\"\n",
      "1.00643128571\n",
      "1.00643128571\n",
      "SymbolBid__first_location_of_minimum\n",
      "1.247\n",
      "0.247\n",
      "SymbolBid__energy_ratio_by_chunks__num_segments_10__segment_focus_1\n",
      "0.099895855316\n",
      "0.099895855316\n",
      "SymbolBid__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.2__ql_0.0\n",
      "1.95767195767e-06\n",
      "1.95767195767e-06\n",
      "SymbolBid__index_mass_quantile__q_0.9\n",
      "0.901\n",
      "0.901\n",
      "SymbolBid__number_cwt_peaks__n_5\n",
      "98\n",
      "98.0\n",
      "SymbolBid__last_location_of_maximum\n",
      "0.899\n",
      "0.899\n",
      "SymbolBid__first_location_of_maximum\n",
      "1.898\n",
      "0.898\n",
      "SymbolBid__last_location_of_minimum\n",
      "0.248\n",
      "0.248\n",
      "SymbolBid__mean_change\n",
      "3.25325325325e-06\n",
      "3.25325325325e-06\n",
      "SymbolBid__sum_values\n",
      "1008.04491\n",
      "1008.04491\n",
      "SymbolBid__mean\n",
      "1.00804491\n",
      "1.00804491\n",
      "SymbolBid__minimum\n",
      "1.00671\n",
      "1.00671\n",
      "SymbolBid__median\n",
      "1.0078\n",
      "1.0078\n",
      "SymbolBid__c3__lag_3\n",
      "1.02432302731\n",
      "1.02432302731\n",
      "SymbolBid__quantile__q_0.3\n",
      "1.007407\n",
      "1.007407\n",
      "SymbolBid__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_3__w_5\n",
      "[ 0.98310084  1.65942974  0.76507898  0.60604643  1.66023012  1.61423452\n",
      "  1.18850816  1.13901132  0.8694426   1.45175106]\n",
      "0.983100838962\n",
      "SymbolBid__maximum\n",
      "1.01031\n",
      "1.01031\n",
      "SymbolBid__abs_energy\n",
      "1016.1554738\n",
      "1016.1554738\n",
      "SymbolBid__linear_trend__attr_\"intercept\"\n",
      "1.00652398052\n",
      "1.00652398052\n"
     ]
    }
   ],
   "source": [
    "import tsfresh\n",
    "x=input_ts.SymbolBid\n",
    "param = {\"coeff\": 0, \"attr\": \"real\"}\n",
    "#print(param)\n",
    "\n",
    "print('SymbolBid__fft_coefficient__coeff_0__attr_\"real\"')\n",
    "print(fft_coefficient(x, [0, \"real\"]))\n",
    "print(features['SymbolBid__fft_coefficient__coeff_0__attr_\"real\"'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__linear_trend__attr_\"slope\"')\n",
    "print(linear_trend(x, \"slope\"))\n",
    "print(features['SymbolBid__linear_trend__attr_\"slope\"'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__agg_linear_trend__f_agg_\"min\"__chunk_len_50__attr_\"intercept\"')\n",
    "print(agg_linear_trend(x, [\"min\",50,\"intercept\"]))\n",
    "print(features['SymbolBid__agg_linear_trend__f_agg_\"min\"__chunk_len_50__attr_\"intercept\"'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__first_location_of_minimum')\n",
    "print(first_location_of_minimum(x))\n",
    "print(features['SymbolBid__first_location_of_minimum'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__energy_ratio_by_chunks__num_segments_10__segment_focus_1')\n",
    "print(energy_ratio_by_chunks(x, 10, 1))\n",
    "print(features['SymbolBid__energy_ratio_by_chunks__num_segments_10__segment_focus_1'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.2__ql_0.0')\n",
    "print(change_quantiles(x, 0.0, 0.2, False, \"mean\"))\n",
    "print(features['SymbolBid__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.2__ql_0.0'].iloc[-1])\n",
    "#print(feature_scores_ordered.features.loc[357])\n",
    "\n",
    "print('SymbolBid__index_mass_quantile__q_0.9')\n",
    "print(index_mass_quantile(x, 0.9))\n",
    "print(features['SymbolBid__index_mass_quantile__q_0.9'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__number_cwt_peaks__n_5')\n",
    "print(number_cwt_peaks(x, 5))\n",
    "print(features['SymbolBid__number_cwt_peaks__n_5'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__last_location_of_maximum')\n",
    "print(last_location_of_maximum(x))\n",
    "print(features['SymbolBid__last_location_of_maximum'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__first_location_of_maximum')\n",
    "print(first_location_of_maximum(x))\n",
    "print(features['SymbolBid__first_location_of_maximum'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__last_location_of_minimum')\n",
    "print(last_location_of_minimum(x))\n",
    "print(features['SymbolBid__last_location_of_minimum'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__mean_change')\n",
    "print(mean_change(x))\n",
    "print(features['SymbolBid__mean_change'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__sum_values')\n",
    "print(sum_values(x,[]))\n",
    "print(features['SymbolBid__sum_values'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__mean')\n",
    "print(mean(x,[]))\n",
    "print(features['SymbolBid__mean'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__minimum')\n",
    "print(minimum(x,[]))\n",
    "print(features['SymbolBid__minimum'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__median')\n",
    "print(median(x,[]))\n",
    "print(features['SymbolBid__median'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__c3__lag_3')\n",
    "print(c3(x, [3]))\n",
    "print(features['SymbolBid__c3__lag_3'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__quantile__q_0.3')\n",
    "print(quantile(x, [0.3]))\n",
    "print(features['SymbolBid__quantile__q_0.3'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_3__w_5')\n",
    "print(cwt_coefficients(x, [[2, 5, 10, 20],[3,9,2,3,11,12,5,4,8,14],[5,10,2,2,10,10,5,5,5,10]]))\n",
    "print(features['SymbolBid__cwt_coefficients__widths_(2, 5, 10, 20)__coeff_3__w_5'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__maximum')\n",
    "print(maximum(x,[]))\n",
    "print(features['SymbolBid__maximum'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__abs_energy')\n",
    "print(abs_energy(x, []))\n",
    "print(features['SymbolBid__abs_energy'].iloc[-1])\n",
    "\n",
    "print('SymbolBid__linear_trend__attr_\"intercept\"')\n",
    "print(linear_trend(x, \"intercept\"))\n",
    "print(features['SymbolBid__linear_trend__attr_\"intercept\"'].iloc[-1])\n",
    "#print(feature_scores.scores[feature_scores_ordered.features=='SymbolBid__fft_coefficient__coeff_0__attr_\"real\"'])\n",
    "#print(features.SymbolBid__last_location_of_maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "from scipy.signal import cwt, find_peaks_cwt, ricker, welch\n",
    "\n",
    "def complex_agg(x, agg):\n",
    "    if agg == \"real\":\n",
    "        return x.real\n",
    "    elif agg == \"imag\":\n",
    "        return x.imag\n",
    "    elif agg == \"abs\":\n",
    "        return np.abs(x)\n",
    "    elif agg == \"angle\":\n",
    "        return np.angle(x, deg=True)\n",
    "\n",
    "def _aggregate_on_chunks(x, f_agg, chunk_len):\n",
    "    \"\"\"\n",
    "    Takes the time series x and constructs a lower sampled version of it by applying the aggregation function f_agg on\n",
    "    consecutive chunks of length chunk_len\n",
    "\n",
    "    :param x: the time series to calculate the aggregation of\n",
    "    :type x: pandas.Series\n",
    "    :param f_agg: The name of the aggregation function that should be an attribute of the pandas.Series\n",
    "    :type f_agg: str\n",
    "    :param chunk_len: The size of the chunks where to aggregate the time series\n",
    "    :type chunk_len: int\n",
    "    :return: A list of the aggregation function over the chunks\n",
    "    :return type: list\n",
    "    \"\"\"\n",
    "    return [getattr(x[i * chunk_len: (i + 1) * chunk_len], f_agg)() for i in range(int(np.ceil(len(x) / chunk_len)))]    \n",
    "\n",
    "def quantile(x, param):\n",
    "    \"\"\"\n",
    "    Calculates the q quantile of x. This is the value of x greater than q% of the ordered values from x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param q: the quantile to calculate\n",
    "    :type q: float\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    #x = pd.Series(x)\n",
    "    return np.percentile(x, 100*param[0])\n",
    "\n",
    "def fft_coefficient(x, param):\n",
    "    \"\"\"\n",
    "    Calculates the fourier coefficients of the one-dimensional discrete Fourier Transform for real input by fast\n",
    "    fourier transformation algorithm\n",
    "\n",
    "    .. math::\n",
    "        A_k =  \\\\sum_{m=0}^{n-1} a_m \\\\exp \\\\left \\\\{ -2 \\\\pi i \\\\frac{m k}{n} \\\\right \\\\}, \\\\qquad k = 0,\n",
    "        \\\\ldots , n-1.\n",
    "\n",
    "    The resulting coefficients will be complex, this feature calculator can return the real part (attr==\"real\"),\n",
    "    the imaginary part (attr==\"imag), the absolute value (attr=\"\"abs) and the angle in degrees (attr==\"angle).\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param param: contains dictionaries {\"coeff\": x, \"attr\": s} with x int and x >= 0, s str and in [\"real\", \"imag\",\n",
    "        \"abs\", \"angle\"]\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "\n",
    "    #assert min([config[\"coeff\"] for config in param]) >= 0, \"Coefficients must be positive or zero.\"\n",
    "    #assert set([config[\"attr\"] for config in param]) <= set([\"imag\", \"real\", \"abs\", \"angle\"]), \\\n",
    "    #    'Attribute must be \"real\", \"imag\", \"angle\" or \"abs\"'\n",
    "    \n",
    "    fft = np.fft.rfft(x)\n",
    "\n",
    "    \n",
    "\n",
    "    res = complex_agg(fft[param[0]], param[1])\n",
    "    return res\n",
    "\n",
    "def linear_trend(x, param):\n",
    "    \"\"\"\n",
    "    Calculate a linear least-squares regression for the values of the time series versus the sequence from 0 to\n",
    "    length of the time series minus one.\n",
    "    This feature assumes the signal to be uniformly sampled. It will not use the time stamps to fit the model.\n",
    "    The parameters control which of the characteristics are returned.\n",
    "\n",
    "    Possible extracted attributes are \"pvalue\", \"rvalue\", \"intercept\", \"slope\", \"stderr\", see the documentation of\n",
    "    linregress for more information.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param param: contains dictionaries {\"attr\": x} with x an string, the attribute name of the regression model\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "    # todo: we could use the index of the DataFrame here\n",
    "    attr = param[0]\n",
    "    linReg = linregress(range(len(x)), x)\n",
    "\n",
    "    return getattr(linReg, attr)\n",
    "\n",
    "def agg_linear_trend(x, param):\n",
    "    \"\"\"\n",
    "    Calculates a linear least-squares regression for values of the time series that were aggregated over chunks versus\n",
    "    the sequence from 0 up to the number of chunks minus one.\n",
    "\n",
    "    This feature assumes the signal to be uniformly sampled. It will not use the time stamps to fit the model.\n",
    "\n",
    "    The parameters attr controls which of the characteristics are returned. Possible extracted attributes are \"pvalue\",\n",
    "    \"rvalue\", \"intercept\", \"slope\", \"stderr\", see the documentation of linregress for more information.\n",
    "\n",
    "    The chunksize is regulated by \"chunk_len\". It specifies how many time series values are in each chunk.\n",
    "\n",
    "    Further, the aggregation function is controlled by \"f_agg\", which can use \"max\", \"min\" or , \"mean\", \"median\"\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param param: contains dictionaries {\"attr\": x, \"chunk_len\": l, \"f_agg\": f} with x, f an string and l an int\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "    # todo: we could use the index of the DataFrame here\n",
    "    calculated_agg = {}\n",
    "    f_agg = param[0]\n",
    "    chunk_len = param[1]\n",
    "    attr = param[2]\n",
    "    \n",
    "    aggregate_result = _aggregate_on_chunks(x, f_agg, chunk_len)\n",
    "    if f_agg not in calculated_agg or chunk_len not in calculated_agg[f_agg]:\n",
    "        if chunk_len >= len(x):\n",
    "            calculated_agg[f_agg] = {chunk_len: np.NaN}\n",
    "        else:\n",
    "            lin_reg_result = linregress(range(len(aggregate_result)), aggregate_result)\n",
    "            calculated_agg[f_agg] = {chunk_len: lin_reg_result}\n",
    "\n",
    "    if chunk_len >= len(x):\n",
    "        res_data = np.NaN\n",
    "    else:\n",
    "        res_data = getattr(calculated_agg[f_agg][chunk_len], attr)\n",
    "        \n",
    "    return res_data\n",
    "\n",
    "def first_location_of_minimum(x):\n",
    "    \"\"\"\n",
    "    Returns the first location of the minimal value of x.\n",
    "    The position is calculated relatively to the length of x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.argmin(x) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def energy_ratio_by_chunks(x, num_segments, segment_focus):\n",
    "    \"\"\"\n",
    "    Calculates the sum of squares of chunk i out of N chunks expressed as a ratio with the sum of squares over the whole\n",
    "    series.\n",
    "\n",
    "    Takes as input parameters the number num_segments of segments to divide the series into and segment_focus\n",
    "    which is the segment number (starting at zero) to return a feature on.\n",
    "\n",
    "    If the length of the time series is not a multiple of the number of segments, the remaining data points are\n",
    "    distributed on the bins starting from the first. For example, if your time series consists of 8 entries, the\n",
    "    first two bins will contain 3 and the last two values, e.g. `[ 0.,  1.,  2.], [ 3.,  4.,  5.]` and `[ 6.,  7.]`.\n",
    "\n",
    "    Note that the answer for `num_segments = 1` is a trivial \"1\" but we handle this scenario\n",
    "    in case somebody calls it. Sum of the ratios should be 1.0.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param param: contains dictionaries {\"num_segments\": N, \"segment_focus\": i} with N, i both ints\n",
    "    :return: the feature values\n",
    "    :return type: list of tuples (index, data)\n",
    "    \"\"\"\n",
    "    res_data = []\n",
    "    res_index = []\n",
    "    full_series_energy = np.sum(x ** 2)\n",
    "\n",
    "    assert segment_focus < num_segments\n",
    "    assert num_segments > 0\n",
    "\n",
    "    res_data = np.sum(np.array_split(x, num_segments)[segment_focus] ** 2.0)/full_series_energy\n",
    "\n",
    "    return res_data\n",
    "\n",
    "def change_quantiles(x, ql, qh, isabs, f_agg):\n",
    "    \"\"\"\n",
    "    First fixes a corridor given by the quantiles ql and qh of the distribution of x.\n",
    "    Then calculates the average, absolute value of consecutive changes of the series x inside this corridor.\n",
    "\n",
    "    Think about selecting a corridor on the\n",
    "    y-Axis and only calculating the mean of the absolute change of the time series inside this corridor.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param ql: the lower quantile of the corridor\n",
    "    :type ql: float\n",
    "    :param qh: the higher quantile of the corridor\n",
    "    :type qh: float\n",
    "    :param isabs: should the absolute differences be taken?\n",
    "    :type isabs: bool\n",
    "    :param f_agg: the aggregator function that is applied to the differences in the bin\n",
    "    :type f_agg: str, name of a numpy function (e.g. mean, var, std, median)\n",
    "\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if ql >= qh:\n",
    "        ValueError(\"ql={} should be lower than qh={}\".format(ql, qh))\n",
    "\n",
    "    div = np.diff(x)\n",
    "    if isabs:\n",
    "        div = np.abs(div)\n",
    "    # All values that originate from the corridor between the quantiles ql and qh will have the category 0,\n",
    "    # other will be np.NaN\n",
    "    try:\n",
    "        bin_cat = pd.qcut(x, [ql, qh], labels=False)\n",
    "        bin_cat_0 = bin_cat == 0\n",
    "    except ValueError:  # Occurs when ql are qh effectively equal, e.g. x is not long enough or is too categorical\n",
    "        return 0\n",
    "    # We only count changes that start and end inside the corridor\n",
    "    ind = (bin_cat_0 & np.roll(bin_cat_0, 1))[1:]\n",
    "    if sum(ind) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        ind_inside_corridor = np.where(ind == 1)\n",
    "        aggregator = getattr(np, f_agg)\n",
    "        return aggregator(div[ind_inside_corridor])\n",
    "    \n",
    "def index_mass_quantile(x, q):\n",
    "    \"\"\"\n",
    "    Those apply features calculate the relative index i where q% of the mass of the time series x lie left of i.\n",
    "    For example for q = 50% this feature calculator will return the mass center of the time series\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param param: contains dictionaries {\"q\": x} with x float\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    abs_x = np.abs(x)\n",
    "    s = sum(abs_x)\n",
    "\n",
    "    if s == 0:\n",
    "        # all values in x are zero or it has length 0\n",
    "        return np.NaN\n",
    "    else:\n",
    "        # at least one value is not zero\n",
    "        mass_centralized = np.cumsum(abs_x) / s\n",
    "        return (np.argmax(mass_centralized >= q)+1)/len(x)\n",
    "    \n",
    "def number_cwt_peaks(x, n):\n",
    "    \"\"\"\n",
    "    This feature calculator searches for different peaks in x. To do so, x is smoothed by a ricker wavelet and for\n",
    "    widths ranging from 1 to n. This feature calculator returns the number of peaks that occur at enough width scales\n",
    "    and with sufficiently high Signal-to-Noise-Ratio (SNR)\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param n: maximum width to consider\n",
    "    :type n: int\n",
    "    :return: the value of this feature\n",
    "    :return type: int\n",
    "    \"\"\"\n",
    "    return len(find_peaks_cwt(vector=x, widths=np.array(list(range(1, n + 1))), wavelet=ricker))\n",
    "\n",
    "def last_location_of_maximum(x):\n",
    "    \"\"\"\n",
    "    Returns the relative last location of the maximum value of x.\n",
    "    The position is calculated relatively to the length of x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    return 1.0 - np.argmax(x[::-1]) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def first_location_of_maximum(x):\n",
    "    \"\"\"\n",
    "    Returns the first location of the maximum value of x.\n",
    "    The position is calculated relatively to the length of x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.argmax(x) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def last_location_of_minimum(x):\n",
    "    \"\"\"\n",
    "    Returns the last location of the minimal value of x.\n",
    "    The position is calculated relatively to the length of x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    return 1.0 - np.argmin(x[::-1]) / len(x) if len(x) > 0 else np.NaN\n",
    "\n",
    "def mean_change(x):\n",
    "    \"\"\"\n",
    "    Returns the mean over the absolute differences between subsequent time series values which is\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\frac{1}{n} \\\\sum_{i=1,\\ldots, n-1}  x_{i+1} - x_{i}\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    return np.mean(np.diff(x))\n",
    "\n",
    "def abs_energy(x, param):\n",
    "    \"\"\"\n",
    "    Returns the absolute energy of the time series which is the sum over the squared values\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        E = \\\\sum_{i=1,\\ldots, n} x_i^2\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.dot(x, x)\n",
    "\n",
    "def sum_values(x, param):\n",
    "    \"\"\"\n",
    "    Calculates the sum over the time series values\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: bool\n",
    "    \"\"\"\n",
    "    if len(x) == 0:\n",
    "        return 0\n",
    "\n",
    "    return np.sum(x)\n",
    "\n",
    "def mean(x, param):\n",
    "    \"\"\"\n",
    "    Returns the mean of x\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    return np.mean(x)\n",
    "\n",
    "def minimum(x, param):\n",
    "    \"\"\"\n",
    "    Calculates the lowest value of the time series x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    return np.min(x)\n",
    "\n",
    "def median(x, param):\n",
    "    \"\"\"\n",
    "    Returns the median of x\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    return np.median(x)\n",
    "\n",
    "def c3(x, param):\n",
    "    \"\"\"\n",
    "    This function calculates the value of\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\frac{1}{n-2lag} \\sum_{i=0}^{n-2lag} x_{i + 2 \\cdot lag}^2 \\cdot x_{i + lag} \\cdot x_{i}\n",
    "\n",
    "    which is\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\mathbb{E}[L^2(X)^2 \\cdot L(X) \\cdot X]\n",
    "\n",
    "    where :math:`\\\\mathbb{E}` is the mean and :math:`L` is the lag operator. It was proposed in [1] as a measure of\n",
    "    non linearity in the time series.\n",
    "\n",
    "    .. rubric:: References\n",
    "\n",
    "    |  [1] Schreiber, T. and Schmitz, A. (1997).\n",
    "    |  Discrimination power of measures for nonlinearity in a time series\n",
    "    |  PHYSICAL REVIEW E, VOLUME 55, NUMBER 5\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param lag: the lag that should be used in the calculation of the feature\n",
    "    :type lag: int\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    n = x.size\n",
    "    if 2 * param[0] >= n:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean((np.roll(x, 2 * -param[0]) * np.roll(x, -param[0]) * x)[0:(n - 2 * param[0])])\n",
    "    \n",
    "def cwt_coefficients(x, param):\n",
    "    \"\"\"\n",
    "    Calculates a Continuous wavelet transform for the Ricker wavelet, also known as the \"Mexican hat wavelet\" which is\n",
    "    defined by\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{2}{\\\\sqrt{3a} \\\\pi^{\\\\frac{1}{4}}} (1 - \\\\frac{x^2}{a^2}) exp(-\\\\frac{x^2}{2a^2})\n",
    "\n",
    "    where :math:`a` is the width parameter of the wavelet function.\n",
    "\n",
    "    This feature calculator takes three different parameter: widths, coeff and w. The feature calculater takes all the\n",
    "    different widths arrays and then calculates the cwt one time for each different width array. Then the values for the\n",
    "    different coefficient for coeff and width w are returned. (For each dic in param one feature is returned)\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :param param: contains dictionaries {\"widths\":x, \"coeff\": y, \"w\": z} with x array of int and y,z int\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "    \n",
    "    calculated_cwt = {}\n",
    "    widths = param[0]\n",
    "    coeff = param[1]\n",
    "    w = param[2]\n",
    "    res = np.zeros((len(w)))\n",
    "    #print(coeff)\n",
    "    calculated_cwt_for_widths = cwt(x, ricker, widths)\n",
    "    #print(calculated_cwt_for_widths)\n",
    "    for r in range(len(w)):\n",
    "        i = widths.index(w[r])\n",
    "        if calculated_cwt_for_widths.shape[1] <= coeff[r]:\n",
    "            res[r] = np.NaN\n",
    "        else:\n",
    "            res[r] = calculated_cwt_for_widths[i, coeff[r]]\n",
    "\n",
    "    return res\n",
    "\n",
    "def maximum(x,param):\n",
    "    \"\"\"\n",
    "    Calculates the highest value of the time series x.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: pandas.Series\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    return np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_scores_ordered.to_csv('../features/feature_scores_ordered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            features scores\n",
      "0  SymbolBid__fft_coefficient__coeff_30__attr_\"an...      4\n",
      "1  SymbolBid__fft_coefficient__coeff_30__attr_\"an...      3\n",
      "2  SymbolBid__fft_coefficient__coeff_30__attr_\"an...      2\n"
     ]
    }
   ],
   "source": [
    "#feature_scores = pd.DataFrame(columns=['features','scores'])\n",
    "feature_scores = feature_scores.append(pd.DataFrame({'features':c,'scores':1},index=[0]),ignore_index=True)\n",
    "\n",
    "feature_scores.scores[feature_scores.features==c] += 1\n",
    "print(feature_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('f_agg_\"mean\"', 0.92831114415939009)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tsfresh\n",
    "print(tsfresh.feature_extraction.feature_calculators.number_cwt_peaks(x, 5))\n",
    "param=[{\"f_agg\": \"mean\", \"maxlag\": 4}]\n",
    "tsfresh.feature_extraction.feature_calculators.agg_autocorrelation(x,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IDweights': '000286', 'assets': [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 27, 28, 29, 30, 31, 32], 'nEventsPerStat': 1000, 'outputGain': 0.6, 'dateTest': ['2018.03.09', '2018.03.12', '2018.03.13', '2018.03.14', '2018.03.15', '2018.03.16', '2018.03.19', '2018.03.20', '2018.03.21', '2018.03.22', '2018.03.23', '2018.03.26', '2018.03.27', '2018.03.28', '2018.03.29', '2018.03.30', '2018.04.02', '2018.04.03', '2018.04.04', '2018.04.05', '2018.04.06', '2018.04.09', '2018.04.10', '2018.04.11', '2018.04.12', '2018.04.13', '2018.04.16', '2018.04.17', '2018.04.18', '2018.04.19', '2018.04.20', '2018.04.23', '2018.04.24', '2018.04.25', '2018.04.26', '2018.04.27', '2018.04.30', '2018.05.01', '2018.05.02', '2018.05.03', '2018.05.04', '2018.05.07', '2018.05.08', '2018.05.09', '2018.05.10', '2018.05.11', '2018.05.14', '2018.05.15', '2018.05.16', '2018.05.17', '2018.05.18', '2018.05.21', '2018.05.22', '2018.05.23', '2018.05.24', '2018.05.25', '2018.05.28', '2018.05.29', '2018.05.30', '2018.05.31', '2018.06.01', '2018.06.04', '2018.06.05', '2018.06.06', '2018.06.07', '2018.06.08', '2018.06.11', '2018.06.12', '2018.06.13', '2018.06.14', '2018.06.15', '2018.06.18', '2018.06.19', '2018.06.20', '2018.06.21', '2018.06.22', '2018.06.25', '2018.06.26', '2018.06.27', '2018.06.28', '2018.06.29', '2018.07.02', '2018.07.03', '2018.07.04', '2018.07.05', '2018.07.06', '2018.07.09', '2018.07.10', '2018.07.11', '2018.07.12', '2018.07.13', '2018.07.30', '2018.07.31', '2018.08.01', '2018.08.02', '2018.08.03', '2018.08.06', '2018.08.07', '2018.08.08', '2018.08.09', '2018.08.10', '2018.08.13', '2018.08.14', '2018.08.15', '2018.08.16', '2018.08.17', '2018.08.20', '2018.08.21', '2018.08.22', '2018.08.23', '2018.08.24', '2018.08.27', '2018.08.28', '2018.08.29', '2018.08.30', '2018.08.31', '2018.09.03', '2018.09.04', '2018.09.05', '2018.09.06', '2018.09.07', '2018.09.10', '2018.09.11', '2018.09.12', '2018.09.13', '2018.09.14', '2018.09.17', '2018.09.18', '2018.09.19', '2018.09.20', '2018.09.21', '2018.09.24', '2018.09.25', '2018.09.26', '2018.09.27'], 'lB': 1300, 'save_stats': True, 'startFrom': 6, 'miniBatchSize': 32, 'IDresults': '100286', 'config_name': 'C0286', 'size_hidden_layer': 200, 'channels': [0], 'num_epochs': 1, 'lR0': 0.0001, 'movingWindow': 100, 'endAt': 6, 'save_journal': True, 'if_build_IO': False, 'IO_directory': '../RNN/IO/', 'hdf5_directory': 'D:/SDC/py/HDF5/', 'L': 3, 'size_output_layer': 5, 'max_var': 10, 'commonY': 3, 'keep_prob_dropout': 0.9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import print_config, modify_config\n",
    "print_config('C0286T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modify_config('C0286','hdf5_directory','D:/SDC/py/HDF5/')\n",
    "modify_config('C0286T','save_journal',True)\n",
    "#modify_config('C0286','endAt',6)\n",
    "#modify_config('C0286','startFrom',6)\n",
    "modify_config('C0286T','if_build_IO',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SymbolBid__fft_coefficient__coeff_30__attr_\"angle\"'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
