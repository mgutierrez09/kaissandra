{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Cassandra1.jpeg/800px-Cassandra1.jpeg)\n",
    "## Notebook to run serial methods\n",
    "\n",
    "With this notebook you can run live/backtest Kaissandra, plot live results and much more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\magut\\root\\Projects\\SDC\\kaissandra\\ added to python path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "this_path = os.getcwd()\n",
    "path = '\\\\'.join(this_path.split('\\\\')[:-1])+'\\\\'\n",
    "if path not in sys.path:\n",
    "    sys.path.insert(0, path)\n",
    "    print(path+\" added to python path\")\n",
    "else:\n",
    "    print(path+\" already in python path\")\n",
    "    \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Util Functions and Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions_filename(asset, open_dt, close_dt):\n",
    "    \"\"\"  \"\"\"\n",
    "    \n",
    "    dt_open = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            open_dt,'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "    dt_close = dt.datetime.strftime(dt.datetime.strptime(\n",
    "            close_dt,'%Y.%m.%d %H:%M:%S'),'%y%m%d%H%M%S')\n",
    "    filename = 'O'+dt_open+'C'+dt_close+asset\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live = False\n",
    "start_time = '19_01_27_16_04_55'\n",
    "\n",
    "if live:\n",
    "    ext = '_LI_'\n",
    "    directory = 'live'\n",
    "else:\n",
    "    ext = '_BT_'\n",
    "    directory = 'back_test'\n",
    "results_dir = '../../RNN/resultsLive/'+directory+'/trader/'\n",
    "positions_dir = '../../RNN/resultsLive/back_test/positions/'+start_time+'/'\n",
    "filename = results_dir+start_time+ext+\"positions_soll.log\"\n",
    "positions = pd.read_csv(filename).sort_values(by=['Entry Time']).reset_index().drop(labels='index',axis=1)\n",
    "print(positions.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Stats File and Plot Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['asset','Di','Ti','Do','To','direction','groi','roi','profit','e_spread','spread','max','min','argmax','argmin','samples','extensions','stoploss','file']\n",
    "pos_format = pd.DataFrame(data=0,columns=columns,index=range(positions.shape[0]))\n",
    "plt_index = 0\n",
    "for p in range(positions.shape[0]):\n",
    "    #print(positions.iloc[p])\n",
    "    pos_format['asset'].iloc[p] = positions['Asset'].iloc[p]\n",
    "    pos_format['Di'].iloc[p] = positions['Entry Time'].iloc[p][:10]\n",
    "    pos_format['Ti'].iloc[p] = positions['Entry Time'].iloc[p][11:]\n",
    "    pos_format['Do'].iloc[p] = positions['Exit Time'].iloc[p][:10]\n",
    "    pos_format['To'].iloc[p] = positions['Exit Time'].iloc[p][11:]\n",
    "    pos_format['groi'].iloc[p] = positions['GROI'].iloc[p]\n",
    "    pos_format['roi'].iloc[p] = positions['ROI'].iloc[p]\n",
    "    pos_format['e_spread'].iloc[p] = positions['E_spread'].iloc[p]\n",
    "    pos_format['spread'].iloc[p] = positions['Spread'].iloc[p]\n",
    "    pos_format['profit'].iloc[p] = positions['Profit'].iloc[p]\n",
    "    pos_format['stoploss'].iloc[p] = positions['stoploss'].iloc[p]\n",
    "    direction = positions['Position'].iloc[p]\n",
    "    pos_format['direction'].iloc[p] = direction\n",
    "    filename_pos = get_positions_filename(positions['Asset'].iloc[p], positions['Entry Time'].iloc[p], positions['Exit Time'].iloc[p])\n",
    "    pos_format['file'].iloc[p] = filename_pos\n",
    "    pos_ev = pd.read_csv(positions_dir+filename_pos+'.txt', sep=',')\n",
    "    pos_track = pickle.load( open( positions_dir+filename_pos+\".p\", \"rb\" ))\n",
    "    #print(pos_track)\n",
    "    pos_format['extensions'].iloc[p] = pos_track['n_ext']\n",
    "    pos_format['samples'].iloc[p] = pos_ev.shape[0]\n",
    "    #print(pos_ev.columns)\n",
    "    maxBid = pos_ev['SymbolBid'].max()\n",
    "    minBid = pos_ev['SymbolBid'].min()\n",
    "    maxAsk = pos_ev['SymbolAsk'].max()\n",
    "    minAsk = pos_ev['SymbolAsk'].min()\n",
    "    Bi = positions['Bi'].iloc[p]\n",
    "    Ai = positions['Ai'].iloc[p]\n",
    "    #if direction>0:\n",
    "    #        GROI_live = roi_ratio*(Ao-Ai)/Ai\n",
    "    #        spread = (Ao-Bo)/Ai\n",
    "    #        \n",
    "    #    else:\n",
    "    #        GROI_live = roi_ratio*(Bi-Bo)/Ao\n",
    "    if direction>0:\n",
    "        pos_format['max'].iloc[p] = 100*(maxAsk-positions['Ai'].iloc[p])/positions['Ai'].iloc[p]\n",
    "        pos_format['min'].iloc[p] = 100*(minAsk-positions['Ai'].iloc[p])/positions['Ai'].iloc[p]\n",
    "        pos_format['argmax'].iloc[p] = pos_ev['SymbolAsk'].idxmax()\n",
    "        pos_format['argmin'].iloc[p] = pos_ev['SymbolAsk'].idxmin()\n",
    "        groi_ev = 100*(pos_ev['SymbolAsk'].iloc[:]-positions['Ai'].iloc[p])/positions['Ai'].iloc[p]\n",
    "        label = 'long'\n",
    "    else:\n",
    "        pos_format['max'].iloc[p] = 100*(positions['Bi'].iloc[p]-minBid)/maxAsk\n",
    "        pos_format['min'].iloc[p] = 100*(positions['Bi'].iloc[p]-maxBid)/maxAsk\n",
    "        pos_format['argmax'].iloc[p] = pos_ev['SymbolBid'].idxmax()\n",
    "        pos_format['argmin'].iloc[p] = pos_ev['SymbolBid'].idxmin()\n",
    "        groi_ev = 100*(positions['Bi'].iloc[p]-pos_ev['SymbolBid'].iloc[:])/pos_ev['SymbolAsk'].iloc[:]\n",
    "        label = 'short'\n",
    "    if positions['GROI'].iloc[p]>0:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    plt.figure(plt_index)\n",
    "    plt.plot(groi_ev, color=color, label=label)\n",
    "    for e in range(pos_track['n_ext']):\n",
    "        plt.plot([pos_track['@tick#'][e+1] for i in range(2)],[pos_format['min'].iloc[p], pos_format['max'].iloc[p]])\n",
    "    plt.legend()\n",
    "    plt.title(filename_pos)\n",
    "    plt_index += 1\n",
    "print(pos_format.to_string())\n",
    "pos_format.to_csv(positions_dir+'stats.csv', index=False, sep='\\t', float_format='%.5f')\n",
    "print(\"Positions summary saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Summary from Position Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Kaissandra in Online Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# runLive in multiple processes\n",
    "from multiprocessing import Process\n",
    "import datetime as dt\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from kaissandra.runLive import run\n",
    "\n",
    "assets = [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 17, 19, 27, 28, 29, 30, 31, 32]#\n",
    "running_assets = assets#[7, 14]\n",
    "start_time = dt.datetime.strftime(dt.datetime.now(),'%y_%m_%d_%H_%M_%S')\n",
    "#disp = Process(target=run, args=[running_assets,start_time])\n",
    "#disp.start()\n",
    "for ass_idx in range(len(running_assets)):\n",
    "    disp = Process(target=run, args=[running_assets[ass_idx:ass_idx+1],start_time])\n",
    "    disp.start()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get total returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "start_time = '18_12_10_10_53_20'\n",
    "results_dir = '../RNN/resultsLive/back_test/trader/'\n",
    "filename = results_dir+start_time+'_LI_'+\"positions_soll.log\"\n",
    "positions = pd.read_csv(filename)\n",
    "print(positions.GROI.sum())\n",
    "print(positions.ROI.sum())\n",
    "print(positions.Profit.sum())\n",
    "print(positions.Profit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
